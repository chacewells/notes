# Module 1

## Introduction

In today’s rapidly evolving technological landscape, artificial intelligence (AI) is no longer a futuristic concept but a driving force of innovation and disruption across industries. Yet, AI alone is not the answer to corporate success, any more than other technologies were before. It takes smart leadership to drive success in a fast-moving, technology-fueled business environment—now more than ever.

This module sets the foundation for the rest of the course, providing a strategic lens on how organizations can successfully navigate and harness AI-driven transformation. Drawing from MIT research and real-world case studies, we will explore:

The key capabilities necessary for mastering digital transformation in an AI-powered world
What is different in the AI era
Industry case studies from healthcare, finance, manufacturing, and mining, illustrating how AI is driving innovation and business success
By the end of this module, you will be able to identify key digital transformation capabilities, analyze AI’s role in business transformation, and evaluate real-world applications of AI across various industries.

Throughout this course, we will emphasize not just technology, but leadership—understanding how executives can align AI-driven opportunities with strategic business goals, overcome resistance to change, and foster an organizational culture that is continuously adaptive and future-ready.

Table of Contents

1. Why Digital Mastery Is Important in the AI-Powered Future
   Understanding the Exponential Pace of Change
   Understanding the Organizational Pace of Change and the Meaning of Transformation
2. Key Capabilities for Digital Transformation
   The Digital Mastery Framework
   Key Capabilities for Digital Mastery
3. What Is Different in the AI Era?
4. Industry Case Studies
   Healthcare: AI-Powered Diagnostics and Personalized Medicine
   Finance: AI-Driven Fraud Detection and Personalized Banking
   Manufacturing: AI-Driven Evolution and Coordination
   Mining: AI-Powered Automation and Sustainability
5. Looking Ahead

learning objectives
in module 1, “the new era of digital transformation,” with mit instructor dr. george westerman, ﻿you will:

identify the key capabilities necessary for digital transformation mastery

Understand the difference between technological rates of change and organizational rates of change and what this difference means for digital transformation

Explore examples of successful digital transformation in sectors like healthcare, finance, and manufacturing

Overall Course Learning Objectives

Analyze the potential opportunities enabled by emerging digital technologies like AI, robotics, and the Internet of Things (IoT)
Develop strategies for transforming customer experience, operations, and business models using technology
Understand how to establish the innovative culture and capabilities that are essential for success in the modern AI era

## Skip to content

Home Menu
Previous
Next

1. Why Digital Mastery Is Important in the AI-Powered Future
   The rapid advancement of artificial intelligence (AI) and digital technologies is reshaping industries at an unprecedented pace. While organizations have been engaged in some forms of digital transformation for decades, and the digital transformation era has been underway for more than a decade, the emergence of generative AI, machine learning, and related innovations has introduced a new wave of change. However, driving real benefit from technologies is not simply about investing in technology—it is about ensuring your organization gains meaningful value by transforming the way it does business.

Before we begin to consider the role leaders play in driving AI-powered digital transformation and the key capabilities organizations must strengthen to ensure successful transformation initiatives, we need to understand what we truly mean by an "unprecedented pace."

In 1965, Gordon Moore, a cofounder of semiconductor company Intel, was asked for a prediction of the semiconductor field for the following decade (Intel, 2023). Moore gave a rough estimate of a doubling of complexity every year. Moore’s estimate has since been slightly revised to a doubling approximately every 24 months and is commonly known as Moore’s Law. This means that technology advances at an exponential rate.

Moore’s Law has held true for integrated circuits well beyond its initial ten-year window. Furthermore, the exponential nature of progress has been found to hold for many other digital technologies (Roser et al., 2023).

Understanding the Exponential Pace of Change
Technological innovation follows an exponential growth curve. But humans tend to think linearly. This means that managers tend to overestimate what new technologies can deliver in the near term while underestimating the speed at which they add capability over time (Bonnet & Westerman, 2020). AI adoption exemplifies this challenge:

Business planning works better when changes are gradual and manageable.
But, as innovators integrate AI with Internet of Things (IoT), cloud computing, real-time analytics, and new business practices, industries experience major shifts in business models, customer expectations, and operational capabilities (Westerman, 2024).
Therefore, leaders must continuously recalibrate strategies to align with emerging technological possibilities rather than relying on rigid transformation roadmaps.
Organizations that fail to recognize this exponential evolution often fall behind more agile competitors, struggling with outdated models and resistance to AI-driven change.

A common example of exponential progress is the development of computing machines. In 1969, the Apollo 11 Guidance Computer safely landed a human on the Moon, one of the greatest and most complex computing applications ever carried out. The Apollo 11 Guidance Computer operated at 12,250 floating point operations per second (​Adobe, 2022). By 1985, just 16 years later, the top supercomputer was operating at 1.9 billion floating points. The iPhone that may be lying on your desk is capable of 11 trillion floating point operations per second. That is to say, the average smartphone today is trillions of times more powerful than the computer that landed astronauts on the Moon just fifty years ago.

However, considering the differences between the 1985 CRAY-2 supercomputer and an iPhone is illustrative in another way. The CRAY-2 required 16 square feet of space and weighed 5,500 pounds and cost between 12 and 20 million dollars to produce (​​Martin, 2019). An iPhone, on the other hand, costs an estimated $485 per unit (​​Lee, 2024). It is not only computer power, but several other performance metrics by which we can observe exponential advancement in technology.

Interestingly, as noted above, Moore’s Law has been seen to hold for technologies beyond computing. In biochemistry, for example, the costs of sequencing the human genome have even outpaced Moore’s Law since 2001 (​​National Human Genome Research Institute, 2023).

​Adapted from: (National Human Genome Research Institute, 2023)​

Recognizing the exponential pace of technological change is only the first step. While AI and digital innovations are accelerating the transformation of industries, it is not the technology itself that determines success—it is how organizations respond to these changes. The ability to thrive in this rapidly evolving environment depends on more than just adopting the latest tools; it requires strategic decision-making, solid organization capability, and strong leadership, at any level, to drive change.

Understanding the Organizational Pace of Change and the Meaning of Transformation
Despite technological progress, research consistently shows that 70%﻿ of digital transformation initiatives fail. The primary reason is not the technology itself, but the inability of leaders to drive necessary changes in their organizations to change. This reflects what has been termed the first law of digital innovation (or Westerman’s Law) (Westerman, 2019): The First Law of Digital Innovation.

“Technology changes quickly, but organizations change much more slowly.”
Dr. George Westerman (2019)

This principle underscores a critical reality: while AI and digital tools evolve exponentially, businesses must also develop leadership strategies, cultures, and workforce readiness to successfully implement these innovations (Westerman et al., 2014; Bonnet & Westerman, 2020).

It is incumbent on leaders to match these two forces: the rate of technological change and the rate of organizational change. As we continue through this course, we will see how leadership plays a pivotal role in navigating and aligning these forces. You will learn how to craft a compelling vision for the future, promote conversations that engage and empower teams, and address legacy systems and practices that slow transformation (Westerman, 2019). We will explore strategies for initiating pilots that create momentum and build a culture of continuous innovation, ensuring that digital transformation becomes an ongoing process that drives lasting change in your organization.

Poll
Results

Forum: Is Your Company a Software Company?
It is common for organizational leaders to make statements such as, "We are not a bank, we are a software company," or "We are not a trucking company, we are an information company." In the discussion forum, you will explore how your organization defines itself and how technology and innovation shape that identity.

2.  Key Capabilities for Digital Transformation
    Digital transformation is not solely about adopting new technologies—it is about building the organizational capabilities that enable businesses to adapt, innovate, and thrive in an environment shaped by continuous change. Effective leaders shape organizational capabilities and culture that allow digital transformation initiatives to succeed. This is an on-going activity that requires continuous direction from leadership. To establish a solid basis for this course, we must first identify the essential capabilities required.

At the start of the digital transformation era, MIT research with hundreds of large companies (Westerman et al., 2014) showed that at the companies best able to drive digital transformation—companies they called digital masters—have two essential capabilities: digital capability and leadership capability. These capabilities are interdependent; technology can enable new possibilities, but it is leadership that ensures these technologies create lasting impact. Additional research by MIT and others in the 15 years since that time continues to show the importance of these two capabilities, while building deeper knowledge about what those capabilities are.

The Digital Mastery Framework

The digital mastery framework evaluates organizations across two key dimensions (Westerman et al., 2014). Digital capability measures the use of digital technology in a company’s key processes, while leadership capability examines the ability to envision and drive change.

Effective leadership ensures that digital initiatives align with strategic priorities and that organizations cultivate an environment that encourages experimentation, adaptability, and continuous learning. Together, these capabilities determine whether a business can navigate disruption, capitalize on emerging opportunities, and sustain long-term success in a rapidly evolving digital landscape.

Click on each card to uncover the distinct features of digital and leadership capabilities and explore how these pillars drive organizational success.

Digital Capability
Flip
Digital capability is the organization’s use of technology in customer experiences, operations, employee experiences, and business models. It is not just about adopting tools like AI, IoT, or data analytics, but about embedding them into core processes to drive real-time decision-making, innovation, and resilience. Companies with strong digital capabilities do not just improve efficiency—they transform how value is created and delivered in their industries.

Flip
Leadership Capability
Flip
Leadership capability goes beyond guiding teams through digital initiatives. It reflects the ability to set a clear strategic vision, engage employees, encourage a culture of adaptability, and lead with purpose in times of rapid change. Leaders play a pivotal role in creating these capabilities. They also have a strong role in embedding digital thinking across the organization, promoting continuous learning, and ensuring that technological investments align with broader business objectives. In the AI-powered era, strong leadership also means balancing technological potential with ethical considerations, governance, and sustainable growth (Bonnet & Westerman, 2020).

Flip
The digital mastery framework helps organizations assess where they stand in their digital transformation journey based on two critical dimensions.

Digital capability: How effectively an organization utilizes technology to improve operations, enhance customer experiences, and drive innovation
Leadership capability: The organization’s ability to set a clear vision, engage employees in change, and build a culture that adapts in a rapidly evolving environment (Westerman et al., 2014)
Understanding your organization’s position within the digital mastery framework is a key first step to identifying both strengths and areas for growth. The framework categorizes organizations into four distinct groups based on how they perform across these dimensions: beginners, fashionistas, conservatives, and digital masters.

Adapted from: (Westerman et al., 2021)

Digital capability:

Customer experience
Operations
Employee experience
Business model
Digital platform
Leadership capability:

Vision
Engagement
Governance
Technology leadership
Digital-ready culture

Beginners

Conservatives

Fashionistas

Digital masters

Organizations typically fall into one of four categories. Beginners are those with low digital and leadership capabilities, often hesitant to invest in transformation due to cost concerns or past failures. Fashionistas experiment with new digital tools but lack a coherent strategy, leading to disconnected efforts and inefficiencies. Conservatives are cautious adopters, ensuring strong governance but often missing opportunities due to slow execution. Finally, digital masters successfully combine technological expertise with strong leadership, consistently driving innovation across their operations.

A company such as Asian Paints exemplifies this model, having transformed from a fragmented regional business into a globally integrated, technology-enabled enterprise. By standardizing its operations through an enterprise-wide ERP system, the company streamlined logistics and enabled AI-powered decision-making, positioning itself as a leader in its industry. (Westerman, 2025)

Similarly, DBS showcases how strong leadership capabilities can drive digital transformation. The bank transitioned from a traditional financial institution to a technology-first organization, embedding AI and data analytics into its core operations to enhance customer experience, improve risk management, and foster a culture of continuous innovation.

In the healthcare sector, Mayo Clinic illustrates the transformative potential of AI in improving patient outcomes and operational efficiency. By leveraging advanced data analytics, AI-driven diagnostic tools, and precision medicine initiatives, Mayo Clinic has redefined healthcare delivery while maintaining its commitment to clinical excellence.

We will explore these transformations in more detail in the Industry Case Studies section, highlighting how different organizations apply the principles of digital mastery to their unique contexts.

This framework remains highly relevant, even as AI is fundamentally altering the digital transformation landscape. Companies that integrate AI-driven capabilities alongside traditional digital transformation strategies are the ones best positioned for long-term success.

Key Capabilities for Digital Mastery
Achieving success in digital transformation requires more than just the implementation of new technologies. It depends on an organization’s ability to develop two capabilities that enable it to adapt, innovate, and lead effectively in an AI-powered world. These capabilities form the foundation for sustained transformation, driving both operational excellence and strategic growth.

Rather than focusing solely on technology, digital mastery is about how organizations integrate digital tools with strong leadership practices to create long-term value. This section explores the core capabilities that underpin successful transformation, organized around two key dimensions: digital capability and leadership capability.

Each of these capabilities is supported by sub-capabilities that highlight the specific competencies organizations need to thrive in a rapidly evolving business landscape.

Digital Capability
Digital capability encompasses an organization’s ability to strategically integrate technology across five key areas: customer experience, operations, employee experience, business models, and digital platforms. A strong digital capability ensures that leaders can effectively leverage technology to drive innovation, enhance efficiency, and build long-term resilience in their organizations (Davenport & Westerman, 2018).

Organizations with strong digital capability do not just adopt technology—they integrate it strategically to create value, drive innovation, and build resilience in the face of disruption.

Customer experience

Operations

Employee experience

Business model

Digital platform

Leadership Capability
While technology can enable transformation, it is leadership capability that ensures its success. This dimension reflects an organization’s ability to set a clear strategic vision, inspire teams, and lead change effectively in a dynamic environment. Strong leadership capability encourages an organizational culture that embraces continuous learning, agility, and innovation (Westerman et al., 2014; Westerman et al., 2019).

Leadership capability ensures that digital transformation is not just a technological shift but a strategic, organization-wide evolution.

Vision

Engagement

Governance

Technology leadership

AI-ready culture

Poll
Results

Assignment: The Digital Mastery Framework
In this assignment, you will evaluate how your organization, or an organization you are familiar with, balance digital capability with leadership capability.

You will find all assignment details in the virtual campus.

Skip to content
Home Menu
Previous
Next 3. What Is Different in the AI Era?
The rise of AI is reshaping industries, organizations, and leadership itself. Digital transformation is not just about adopting new technologies—it is about rethinking how businesses operate, how decisions are made, and how people and machines collaborate. This course explores the intersection of AI and leadership, focusing on what it takes to guide organizations through an era of rapid technological change.

At its core, this course is about leading technology-based transformation, not just understanding AI. While AI plays a central role, the focus extends beyond technical capabilities to the broader challenges of organizational capability, workforce adaptation, and value creation. AI is not just automating routine tasks—it is augmenting decision-making, generating creative solutions, and continuously evolving. This shift requires a new leadership mindset, one that embraces uncertainty, encourages trust in AI-driven systems, and ensures that technological advancements align with strategic goals.

In this course, we blend technology and management, covering key concepts such as digital twins, robotics, and AI applications within the context of leadership strategies for driving change. The discussion extends beyond implementation to address critical questions:

What are opportunities to improve customer experience, operations and other areas using AI?
How should organizations adapt their processes and cultures?
How does AI reshape the workforce?
What governance frameworks are needed to manage AI’s risks and opportunities?
A defining feature of AI-driven transformation is its impact on human-machine collaboration. AI increasingly supports complex decision-making and customer interactions, raising new ethical and operational considerations. Successful leadership in this space requires more than just technical understanding—it demands a deep engagement with the social, cultural, and strategic implications of AI adoption.

Ultimately, digital transformation in the AI era is about more than technology; it is about vision, adaptation, and the ability to lead through complexity. Strong leadership principles remain essential, but they must be applied in new ways to navigate the challenges of an AI-powered world. Effective leaders will not only embrace AI but also shape its role in creating more agile, innovative, and resilient organizations. In order to prepare leaders to meet these challenges, this course will explore key leadership skills for the AI era.

Driving Transformation, Not Just Implementing Technology
Developing a Clear and Engaging Vision
Engaging People and Overcoming Resistance
Establishing Governance for Progress, Not Just Protection
Building an AI-Ready Culture
Promoting Collaboration Between IT and Business Functions
By mastering these leadership skills, organizations can move beyond simply implementing AI and instead harness its potential to drive meaningful, sustainable change.

Skip to content
Home Menu
Previous
Next 4. Industry Case Studies
Organizations across industries are leveraging AI-driven transformation strategies to improve customer experiences, operational efficiency, and business models. By examining real-world case studies, we can better understand how different sectors apply AI and automation to drive innovation and competitive advantage.

This section will explore four key industries where digital transformation has had a profound impact:

Healthcare – The role of AI in personalized medicine, diagnostics, and operational efficiency
Finance – How AI enhances fraud detection, risk management, and customer personalization
Manufacturing – How an established company evolved from a fragmented operation to an AI-driven global enterprise
Mining – The application of AI-powered automation in resource extraction and sustainability efforts
Each case study illustrates how companies integrate AI technologies into their operations, reshape their workforce strategies, and redefine business models for long-term success.

Healthcare: AI-Powered Diagnostics and Personalized Medicine
The healthcare industry has rapidly embraced AI-driven diagnostics, personalized medicine, and hospital management systems to improve patient care, reduce costs, and enhance efficiency. AI-assisted diagnostic tools now analyze medical imaging (X-rays, MRIs, CT scans) with similar-or-better accuracy to human radiologists, enabling earlier disease detection and improved survival rates. AI-powered genomics analysis is also revolutionizing personalized medicine, tailoring treatments based on genetic data to enhance efficacy and minimize side effects (Mayo Clinic, 2025; World Economic Forum, 2025).

Finance: AI-Driven Fraud Detection and Personalized Banking
The financial sector has been an early adopter of AI-powered risk assessment, fraud detection, and customer personalization. AI-driven analytics now detect fraudulent transactions in real time, improve credit risk evaluation, and enhance customer experiences through predictive insights (Westerman et al., 2024). AI models have significantly improved payment validation, customer engagement, and financial security, making banking more efficient and tailored to individual needs (J.P. Morgan, 2023).

Banks such as JPMorgan Chase, Citi, and HSBC have leveraged AI to revolutionize fraud prevention, credit scoring, and banking automation, ensuring greater financial inclusion and operational efficiency (McKinsey & Company, 2024).

Manufacturing: AI-Driven Evolution and Coordination
Asian Paints, India’s largest paint manufacturer, has leveraged AI and automation technologies to lead multiple waves of digital transformation across its operations. Previously, its 13 regional units operated independently, leading to inefficiencies in manufacturing, logistics, and customer engagement. By implementing AI-driven automation, predictive analytics, and a centralized enterprise resource planning (ERP) system, the company optimized its supply chain, enhanced customer experience, and created a new business service that expand its business beyond product sales (Westerman et al., 2014).

Mining: AI-Powered Automation and Sustainability
The mining industry is leveraging AI-powered automation, predictive analytics, and sustainability-focused AI models to transform resource extraction, safety, and environmental management. Traditionally, mining operations involved high-risk manual labor, unpredictable resource yields, and significant environmental impact. AI-driven solutions are addressing these challenges by enhancing operational efficiency, reducing risks, and enabling sustainable mining practices (Bonnet & Westerman, 2020).

Companies like Rio Tinto and BHP are using autonomous drilling, AI-driven ore analysis, and machine learning models to optimize mineral extraction, improve worker safety, and minimize environmental damage (Rio Tinto, 2024; BHP, 2024). AI's role in predictive maintenance has significantly reduced equipment failures, improved production uptime, and enhanced operational continuity (BHP, 2024).

Skip to content
Home Menu
Previous
Next

1. The Role of AI in Business Transformation
   The rapid advancement of artificial intelligence (AI) is reshaping business strategy and operations across industries. However, the true catalyst for transformation is not AI itself, but how business leaders integrate it into decision-making, operations, and corporate culture (Westerman, 2023). The organizations that thrive in an AI-powered future will not be those that simply adopt AI technologies, but those that strategically apply them to enhance business value and manage organizational change effectively (Ramakrishnan, 2024b).

This module will explore how business leaders can leverage AI as a tool to drive transformation, rather than allowing technology to dictate the direction of their organizations. The focus is on understanding AI’s capabilities and limitations, differentiating between various AI models, and applying structured frameworks for evaluation and implementation.

AI as an Enabler, Not the Driver of Transformation
A common misconception in AI adoption is the belief that technology itself leads to business change. In reality, companies that successfully implement AI do so not because of the technology alone, but because of how business leaders integrate it into strategy, operations, and governance (Westerman, 2023). AI is a lever for innovation, but without structured decision-making, clear objectives, and a well-defined transformation roadmap, its potential remains untapped.

Key considerations for business leaders include:

Strategic alignment
Operational impact
Leadership readiness
How does AI support the organization’s long-term goals?
In what ways can AI-driven insights help identify new market opportunities or refine competitive positioning?
To illustrate this, companies such as JPMorgan Chase, Unilever, and McKinsey & Company have successfully embedded AI in their operations—not simply by adopting new tools, but by embedding AI into structured decision-making, employee training, and governance frameworks (Stackpole, 2024a). Additionally, the Fortune 50 AI Innovators list identifies industry leaders, such as Microsoft, OpenAI, and Salesforce, that are shifting from experimental AI use to enterprise-wide deployment, signaling a broader transformation trend (Kell, 2024).

Recommended Link
The Fortune 50 AI Innovators list identifies the companies at the forefront of AI adoption, highlighting how organizations such as Microsoft, OpenAI, and Salesforce are scaling AI initiatives beyond experimentation to enterprise-wide deployment, signaling a shift toward AI-driven business transformation (Kell, 2024).

From Hype to Impact: Moving Beyond Technological Obsession
Generative AI and large language models (LLMs) have fueled intense discussions about automation, efficiency, and productivity gains. Yet, many organizations rush into AI adoption without a clear understanding of its true value or the challenges of implementation (Ramakrishnan, 2024a).

To maximize impact, AI adoption must be approached with a leadership-first mindset, ensuring that:

AI initiatives are aligned with business goals, not just pursued for the sake of innovation.
AI-driven changes are integrated into corporate culture and decision-making.
Business leaders are prepared to address ethical, operational, and workforce implications.

Click on the images below to see how businesses have taken a leadership first mindset.

AI in Sales
AI Maturity
Business leaders must recognize that AI adoption is not just about upgrading technology—it is about redefining leadership itself. The future will not belong to organizations that simply use AI; it will belong to those that integrate AI into leadership strategies, business models, and corporate culture (Westerman et al., 2024). A structured approach to AI adoption will ensure that organizations are not just AI-enabled, but AI-empowered.

Skip to content
Home Menu
Previous
Next 2. Foundations of AI and LLMs
AI refers to the science of creating systems capable of performing tasks traditionally requiring human intelligence, such as problem-solving, decision-making, and creative generation. Since its formal inception at the Dartmouth Conference in 1956, AI has evolved through distinct phases, driven by technological advancements and expanding ambitions.

Image source: (iMedia, 2025)

Today, AI technologies like large language models (LLMs) are revolutionizing industries by enabling automation, enhancing decision-making, and driving innovation. Early AI systems focused on rule-based approaches, where human expertise was encoded into algorithms. Over time, these gave way to machine learning (ML), deep learning, and generative AI. Each step addressed limitations of its predecessor, building a foundation for today’s transformative AI technologies, including LLMs and multimodal systems.

Understanding AI: The Evolution from Rules to Learning Systems
AI has progressed through multiple evolutionary phases, shifting from explicitly programmed rule-based systems to self-learning models capable of adapting to new patterns in data. Early AI efforts focused on symbolic reasoning and expert systems, where human knowledge was codified into predefined rules (Russell & Norvig, 2021). However, as computational power and data availability expanded, ML and deep learning approaches emerged, enabling AI to improve performance autonomously through exposure to data (Goodfellow et al., 2016).

Traditional AI (Rules-Based Systems)
The first wave of AI systems relied heavily on predefined rules created by human experts. These systems used symbolic reasoning to map inputs to outputs, applying explicitly defined if-then statements to make decisions (Russell & Norvig, 2021). While these early AI models were effective for structured tasks, their rigidity and inability to handle uncertainty limited their practical applications (Buchanan, 2005).

Rule-based systems performed well when decision criteria were clear and could be explicitly encoded. However, as AI applications expanded, it became evident that manually programming rules for every possible scenario was inefficient and impractical (McCarthy, 2007).

Example: The Chair vs. Stool Classification Problem
Consider an AI system tasked with determining whether an object is a chair, stool, or neither based on its attributes. It can quickly become clear how a limited set of strict rules falls short in this task. However, accuracy can be continually improved through the addition of rules, as can be seen in the example below.

The Goal of AI
AI aims to replicate tasks that traditionally require human intelligence. In early AI systems, this meant asking experts how they performed specific tasks and translating this into explicit if-then rules. While effective in simple cases, this approach faced significant limitations, achieving success in only a few narrowly defined areas.

Next
(Ramakrishnan, 2024b)

This iterative, manual refinement process highlights the core limitation of rule-based AI:

Rules require constant manual updates, making the system difficult to scale.
It cannot generalize beyond predefined conditions, failing in complex, dynamic scenarios.
Strengths and Limitations of Rule-Based AI
Rule-based AI systems were among the earliest implementations of artificial intelligence, proving highly effective in structured, well-defined environments. Their reliance on explicitly programmed logic made them particularly useful in domains where expert knowledge could be translated into deterministic decision rules. However, as AI applications grew in complexity, rule-based systems struggled to scale, leading to the development of more advanced ML and deep learning approaches (Russell & Norvig, 2021).

Strengths

Transparency and explainability

Deterministic and reliable

Useful for well-defined problems
Limitations

Inflexibility and scalability issues

Fails with unstructured data

Unable to learn or generalize
Recommended Link
AI limitation is further explained by Polanyi’s Paradox—the concept that “we know more than we can tell” (Polanyi, 1966). Humans rely on tacit knowledge, which is difficult to codify into explicit rules, making rule-based AI ineffective at handling intuitive or ambiguous decisions.

Examples
In customer service chatbots, early rule-based models could only respond to predefined commands (e.g., “What are your store hours?”). However, if a customer asked a slightly reworded version of the same question, the system would not recognize it, demonstrating rule-based AI’s lack of flexibility (Ramakrishnan, 2024b).

IBM’s Deep Blue (1997), a rules-based chess program, could evaluate millions of possible moves per second but lacked any true understanding of strategy or adaptability beyond predefined moves (Campbell et al., 2002).

As AI applications expanded, ML and deep learning emerged to overcome the limitations of rule-based systems, enabling models to handle unstructured data, learn from experience, and make adaptive decisions. Business leaders must carefully assess where rule-based AI is still effective and where ML models offer superior performance, ensuring the right AI approach is chosen for each application.

The Shift to Machine Learning
Unlike rule-based AI, ML models​ learn from examples. They​ discover relationships and make predictions based on large datasets, allowing them to adapt to new and unexpected scenarios. This transition from rule-driven automation to data-driven learning marked a pivotal shift in AI’s evolution.

Transition from Rule-Based AI to Machine Learning
Rule-Based AI

Initial AI systems using fixed rules

Limitations of Rule-Based AI

Challenges and inefficiencies of rule-based systems

Introduction of ML

Emergence of adaptive ML models

Advantages of ML

Benefits of ML over rule-based AI

Example
Instead of manually defining rules to classify chairs or stools, an ML system analyzes thousands of labeled images, recognizing patterns that differentiate them (Ramakrishnan, 2024b). Similarly, in facial recognition, ML models generalize from large datasets, enabling them to identify faces even in varied or unexpected contexts.

How does ML differ from traditional rule-based AI, and why is it more adaptable? What are the key types of ML, and how do they apply to business challenges? How is predictive AI transforming industries, and what are the key risks and opportunities it presents? Understanding these questions provides insight into how ML models learn, where they are applied, and what business leaders should consider when implementing them.

By shifting from rigid programming to data-driven learning, ML overcame the limitations of rule-based AI, paving the way for scalable, adaptable systems capable of handling real-world complexity.

How Machine Learning Works
ML models learn from data, not from manually defined rules. By analyzing input-output relationships, they uncover patterns and correlations that allow them to make predictions and decisions without human intervention (Goodfellow et al., 2016).

Learns from data instead of explicit instructions

﻿Improves over time as it processes more examples

Adapts to new patterns without requiring manual updates

Example
Recommendation engines like Netflix and Amazon use ML models to analyze user behavior and predict content preferences based on historical interactions (Russell & Norvig, 2021).

Key Concepts in Machine Learning
ML represents a pivotal shift in AI by enabling systems to learn directly from data. At its core, ML relies on two fundamental principles: input and output.

Input: Features or variables describing a scenario (e.g., patient health data)
Output: The predicted result based on input data (e.g., "low risk" or "high risk")
How it works: ML models map input features to outputs, allowing automation in prediction and decision-making.
Example: In healthcare, ML models use patient health data (age, blood pressure, cholesterol levels) to predict cardiac risk (You et al., 2023).
Training: ML models are trained using labeled datasets, allowing them to learn patterns and improve accuracy.
Generalization: Once trained, the model applies its knowledge to new, unseen data, ensuring adaptability.
Example
An ML model trained on thousands of chair images learns to recognize chairs in different styles, even if it encounters a new design it has never seen before.

Supervised vs. Unsupervised Learning
As ML models became essential for business applications, researchers developed two primary training approaches: supervised learning and unsupervised learning. These methods differ in how they process data, extract patterns, and generate predictions, making them suitable for different use cases. Understanding these learning paradigms allows business leaders to assess which AI approach aligns with their strategic goals.

Supervised Learning Models
Supervised learning models are trained on labeled datasets, meaning that input-output pairs are explicitly provided during training. This allows the model to learn patterns and make accurate predictions based on past examples (Goodfellow et al., 2016).

Flip
How it works:

The model is fed training data, where each input has a known, correct output.
It learns to map inputs to outputs by identifying relationships in the data.
Once trained, the model applies what it learned to new, unseen data.
Examples:

Fraud detection in banking: A bank trains an AI model using historical transaction data, where past fraudulent and non-fraudulent transactions are labeled. The model then learns to detect suspicious patterns and flags potential fraud in real time (Mayer et al., 2025).
Medical diagnosis: An AI system trained on labeled X-ray images learns to identify pneumonia cases, improving diagnostic accuracy in hospitals (Goodfellow et al., 2016).
Flip
Unsupervised Learning Models
Unsupervised learning models analyze data without predefined labels. Instead of making direct predictions, these models identify hidden structures, similarities, and clusters within data.

Flip
How it works:

The model is given raw, unlabeled data.
It detects patterns and relationships, grouping similar data points together.
The results help business leaders discover insights that were not explicitly defined.
Example:

Customer segmentation in marketing: Retailers use unsupervised learning to analyze purchase behavior and create targeted customer segments.
Anomaly detection in cybersecurity: AI monitors network traffic to detect unusual behavior, identifying potential cyber threats (Russell & Norvig, 2021).
Flip
Recommended Video
IBM explains the difference between supervised and unsupervised ML.

Supervised vs. Unsupervised Learning
Logical Transition to Deep Learning
While supervised and unsupervised learning have transformed AI applications, they still face limitations when dealing with highly complex, unstructured data (e.g., images, speech, and natural language). Deep learning was developed to overcome these challenges by using multi-layered neural networks capable of extracting features directly from raw data (Goodfellow et al., 2016).

Traditional ML struggles with image recognition because it requires manual feature selection (e.g., identifying edges, shapes).
Deep learning automates this process, learning features directly from images, leading to breakthroughs in fields like facial recognition and autonomous driving.
Deep Learning: Handling Unstructured Data
As ML models advanced, they encountered a significant limitation: structured data dependency. While supervised and unsupervised learning excel at analyzing tabular, labeled datasets, real-world information is often unstructured, existing in the form of images, videos, audio, and natural language. Deep learning emerged as a solution by leveraging multi-layered artificial neural networks capable of extracting patterns directly from raw data, reducing reliance on manual feature engineering.

How Deep Learning Works
Unlike traditional ML models that rely on manual feature extraction, deep learning utilizes artificial neural networks inspired by the human brain. These networks consist of multiple layers of neurons, each responsible for identifying different levels of abstraction in the data (Goodfellow et al., 2016).

Processes unstructured data (text, images, speech) without predefined labels
Automatically extracts features from raw input data
Improves accuracy as more data is processed
Examples:

Facial recognition: Deep learning models analyze thousands of facial images, learning to recognize key features such as eye positioning, jaw structure, and skin texture (Russell & Norvig, 2021).
Autonomous vehicles: AI-powered self-driving systems process real-time sensor data, identifying objects, road signs, and obstacles (Mayer et al., 2025).
Deep Learning vs. Traditional Machine Learning
Deep Learning

Feature

Unstructured (images, text, audio)

Data type

Automatically learns from raw data

Feature selection

Can model highly complex relationships

Complexity

Image recognition, speech processing

Example

Deep learning can autonomously learn intricate fraud patterns, identifying subtle behavioral anomalies.

Traditional Machine Learning

Feature

Structured (tables, numerical)

Data type

Requires manual input

Feature selection

Limited to predefined rules

Complexity

Spam filters, fraud detection

Example

Traditional ML models require explicitly defined features to detect fraudulent credit card transactions.

Key Applications of Deep Learning
Deep learning has significantly advanced AI’s ability to process complex, unstructured data, leading to groundbreaking applications across various industries. One of its most impactful uses is in image recognition, where AI models analyze medical scans, facial images, and manufacturing processes to detect patterns and anomalies. In healthcare, for example, deep learning models can examine X-ray scans to identify pneumonia, achieving diagnostic accuracy comparable to experienced radiologists (Goodfellow et al., 2016). Similarly, in quality control for manufacturing, AI-powered vision systems detect product defects and irregularities, improving production efficiency.

Another key area is natural language processing, where deep learning enables AI to understand and analyze human language. This capability supports chatbots, sentiment analysis, and real-time translation, allowing businesses to automate customer interactions and gain insights from textual data.

Deep learning is also foundational to speech recognition and autonomous systems, powering voice assistants, self-driving vehicles, and robotics. AI-driven speech recognition systems facilitate hands-free interactions in smart devices, while self-driving technologies process sensor data and traffic patterns to make real-time driving decisions. Tesla’s AI-powered autonomous vehicles rely on deep learning to interpret road conditions and navigate safely, showcasing AI’s ability to integrate visual and contextual information for real-world decision-making (Mayer et al., 2025).

Transition to GenAI
While deep learning transformed AI’s capacity to analyze unstructured data, it remained limited to recognizing and classifying existing patterns. This constraint led to the development of generative AI (GenAI), which enables AI models to create entirely new content and synthesize human-like text, images, and designs.

For example, traditional deep learning models can identify objects within an image, but GenAI can generate entirely new images based on learned styles, such as AI-generated artwork or synthetic voices. This ability to go beyond recognition and into creation represents the next major evolution in artificial intelligence, setting the stage for advanced applications in content generation, automation, and decision-making.

Activity
Answer the following questions and see your peers’ responses.

Results:

Generative AI and Large Language Models
GenAI represents a paradigm shift in artificial intelligence, enabling models to generate new content rather than simply analyzing or classifying existing data. Unlike traditional deep learning models, which focus on recognizing patterns within structured inputs, GenAI can create text, images, music, and even code by learning from vast amounts of existing data.

At the core of this breakthrough is the transformer model by Google in 2017, a deep learning architecture that allows AI systems to process and generate human-like content with unprecedented accuracy and coherence (Vaswani et al., 2017). Transformers power large language models (LLMs) such as GPT-4, Claude, and Gemini, making them the foundation of today’s most advanced AI systems.

The Role of Transformer Models in GenAI
Traditional neural networks struggled with long-range dependencies in text and sequences. The introduction of transformers addressed this by utilizing a mechanism called self-attention, which allows AI models to weigh the importance of ​all the ​different words and elements within a sequence​. Furthermore, the self-attention operation can be executed efficiently in parallel rather than sequentially. ​This advancement led to:

Improved context awareness
Scalability and efficiency
Parallel processing
Example
Models understand relationships between words, phrases, and sentences more effectively than previous architectures.

Recommended Reading
"Attention Is All You Need" is a 2017 landmark research paper on ML authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence.

Why Transformers Revolutionized AI
Before transformers, AI models relied on RNNs and LSTM networks, which struggled with:

Retaining context over long sequences (e.g., difficulty in maintaining coherence in long documents)
Slow training times due to sequential data processing
Challenges in handling multimodal inputs (text, images, audio)
Transformers solved these challenges by replacing recurrence with attention mechanisms, allowing AI systems to:

Predict and generate content with greater accuracy
Process large datasets efficiently using parallel computations
Integrate multiple data types, leading to multimodal AI applications (e.g., AI that understands both images and text)
Example
DALL·E 2, a GenAI system for image synthesis, uses transformers to generate realistic images from textual descriptions, demonstrating the power of cross-modal AI processing (OpenAI, 2023).

The advent of transformers marked a pivotal breakthrough in artificial intelligence. By replacing the sequential limitations of RNNs and LSTMs with powerful attention mechanisms, transformers not only enhanced the precision and speed of processing large, complex datasets but also enabled the generation of novel and contextually rich outputs. This revolutionary shift has paved the way for the diverse, multimodal generative AI tools available today, fundamentally transforming the landscape of creative and intelligent systems.

Capabilities and Limitations of LLMs
LLMs represent a significant leap in AI capabilities, enabling systems to generate human-like text, summarize complex information, translate languages, and even write code. These models, such as GPT-4, Claude, and Gemini, rely on transformer architectures to understand context, predict the most likely next word in a sentence, and generate coherent, contextually relevant responses.

However, despite their advancements, LLMs also have their limitations and present risks that business leaders must consider when integrating AI into their workflows.

Capabilities of LLMs

Natural language understanding and generation

Multimodal processing

Code generation and automation

Data analysis and decision support

Limitations and Risks of LLMs

Hallucinations and misinformation

Bias and ethical concerns

​“Erratic” reasoning ability

Computational costs and environmental impact

Predictive AI to GenAI
AI techniques like ML and deep learning have till recently been used for predictive tasks, leveraging historical data to identify patterns, forecast trends, and optimize decision-making, making it invaluable in industries such as finance, healthcare, and supply chain management. However, despite its capabilities, such "predictive AI" could not generate new content or expand beyond what it has learned (Mayer et al., 2025).

Generative AI marks the next evolution in artificial intelligence, shifting from pattern recognition to content creation. Instead of merely analyzing and forecasting, generative models synthesize entirely new text, images, videos, and designs based on patterns learned from massive datasets. This transition redefines how AI interacts with information, offering businesses new possibilities in automation, personalization, and innovation (OpenAI, 2023).

From Analyzing Data to Creating New Content
Predictive AI systems operate by detecting statistical correlations within structured datasets. They excel at making informed guesses about future outcomes based on past trends but lack the ability to generate original ideas or content. Generative AI, powered by transformer neural networks, builds upon this foundation by learning the underlying structure of data and using it to create entirely new material (Vaswani et al., 2017). This ability to produce human-like content allows businesses to automate creative and strategic functions, reducing costs and increasing efficiency.

Predictive AI Model
Generative AI Model
Key Drivers of the Shift to GenAI

The rise of GenAI is fueled by advancements in transformer models, increased computing power, growing demand for personalized automation, and the expansion of multimodal AI.

Breakthroughs in transformer models

Computational power and sustainability concerns

Demand for personalized automation

Expansion of multimodal AI

Collectively, these factors are pushing GenAI beyond predictive analytics into autonomous content creation and decision-making. Organizations must navigate computational costs, sustainability issues, and ethical concerns—topics explored in later sections.

Activity
GenAI and LLMs like ChatGPT, Claude, and Gemini are transforming industries by automating content creation, enhancing decision-making, and personalizing customer interactions. However, they also present challenges related to bias, misinformation, and operational risks.

If you were advising your board or executive team on AI adoption, what key factors would you highlight to balance risk and opportunity?

Add your response to the discussion board below.

To create a pin, click on the ""+"" button in the bottom-right corner. Type your answer, click ""Publish"" and reposition the pin as needed. You can change the color and edit your pin by clicking on the menu (three dots) on the right side of your pin.

Important note: The following interactive element can be challenging to view or interact with on smaller handheld mobile devices. It is recommended to use a desktop, laptop, or tablet to ensure full accessibility.

Forum: Evaluating Risks and Opportunities
Review the responses to the Padlet activity above. Share your thoughts on your peers' responses and approaches to AI adoption.

You will find all forum details in the virtual campus.

Skip to content
Home Menu
Previous
Next 3. Implementation Strategies and Challenges

Identifying the Right AI Tool for the Right Task
As generative AI (GenAI) becomes increasingly integrated into business operations, organizations must navigate the complexities of choosing the right AI model for the right task. While AI offers significant advantages in automation, decision support, and content generation, not all AI models are suited for every application. Business leaders must evaluate whether a task requires predictive analytics, deep learning capabilities, or generative AI solutions, ensuring that AI investments align with strategic goals, feasibility, and return on investment (Mayer et al., 2025).

Selecting the right AI tool involves assessing the complexity of the task, the type of data available, and the level of interpretability required. For example, a financial services firm implementing AI must determine whether predictive AI (for fraud detection), deep learning (for risk modeling), or GenAI (for automated report writing) best serves their business objectives (OpenAI, 2023). Each AI model provides unique capabilities, and choosing the appropriate one ensures that AI-powered automation enhances rather than complicates business workflows.

Machine Learning vs. Deep Learning vs. GenAI
Selecting the appropriate AI model requires a structured approach based on data type, task complexity, and business objectives. Machine learning (ML), deep learning (DL), and GenAI each serve distinct functions, and choosing the right tool ensures efficiency, accuracy, and cost-effectiveness.

Adapted from: (Ramakrishnan, 2024b)

AI Model Selection

Is the data structured or unstructured?

What is the task objective?
Does the task involve real-time adaptation?

Is the output a classification or a creative generation?

Decision Framework Cheat Sheet
Imagine you are a leading international retail company, what AI adoption would you consider?
What type of model and for what purpose?
Flip
ML for predicting product demand and customer churn
DL for real-time image recognition in visual search features
GenAI for automatically creating product descriptions and marketing content (Mayer et al., 2025)
Flip
The GenAI Cost Equation

As organizations explore GenAI adoption, a structured approach is necessary to ensure feasibility, manage risks, and maximize value. The GenAI cost equation, originally developed by Ramakrishnan (2024a), serves as a decision-making framework to assess whether a specific task or workflow justifies GenAI implementation. This equation weighs the financial and operational trade-offs between traditional methods and AI-driven automation.

Adapted from: (Ramakrishnan, 2024a)

Key Components of the GenAI Cost Equation
The equation considers three core cost factors, in addition to the "cost of a miss," which refers to the potential risks and consequences of incorrect AI-generated outputs (Ramakrishnan, 2024a):

Adaptation costs

This is the effort required to tailor a GenAI model to meet task-specific accuracy requirements.
High-stakes industries (e.g., finance, healthcare) demand extensive fine-tuning to mitigate errors.
Example: E-commerce companies adapting LLMs for customer service require custom datasets and guardrails for brand consistency.
Usage costs

These are the direct expenses such as API fees, licensing costs, and cloud infrastructure usage.
Gartner (2024b) notes that token-based pricing models fluctuate as vendors refine cost structures.
Example: OpenAI’s GPT-4 API pricing has decreased significantly, dropping 83% for output tokens and 90% for input tokens, making LLM adoption more cost-effective.
Error detection and correction costs

These include the resources needed to identify, validate, and correct AI-generated errors.
Gartner (2024b) emphasizes that early adopters report 30% of GenAI projects fail due to cost overruns and risk mismanagement.
Example: "Human-in-the-loop" oversight is required for high-stakes applications like legal document review and medical diagnostics.
The "cost of a miss"

This refers to the potential consequences of AI failures, such as misinformation, compliance violations, or reputational damage.
Gartner (2024b) highlights that 42% of business leaders cite legal and regulatory risks as a primary concern for GenAI adoption.
Example: A misdiagnosis by an AI-powered healthcare chatbot could lead to severe patient harm.
Applying the GenAI Cost Equation: A Business Perspective
Gartner (2024b) classifies GenAI use cases into three strategic investment categories:

Defend
Extend
Upend
The GenAI cost equation ensures that businesses make informed decisions about AI adoption feasibility, costs, and risks (Ramakrishnan, 2024a). Recent insights reinforce the importance of continuous cost-benefit monitoring, noting that 55% of organizations plan to increase AI investment, but 30% abandon projects due to cost and complexity (Gartner, 2024c).

To navigate these challenges, business leaders must assess AI investments using structured frameworks, balancing efficiency, risk management, and long-term strategic value.

Integrating AI Tools in a Software Company: A GenAI Cost Equation Perspective
In the previous sections, we broke down the GenAI cost equation and explored how it shapes strategic decisions across various business scenarios. Now, let’s zoom in on a software company to see these ideas in action.

Imagine a software company is considering the integration of LLM tools to enhance coding tasks. Consider how each of the components of the GenAI cost equation would be relevant in this situation.

Adaptation Costs
Usage Costs
Error Detection and Correction Costs
The "Cost of a Miss"
Together, these components of the GenAI cost equation illustrate why LLM-based coding assistants are so appealing. Coding team leaders can see that LLM assistants offer substantial cost savings and productivity gains with minimal additional overhead, reinforcing their strategic value in modern software development.

Assignment: Applying the GenAI Cost Equation
In this assignment, you will dive into the practical application of the GenAI cost equation to analyze a real-world business task.

You will find all assignment details in the virtual campus.

Skip to content
Home Menu
Previous
Next 4. Leadership Through the Realities of Deployment
Practical Applications of Generative AI in Business
As businesses increasingly integrate GenAI into their workflows, its applications in operations, marketing, customer service, and HR are transforming efficiency, personalization, and decision-making. Organizations in retail, healthcare, and finance are leveraging GenAI to automate complex tasks, enhance customer experiences, and drive operational agility.

GenAI in Business Operations
GenAI is reshaping supply chain management, logistics, and inventory forecasting by automating repetitive tasks and enhancing predictive decision-making.

Retail and supply chain

Healthcare operations

Marketing and advertising

AI-Driven Marketing and Customer Engagement
GenAI is revolutionizing marketing through content automation, hyper-personalization, and predictive consumer behavior analytics.

Retail and e-commerce

Brand personalization and AI-powered advertising

AI in Customer Service and Human Resources
Generative AI is enhancing customer service automation and streamlining HR processes, reducing response times and increasing efficiency.

AI-powered customer support chatbots

AI in talent acquisition and workforce management

AI-Powered Decision Support Systems for Business Leaders
In addition to operations, marketing, customer service, and HR, the full potential of GenAI can even extend into executive decision-making, where AI enhances strategic insights for business leaders. Executives can harness generative AI for strategic advantage by implementing the following approaches:

Enhance decision-making with AI-driven insights

Automate complex reporting and data analysis

Balance AI insights with human judgment

Strengthen financial and risk management strategies

Optimize executive workflows with AI copilots
Managing Risks and Ethical Considerations in AI Deployment
The adoption of GenAI presents significant ethical and operational risks that organizations must address. As AI systems become deeply embedded in decision-making and automation, concerns regarding bias, fairness, accountability, security, and compliance have intensified. Research has shown that mentions of AI in global legislative proceedings have increased 6.5 times since 2016, reflecting growing regulatory attention (OneTrust, 2024).

Unregulated AI deployments have already led to misinformation, bias amplification, and security vulnerabilities (Ramakrishnan, 2024b). High-profile incidents, such as AI-powered hiring systems discriminating against women and LLM-generated misinformation influencing political discourse, underscore the urgent need for AI governance frameworks. Without proactive intervention, organizations deploying AI risk facing legal liabilities, financial penalties, and reputational damage.

Business leaders must carefully evaluate how AI models are trained, deployed, and monitored to ensure they align with ethical standards, regulatory requirements, and corporate values. Issues such as algorithmic bias, privacy breaches, misinformation, and liability concerns require proactive oversight. Companies that fail to implement robust AI governance frameworks risk compliance violations and long-term strategic instability (OneTrust, 2024).

Bias, Fairness, and Accountability
GenAI models are trained on large-scale datasets that reflect historical biases, making them susceptible to producing discriminatory outputs if not properly managed. Without intervention, AI-driven decision-making can reinforce existing inequalities, leading to unfair hiring practices, credit scoring disparities, and biased judicial outcomes.

Healthcare

Image generation

AI governance and ethical AI audits

Ensuring fairness in AI-driven decision-making requires a multi-layered approach, including algorithmic transparency, bias mitigation strategies, and regulatory compliance.

Data Privacy and Security Concerns in AI Implementation
LLMs often require vast amounts of training data, raising questions about data ownership, consent, and exposure to security breaches.

Data protection risks in GenAI

AI and personally identifiable information concerns

Best practices for secure AI deployment

Regulatory Considerations and Compliance Best Practices
Governments worldwide are implementing AI governance frameworks to regulate fairness, accountability, and transparency. Companies deploying AI in finance, healthcare, hiring, and biometric applications must comply with emerging laws to avoid legal and reputational risks (KPMG, 2024).

The EU AI Act (2024) is currently the most comprehensive AI regulation, setting a strict risk-based compliance framework for companies operating within or interacting with the European market. It mandates auditability, transparency, and real-time monitoring for high-risk AI systems, ensuring that AI-driven credit scoring, hiring, and facial recognition technologies meet ethical standards (European Parliament, 2025).

In contrast, the United States does not yet have a federal AI law, and the Office of Science and Technology Policy (OSTP) AI Bill of Rights (2022) is not legally binding. It serves as a set of voluntary principles rather than an enforceable regulation, emphasizing AI fairness, privacy, and transparency (OSTP, 2022). AI regulation in the United States remains sector-specific, with the Health Insurance Portability and Accountability Act (HIPAA) governing AI in healthcare, the Securities and Exchange Commission overseeing financial AI applications, and the Federal Trade Commission monitoring AI consumer protections. However, U.S. regulators are developing new AI risk management frameworks, including the National Institute of Standards and Technology’s AI Risk Management Framework (AI RMF), to guide businesses in responsible AI deployment (KPMG, 2024).

Recommended Reading
China’s Generative AI Guidelines (2023) take a centralized, state-controlled approach, requiring AI models to undergo government review before deployment. This impacts global AI providers, requiring localized compliance adjustments for models deployed in China.

Read more about U.S. AI policy from the Biden administration in The White House AI Bill of Rights. Additionally, the National Institute of Standards and Technology (NIST) has its own AI guidelines, which can be found in the NIST AI Risk Management Framework. The Federal Trade Commission AI Compliance Resources detail how AI applications are monitored within consumer protection laws. These materials offer a broader perspective on how AI regulation is developing in the United States, particularly in comparison to structured global frameworks like the EU AI Act.

By integrating these compliance strategies, organizations can minimize regulatory risks, enhance AI accountability, and ensure ethical AI deployment on a global scale.

Establish AI governance teams to oversee compliance strategies across jurisdictions.

Conduct AI impact assessments to identify legal, ethical, and bias risks.

Monitor evolving AI regulations globally to ensure continuous compliance.

Skip to content
Home Menu
Previous
Next 5. Future Implications of Generative AI
GenAI is accelerating industry transformation, shifting competitive dynamics and redefining how businesses operate, innovate, and scale. Organizations that effectively deploy AI-driven strategies are gaining unprecedented operational efficiencies, market insights, and automation capabilities, forcing companies across sectors to adapt or risk obsolescence (Mayer et al., 2025).

The competitive edge in the AI era is no longer about technology adoption alone—it requires strategic integration, workforce alignment, and business model innovation. Companies that fail to develop AI-native strategies risk falling behind competitors that leverage AI to streamline operations, enhance customer experiences, and unlock new revenue streams (Stackpole, 2024a).

The Future of AI in Business Strategy
Business Model Transformation
Companies are restructuring their value chains and operational models around AI, using it to drive innovation, reduce costs, and optimize decision-making. Businesses that successfully incorporate AI not only enhance existing services but also create entirely new business models, increasing market adaptability and resilience (Gartner, 2024c).

Sysco’s AI-Driven Supply Chain Optimization
Adobe’s AI-Powered Creative Suite
Industry Disruption
AI is disrupting traditional industry structures, leading to hyper-automation, real-time market adaptation, and AI-driven decision ecosystems. Early adopters are setting new performance benchmarks, pressuring competitors to either accelerate AI implementation or face diminished market relevance (Stackpole, 2024a).

Société Générale’s AI-Driven Financial Services
AT&T’s AI-Powered Customer Service
The Race for AI Leadership
Organizations that fail to develop AI-specific strategies risk being left behind by AI-native competitors. The shift toward AI-first business models is accelerating, requiring companies to rethink how they generate value, engage with customers, and allocate resources (Gartner, 2024b).

AI-powered firms operate with greater agility, faster iteration cycles, and lower operational costs, outpacing traditional businesses in product innovation, customer service, and data-driven decision-making. The ability to leverage AI for continuous optimization and personalized engagement is emerging as a core driver of sustained competitive advantage (Mayer et al., 2025).

Example
Microsoft has integrated AI-driven automation and cybersecurity solutions into Azure AI, supporting over 60,000 enterprises globally. By embedding AI copilots into its software ecosystem, Microsoft has expanded its cloud-based AI offerings, ensuring long-term competitiveness in the enterprise technology market.

New Skills and Strategic Thinking
The rapid integration of AI across industries requires a new leadership paradigm, where executives must balance technological fluency, strategic foresight, and organizational adaptability. Traditional management approaches that rely solely on intuition and experience are being reshaped by AI-driven decision-making, predictive analytics, and automation. Leaders must now develop a digital-first mindset, ensuring AI is leveraged not only for operational efficiency but also for long-term competitive advantage (Stackpole, 2024a).

The digital mastery framework developed by Dr. George Westerman and colleagues at the MIT Sloan School of Management provides a structured lens for understanding how organizations evolve in the digital era. This framework, previously covered in Module 1, categorizes organizations based on digital capabilities and leadership maturity (Westerman et al., 2024). Businesses striving to become digital masters must ensure their leaders develop AI-literate competencies, ethical oversight mechanisms, and workforce transformation strategies to fully capitalize on AI’s potential.

Intuition-based to AI-enhanced decision-making

Strategic thinking in an AI-first organization

AI-driven talent management and workforce transformation

Executive AI literacy and ethical AI oversight

Emerging AI Trends and Next-Generation Innovations
Advancements in AI are pushing the boundaries of automation, decision-making, and computing power, leading to a new wave of multimodal AI, autonomous AI agents, and the integration of quantum computing into AI systems. These next-generation technologies offer greater efficiency, adaptability, and problem-solving capabilities, but also introduce challenges related to governance, ethical oversight, and technological scalability (Mayer et al., 2025).

Multimodal AI: Expanding beyond text-based LLMs

Autonomous AI agents and self-learning systems

Quantum AI

Assistive to autonomous AI

Activity
You are the CEO of a leading retail company facing competition from AI-native firms that automate supply chains, marketing, and customer service. Your board asks:

How should we integrate AI into our operations to stay competitive?
What risks should we consider?
What leadership skills are needed to navigate this transformation?
Propose a leadership strategy outlining:

One key AI-driven transformation they would prioritize
One major challenge or risk AI presents
How leadership should evolve to manage AI-first organizations
Add your response to the Padlet below.

To create a pin, click on the ""+"" button in the bottom-right corner. Type your answer, click ""Publish"" and reposition the pin as needed. You can change the color and edit your pin by clicking on the menu (three dots) on the right side of your pin.

Important note: The following interactive element can be challenging to view or interact with on smaller handheld mobile devices. It is recommended to use a desktop, laptop, or tablet to ensure full accessibility.

Course Project Part 2: AI Tools in Digital Transformation
In order to address the problem you have identified, you will now turn your attention to potential AI tools. For this part of the course project, you will review and evaluate various AI tools utilizing the perspectives presented in this module.

You will find all project details in the virtual campus.

# Module 3

Skip to content
Home Menu
Previous
Next

1. The Role of Autonomous Systems in Work: Automation and Augmentation
   Autonomous systems are reshaping industries by automating tasks that were once exclusively human-driven. These systems can range from robotic process automation (RPA) in finance to artificial-intelligence-powered medical diagnostics and self-driving vehicles in logistics. As business leaders, understanding how these systems impact workflows is critical to making informed decisions about artificial intelligence (AI) adoption.

Much of the discussion surrounding the development of AI over the past twenty years has been focused on the idea of automation—the ability to delegate tasks previously performed by humans to machines. While automation has been around for centuries (see below), AI has enabled more sophisticated, flexible, and adaptable systems. These systems have the potential to transform industries by improving efficiency, reducing errors, and freeing human workers to focus on more strategic or creative tasks.​​​

​A Brief History of Automation
However, automation is not a one-size-fits-all solution. Some tasks can be completely automated, while others require human oversight or collaboration with machines. In this section, we will explore different types of automation, reflect on personal experiences with automation, and distinguish between automation and augmentation in the workplace.

Reflect
How would you define automation?
Are there different types of automation?
Are there limits to automation?
What is required to automate a task?
Understanding Automation and Automation Technologies
Take a moment to consider how you would define automation. Add your definition to the board below.

To create a pin, click on the ""+"" button in the bottom-right corner. Type your answer, click ""Publish"" and reposition the pin as needed. You can change the color and edit your pin by clicking on the menu (three dots) on the right side of your pin.

Important note: The following interactive element can be challenging to view or interact with on smaller handheld mobile devices. It is recommended to use a desktop, laptop, or tablet to ensure full accessibility.

Workforce Dynamics and Automation
At its core, automation refers to the use of technology, either software or hardware, to perform tasks with minimal human intervention, but its impact extends far beyond simple mechanization. From the early days of industrial machinery revolutionizing manufacturing to the rise of AI shaping complex decision-making, automation has continuously transformed industries and redefined the nature of work. It enhances productivity, improves efficiency, and reshapes economic structures. However, its broader implications—both positive and challenging—depend on how it is designed, implemented, and integrated into society.

Automation can be broadly categorized into two types: deterministic automation and cognitive automation, each shaping human work in distinct ways.

Deterministic Automation
Cognitive Automation
While automation presents clear benefits, it also raises concerns about its impact on employment and workforce dynamics. One perspective sees automation as a collaborative force that enhances human productivity, enabling workers to focus on more strategic and meaningful tasks (Bonnet & Westerman, 2020). However, another viewpoint highlights its adverse potential, particularly the risk of job displacement and the widening of skill gaps (Wang & Lu, 2025). As machines take on more complex functions, there is an increasing need for workforce adaptation through reskilling and continuous learning.

​​History has shown that automation, while displacing some jobs, often creates new roles that require different skill sets​﻿​. The challenge lies in ensuring that workers have the necessary training and opportunities to transition into these emerging roles. Whether through deterministic automation that streamlines operations or cognitive automation that enhances decision-making, the key to successful integration lies in balancing efficiency with human adaptability, ensuring that technology serves as a tool for progress rather than exclusion.​​​

Recommended Readings
The following sources provide further insight on the history of automation:

The Rise of the Robots: Technology expert Martin Ford systematically outlines the achievements of artificial intelligence and uses a wealth of economic data to illustrate the terrifying societal implications. The robots are coming, and we have to decide—now—whether the future will bring prosperity or catastrophe.
The Future of the Professions: This book raises important policy questions—particularly around employment, as it envisions a new generation of "open-collared workers," and around control of online expertise, warning of emerging "gatekeepers"—in an era where machines will surpass humans in most tasks.
﻿The Second Machine Age: Erik Brynjolfsson and Andrew McAfee describe how humans will have to keep pace with machines in order to become prosperous in the future. They identify strategies and policies for businesses and individuals to use to combine digital processing power with human ingenuity.
What is the Future?: John Urry explores the complex, contested nature of the future, emphasizing that it is shaped by uncertainty, competing interests, and unpredictable forces. Drawing from fields like philosophy, literature, science, and urban studies, he examines how societies imagine, model, and perform futures, with case studies on 3D printing, urban mobility, and climate change.
With concerns of job displacement and the necessity of upskilling in mind, from a managerial standpoint, there are five aspects that must be taken into consideration when planning to automate a task or process.

Task type

Team

Budget

Organizational support

Maintenance

From a more technical perspective, the effectiveness of automation relies on a seamless integration of three key components:

Sensors​ and Sources of Data​
Gather real-time data (e.g., cameras, LiDAR, ultrasound probes)
Time logs, human generated text, logs, etc.
Processing Units
Learned or designed algorithms
AI-driven decision-making algorithms
​​​Action (By Human or Machine​​)
​​​The human in the loop performs an action.​​
Actuators: Physical components that perform tasks based on data (e.g., robotic arms, self-driving car steering systems)
Deterministic vs. Cognitive Automation Cheat Sheet
Reflect
Return to the reflection questions from above. How would you answer them now?

How would you define automation?
Are there different types of automation?
Are there limits to automation?
What is required to automate a task?
The Data-to-Decision Loop

Experience With Automation
We all likely have some experience with automation already in our everyday lives. Whether it is using voice assistants like Alexa and Siri, relying on automated customer service chatbots, or simply a thermostat, or clothes dryer with moister sensing for controlled drying, automation is embedded in modern life.

Automation extends beyond personal use—it plays a critical role in the workplace. Businesses use automation to streamline operations, reduce costs, and enhance decision-making. Manufacturing relies on robotic assembly lines, healthcare benefits from AI-powered diagnostic tools, and finance integrates automation in fraud detection and algorithmic trading.

Reflect
What are some automated tools or systems you interact with daily?
How has automation changed the way you work or engage with businesses?
Automation and Augmentation
In this module, we focus on automation in the workplace and explore the spectrum between full automation and human augmentation. While automation refers to machines performing tasks independently, augmentation refers to technology working alongside humans to enhance their capabilities (Holzinger et al., 2022). A key challenge for business leaders is determining where a given task or process should fall along this spectrum—whether to fully automate it, maintain human involvement and to augment human physical capabilities (e.g., collaborative robots or cobots, which we will explore later in the module) and/or AI-enhanced decision-making (e.g., computer-aided diagnostics).

Automation Case Study: The ATM
One very successful (and pervasive) example of automation is the Automated Teller Machine (ATM). Introduced in the late 1960s, ATMs revolutionized banking by automating simple transactions like cash withdrawals and deposits, allowing banks to extend services beyond traditional business hours. (IBM, n.d.)

The widespread adoption of ATMs illustrates key aspects of successful automation:

Reliability – The system must consistently perform as expected.
User acceptance – Customers initially resisted ATMs but gradually embraced them due to their convenience.
Security and trust – Banking automation required encryption and fraud prevention measures to gain public confidence (IBM, n.d.).
Industry transformation – ATMs reduced the need for bank tellers but also created new roles in maintenance, security, and network management (NCR Atleos, 2021).
Understanding the evolution and impact of ATMs helps frame discussions around modern AI-driven automation, demonstrating how machines can take over repetitive, structured tasks while maintaining human oversight where needed. ATMs successfully automated routine banking transactions such as cash withdrawals, deposits, and balance inquiries, reducing the reliance on human tellers for these services (NCR Atleos, 2021). This shift not only improved efficiency and accessibility but also reshaped the workforce by reallocating human workers to more complex customer service roles and financial advising.

The key lesson from ATM automation is that successful automation requires reliability, security, and user trust—factors that remain central to AI-driven automation today. Just as ATMs transformed banking while maintaining human involvement in more nuanced tasks, modern AI automation is focused on optimizing efficiency and shifting human roles toward strategic decision-making (Holzinger et al., 2022). Recognizing this historical precedent helps leaders develop automation strategies that balance machine efficiency with human expertise, ensuring seamless human-AI collaboration rather than workforce displacement.

Augmentation Case Study: Laser Cutting
In the manufacturing sector, the reliability and efficiency of machinery are critical to maintaining productivity and minimizing operational costs. Laser-cutting machines, used for precision cutting of materials such as metal, plastic, and wood, are integral to industries like automotive, aerospace, and consumer electronics. These machines operate at high precision, but when malfunctions occur, the downtime required to identify and fix issues can be substantial, leading to delays and increased production costs. In response to these challenges, innovative technologies such as augmented reality (AR) (which “projects” digital images and graphics into the eyes as they perceive the physical environment)﻿ and AI are being integrated into maintenance and troubleshooting processes to enhance real-time decision-making and reduce downtime.

In this case study, a team of researchers explored the combined use of AR glasses and AI to address common issues that arise in laser-cutting machines. The goal was to create a system that allows technicians to troubleshoot and resolve machine issues in real time, without the need for prolonged stoppages or unnecessary manual inspections. The system provides technicians with an innovative, efficient approach to machine maintenance and diagnostics.

AR glasses serve as an interface that overlays critical information on the technician's field of view, enabling them to interact with the machine and receive step-by-step guidance without diverting attention from the task at hand. Through these glasses, technicians can see visual markers and data points that highlight areas of concern, such as abnormal readings, misalignments, or wear and tear in machine components. This real-time visual assistance is further enhanced by AI, which analyzes both visual data captured by the AR glasses and audio data from the machine’s operations.

AI algorithms process this data to identify potential problems, drawing on machine learning models that have been trained on a vast dataset of known machine faults, operational behaviors, and maintenance records. The AI continuously compares real-time inputs from the machine to historical data, identifying discrepancies and offering actionable recommendations to technicians. For instance, if the AI detects an anomaly in the laser’s power output or an irregular sound pattern that may indicate a mechanical fault, it can alert the technician and suggest corrective actions, such as adjusting settings, replacing specific components, or performing routine maintenance tasks.

Key Benefits and Outcomes

Reduced downtime

Increased accuracy and precision

Improved knowledge sharing and training

Cost efficiency

The integration of AR glasses and AI in real-time troubleshooting of laser-cutting machines represents a major advancement in human-machine collaboration. Rather than replacing workers, this technology enhances their ability to diagnose and resolve issues more efficiently. By overlaying real-time data, AI-driven insights, and step-by-step guidance onto the technician’s field of view, AR glasses augment human expertise, reducing reliance on trial-and-error approaches.

This augmentation significantly reduces downtime and improves the precision of maintenance operations. Workers are no longer solely dependent on experience and intuition—AI assists them by identifying patterns, predicting failures, and suggesting optimized solutions. Additionally, this approach accelerates knowledge transfer, allowing less experienced technicians to perform complex troubleshooting tasks with greater confidence.

As this technology continues to evolve, its impact extends beyond maintenance to quality control, predictive analytics, and remote collaboration. This case study highlights how AI and AR technologies are revolutionizing industrial workflows, enabling smarter, more responsive, and more efficient human-AI collaboration.

Moreover, these advancements also generate new types of jobs, including the maintenance and support of AR devices and the development and continuous updating of standard operating procedures that integrate AI-driven tools.

The adoption of AR and AI technologies creates a new ecosystem of jobs that support, maintain, and optimize these tools. These emerging roles span technical, operational, and strategic domains, including:

AR/VR hardware technicians
AI systems integrators
Digital workflow designers
Industrial data analysts and model trainers
Standard operating procedure developers and maintainers
Remote support specialists
Change management and training specialists
Responsible for the maintenance, calibration, and repair of AR headsets and related hardware. These roles ensure the physical devices are always operational and ergonomically optimized for industrial environments.

Key Applications of Autonomous Systems
The adoption and integration of autonomous systems is transforming industries by enhancing efficiency, accuracy, and decision-making through AI-driven automation and augmentation. Below are key industry use cases demonstrating how these technologies are being employed in various sectors.

Healthcare
Manufacturing
Finance
Retail and Customer Service
Transportation and Logistics
By integrating AI-driven automation into these industries, businesses can achieve higher efficiency, better decision-making, and improved customer experiences, positioning autonomous systems as a cornerstone of future innovation. Therefore, it is essential for leaders to understand the fundamental nature of human-machine collaboration to best integrate and utilize these tools.

Reflect
Which of the use cases above demonstrate deterministic automation and which demonstrate cognitive automation? Which automate a task and which augment a task?

Skip to content
Home Menu
Previous
Next 2. Human-Machine Collaboration
The narrative surrounding the future of work is undergoing a significant transformation. While early discussions were often dominated by concerns about automation leading to widespread job displacement, the current discourse is focused on a more nuanced and optimistic view: the transformative potential of human-machine collaboration. Rather than viewing AI as a force that replaces human workers, the emerging consensus is that AI can serve as a powerful tool to enhance human capabilities (Bonnet & Westerman, 2020). This collaboration between humans and machines is not about redundancy, but about amplifying strengths, employing unique human traits such as creativity, empathy, and critical thinking, while capitalizing on the computational power, speed, and precision of AI.

At its core, human-machine collaboration offers a synergistic partnership that redefines what is possible in the workplace. By effectively combining human insight with machine intelligence, organizations can achieve unprecedented levels of performance, adapt to complex challenges with agility, and open up new frontiers for creativity and problem-solving (Faccio et al., 2022; Holzinger et al., 2022). This section will explore the evolving nature of this collaboration and the ways in which it is reshaping industries, work environments, and organizational structures.

Human-in-the-Loop
One essential structure of human-machine collaboration is to have a “human-in-the-loop.” Human-in-the-loop (HITL) systems integrate human judgment, oversight, and decision-making into automated or AI-driven processes. Unlike fully autonomous systems that operate without human intervention, HITL approaches ensure that humans remain actively engaged in monitoring, guiding, and refining AI-based decisions. This collaboration allows automation to enhance efficiency while preserving human expertise where it is most needed. (Emami et al., 2024)

There are three primary ways in which HITL is applied:

Human-in-the-Loop for Training AI
AI systems require vast amounts of labeled data for training. Human experts curate, annotate, and validate datasets to improve AI models, ensuring accuracy and reducing bias.

Human-in-the-Loop for Decision-Making
In complex or high-stakes environments—such as medical diagnostics, financial fraud detection, or autonomous driving—AI can suggest recommendations, but humans retain the authority to review and finalize decisions.

Human-in-the-Loop for Exception Handling
AI systems excel at handling routine cases, but may struggle with novel or ambiguous situations. Humans step in to resolve edge cases, ensuring that automation remains adaptable and reliable.

HITL frameworks offer a balance between automation and human oversight, enabling AI to function as an augmentative tool rather than a replacement for human expertise. By keeping humans engaged and in the loop, organizations can foster trust, improve system reliability, and ensure that automation aligns with ethical and business objectives.

Understanding Human-Machine Collaboration
The Role of AI and AT in Collaborating With Humans
AI and AT’s potential to enhance human capabilities goes far beyond the traditional notion of replacing jobs. Instead, AI can act as a powerful ally that optimizes workflows, elevates decision-making, and supports creativity, thereby transforming how work is performed and enhancing the value humans bring to their roles. The key idea here is that AI and AT complements human intelligence, allowing workers to focus on more strategic, creative, and high-value tasks, while AI handles the repetitive, data-intensive, or complex processes that might otherwise overwhelm human capacity.

Automating repetitive tasks
Assisting in decision-making with data-driven insights
Enhancing creativity and innovation
Augmenting human interaction and communication
Expanding access to expertise
One of AI’s most significant contributions is its ability to automate mundane tasks, thereby reducing errors and boosting overall efficiency. For instance, as the example of AI-driven chatbots mentioned on the previous page illustrates, routine inquiries can be handled seamlessly, allowing human staff to concentrate on more complex responsibilities. Similarly, tasks such as data entry and scheduling can be streamlined, echoing the benefits of automated systems already highlighted.

Role of Humans in Collaborating With AI and AT
While AI and automation play a crucial role in enhancing efficiency and decision-making, human expertise remains indispensable in human-machine collaboration. AI may process vast amounts of data, recognize patterns, and suggest optimal actions, but it is humans who bring contextual understanding, ethical reasoning, and adaptability to complex and dynamic environments. Several key contributions define the human role in these collaborations:

Contextual Decision-Making
AI can offer recommendations, but humans must evaluate those recommendations within the broader context of business goals, social dynamics, and ethical considerations.

Creativity and Problem-Solving
Unlike AI, which relies on past data, humans can think creatively, innovate, and develop novel solutions to emerging challenges.

Emotional Intelligence and Judgment
Many industries, such as healthcare and customer service, require human empathy and interpersonal skills that AI cannot replicate.

Adaptability and Learning
Humans can quickly adapt to new situations, interpret ambiguous data, and adjust strategies in ways that AI struggles with.

Oversight and Continuous Improvement
Human workers refine AI systems by providing feedback, adjusting parameters, and ensuring that AI-driven decisions align with company values and strategic objectives.

Effective human-machine collaboration is about harnessing AI’s computational power while maintaining human control and oversight. The most successful implementations ensure that AI enhances, rather than replaces, human decision-making, creating a symbiotic relationship between human intelligence and machine efficiency.

Case Study: Agriculture
In the agriculture sector, augmented reality (AR) is transforming the way farmers and agricultural workers interact with data, making them central decision-makers rather than passive recipients of automation (Holzinger et al., 2022). AR enhances human expertise by overlaying real-time environmental data, predictive analytics, and task-specific recommendations directly into the user’s field of vision. This augments decision-making rather than replacing human judgment.

Farmers use AR devices, such as AR glasses, to access information about soil conditions, weather patterns, and crop health. This enables them to make informed choices about irrigation, fertilization, and pest control, combining their deep agricultural knowledge with AI-driven insights. Unlike fully automated systems, where decisions are made without human input, AR systems reinforce the importance of human oversight by allowing farmers to interpret complex environmental variables and adjust strategies accordingly.

Example: Identifying and Responding to Disease
Example: Equipment Maintenance
A crucial aspect of this collaboration is the feedback loop between humans and AI. Farmers contribute on-the-ground observations and experiential knowledge back into the system, refining AI models over time. This iterative process ensures that AR solutions remain relevant, practical, and aligned with real-world agricultural challenges.

Reflect
Have you worked with an AI-powered tool before? How did it impact your workflow?
What tasks in your industry could benefit from human-AI collaboration?
Cobots in Human-Machine Collaboration
Collaborative robots, or cobots, are designed to work alongside humans, enhancing their capabilities rather than replacing them. Unlike traditional industrial robots that operate in isolated environments, cobots are engineered for safe, flexible, and adaptive interaction with human workers (Faccio et al., 2022). These machines are increasingly used in industries such as manufacturing, healthcare, logistics, and agriculture, where they assist humans in performing complex tasks with greater efficiency and precision.

Cobots play a particularly significant role in agriculture, complementing AR systems to create a more integrated, human-centered AI approach. While AR provides real-time data overlays to enhance decision-making, cobots assist in physically executing tasks based on those insights. For example:

Crop Monitoring and Harvesting
AR systems can analyze crop health and recommend harvesting times, while cobots assist in the precise picking and sorting of produce, reducing waste and improving efficiency.

Livestock Management
Farmers using AR can track animal health indicators, while cobots automate feeding, monitoring, and medical administration, ensuring consistent care.

Precision Farming
AR tools provide insights on soil conditions, and cobots help in automated seeding, irrigation, and fertilization, reducing labor-intensive processes while improving yield outcomes.

Source: (Holzinger et al., 2022)

Key Features of Cobots
Cobots offer several advantages that make them particularly valuable in human-machine collaboration:

Safety

Flexibility

Augmentation of human work

Beyond agriculture, cobots are revolutionizing other industries, particularly manufacturing and logistics. In automotive production, for example, cobots assist assembly line workers by handling intricate assembly tasks, improving worker ergonomics, and reducing physical strain. In warehouses, cobots work alongside human employees by moving heavy loads, optimizing inventory management, and streamlining supply chain operations (Faccio et al., 2022; Waseem, 2024).

As cobots continue to evolve, their role in human-machine collaboration will expand, blurring the lines between automation and augmentation. The key challenge for businesses is ensuring that cobots are integrated thoughtfully—enhancing efficiency without diminishing the role of human expertise.

Skip to content
Home Menu
Previous
Next 3. Building Trust in Automation
The increasing integration of automation and AI across various sectors necessitates a fundamental understanding of trust. Without user confidence in automated systems, their potential for enhancing productivity, decision-making, and overall societal benefit will remain unrealized (Yazdanpanah et al., 2021; Brauner et al., 2022). Leaders must understand the critical aspects of building and maintaining trust in automation, the importance of transparency and reliability, and the significant role of regulatory frameworks in fostering responsible AI adoption.

Another key aspect leaders must keep in mind is that building trust in automation is not solely about ensuring technical accuracy and reliability; it also demands the active involvement of domain experts and end users from the very beginning of the development process. By incorporating the specialized insights of professionals who understand the nuances of their fields, developers can tailor autonomous systems to meet real-world challenges more effectively. This collaborative approach not only helps to identify and mitigate potential risks early on, but also creates a feedback loop that drives continuous improvement. Engaging experts and users throughout the system’s lifecycle is therefore critical for establishing a foundation of trust, ensuring that these technologies evolve in ways that truly benefit their intended applications.

Case Study: Ultrasound Imaging
Building trust in autonomous medical systems requires demonstrating reliability, consistency, and measurable improvements in patient outcomes. The medical field is one where errors must be minimized, as even small mistakes can have serious consequences. For automation to be accepted in healthcare, it must not only match but exceed human performance in accuracy and precision (Lambert et al., 2023).

The field of medical imaging provides a compelling example of how automation can address inherent human variability and enhance the reliability of diagnostic processes and in the process building trust in such systems. You are likely familiar with ultrasound procedures—whether from personal experience or as part of routine medical diagnostics. Ultrasound imaging is widely used because it is non-invasive, cost-effective, and safe, relying on sound waves instead of radiation to generate real-time images of internal structures. However, despite its advantages, ultrasound remains highly operator-dependent, meaning the quality of the images—and consequently the accuracy of diagnoses—varies based on the skill and technique of the technician performing the scan (Gilbertson & Anthony, 2012).

Consider how much of an art form ultrasound currently is. A technician manually manipulates the probe, adjusting pressure, angle, and positioning in response to the image feedback they see on the screen. Even small variations in how the probe is held can impact the clarity of the scan, making consistency a challenge, especially when monitoring changes in a patient’s condition over time. The variability introduced by different users means that repeatability is difficult to achieve, which can hinder longitudinal studies and comparative diagnostics.

Reflect
Leading digital transformation and AI-integration initiatives requires the articulation of clear, measurable outcomes. Take a moment to consider how you could define the objectives for a team working on automating ultrasound procedures.

Which parts of an ultrasound could be automated?
What specific outcomes would you want to achieve by automating this task?
Recall the data to decision loop. What aspect of ultrasound data could automation help reduce?
B-Mode

1N – 10.9 kPa

3N – 15.9 kPa

5N – 20.3 kPa

7N – 20.3 kPa

9N – 21.8 kPa

Source: (Anthony, 2024)

Automation offers a pathway to mitigate these challenges. By utilizing robotic systems, sensors, and algorithms, it becomes possible to monitor and control the ultrasound probe’s interaction with the patient’s body (Gilbertson & Anthony, 2013; Koppaka et al., 2014; Sankepalle et al., 2023). For instance, sensors can measure the contact state, including the probe’s position and the amount of pressure being applied. As illustrated with false color images of the thyroid, even small variations in pressure can significantly alter the mechanical properties of the tissue as perceived by the ultrasound, potentially leading to inaccurate assessments of stiffness (Gilbertson & Anthony, 2012). An autonomous system can consistently apply a defined level of pressure, thereby reducing this critical source of variability introduced by human operation. This leads to enhanced repeatability in the imaging process, ultimately contributing to more consistent and reliable diagnostic information.

Building trust in autonomous medical systems depends on their ability to consistently deliver reliable, high-quality results that surpass human variability. The automation of ultrasound imaging illustrates how technology can reduce operator dependence, ensuring greater accuracy, repeatability, and diagnostic confidence. By addressing inconsistencies that stem from human technique, autonomous systems not only improve patient outcomes but also help establish trust in AI-driven healthcare solutions. When clinicians and patients can depend on these systems to provide precise and reproducible results, the path to broader adoption and acceptance becomes clearer. Trust is not built on automation alone—it is earned through demonstrated performance, transparency, and meaningful improvements in patient care.

The Importance of Explainability and Reliability in AI-Driven Diagnosis
As AI systems take on increasingly complex and high-stakes tasks—such as medical diagnosis—explainability and reliability become critical for building trust and ensuring safe deployment. In domains like healthcare, where clinical decisions can have life-altering consequences, understanding the rationale behind an AI-generated recommendation is essential. Clinicians must be able to interpret, validate, and confidently act on the system’s output.

Explainable AI (XAI) is an emerging field that addresses this need by developing methods to make AI models more transparent, interpretable, and user-friendly (Brauner et al., 2022). The goal of XAI is not just to improve model usability for developers, but to ensure that end users—such as doctors, technicians, or patients—can understand the reasoning process behind the AI’s conclusions.

XAI techniques can range from inherently interpretable models (like decision trees, rule-based systems, or linear regressions) to post hoc explanation tools that attempt to clarify the behavior of more complex models such as deep neural networks (DNNs). For instance, a decision tree—which mimics a series of human-understandable questions—can be used alongside a neural network, which often functions as a “black box” due to its opaque internal representations. By combining these approaches, practitioners can benefit from the high accuracy and pattern recognition capabilities of neural networks, while leveraging simpler models or surrogate explainers to identify which input features were most influential in driving a decision.

In medical diagnosis, this hybrid approach can be particularly valuable. For example, an AI system might flag a tumor as malignant based on subtle imaging features. XAI techniques can help highlight which specific features or regions of the image contributed most to that conclusion, allowing a radiologist to review and corroborate the finding. This enhances clinical confidence and facilitates human-AI collaboration, rather than blind reliance on machine outputs.

Ultimately, the push for explainability reflects a broader shift toward responsible AI—where performance, interpretability, and ethical accountability are all considered essential for deployment in sensitive contexts. As regulations evolve and AI is increasingly integrated into decision-making pipelines, the demand for transparent, interpretable, and reliable systems will only grow.

Without explainability, AI systems can often be perceived as “black boxes,” making decisions based on complex patterns that are opaque to human understanding (Adadi & Berrada, 2018). This lack of transparency can hinder the adoption of AI, especially in situations where human expertise and intuition remain valuable (Holzinger et al., 2022). Users need to understand the factors influencing an AI’s output to assess its reliability and identify potential biases or limitations.

The ultrasound case provides an example of how the black box of AI can be opened and understood. Practitioners know what the tools is guiding them to do (e.g., maintain pressure), and they understand the system is generating outputs based on a consistent measurement.

Trustworthy AI requires not only explainability but also robustness, meaning the ability of AI models to maintain performance even with small changes or disturbances in the input data. Reliability, encompassing factors like accuracy and consistency, is a cornerstone of trustworthiness. If an AI-driven diagnostic tool consistently provides accurate results and can clearly articulate its reasoning, healthcare professionals are more likely to trust and effectively integrate it into their workflows (Sadeghi et al., 2024). Conversely, a system that produces seemingly arbitrary outputs or fails to justify its conclusions will struggle to gain acceptance, regardless of its potential analytical power.

Regulatory Hurdles and AI Adoption
The adoption of AI in highly regulated industries such as healthcare and finance faces significant regulatory hurdles. These regulations are in place to ensure safety, efficacy, and ethical practices, and the integration of AI must align with these established frameworks (Faccio et al., 2022; Yazdanpanah et al., 2021).

A key challenge stems from the non-deterministic nature of many AI models. In contrast to traditional software systems that provide consistent, rule-based outputs, some AI systems—particularly those based on deep learning—can yield different answers to the same query depending on context, data drift, or internal randomness. From a regulatory standpoint, this unpredictability is problematic. Industries such as medical devices or pharmaceutical manufacturing require repeatability, explainability, and strict validation. Any system that influences product quality or patient outcomes must undergo rigorous testing and deliver consistent, auditable results.

In healthcare, for instance, AI may be used to analyze diagnostic images, predict disease risk, or optimize clinical workflows. However, any AI-derived recommendation that influences patient care must be validated and traceable. Regulatory agencies like the FDA demand robust evidence, including validation studies, explainability mechanisms, and documentation of human oversight. AI tools cannot operate in isolation; their outputs must be verifiable and interpretable by clinicians to ensure accountability and patient safety (Anthony, 2024).

Similarly, in the financial sector, AI adoption is constrained by laws focused on accountability, transparency, bias mitigation, and risk management. Financial institutions must be able to explain AI-driven decisions, such as credit scoring or fraud detection, to regulators, auditors, and affected individuals. Noncompliance can lead to significant legal and reputational consequences. As Holzinger et al. (2022) note, trustworthy AI must be both ethically responsible and legally compliant, and as Aboy et al. (2024) emphasize, this is particularly vital from a European legal standpoint where AI must navigate complex regulatory, liability, and data protection requirements.

Click below to read more details about the European Union AI Act and regulations in the medical field.

The EU AI Act
These regulatory hurdles are not necessarily barriers, but rather essential safeguards that ensure the responsible deployment of AI in critical domains. Overcoming them requires a focus on developing AI systems that are not only powerful but also inherently transparent, auditable, and capable of providing verifiable evidence for their decisions and actions.

Furthermore, a core component of responsible AI deployment in regulated industries is data traceability and representativeness. AI systems must be trained on datasets that accurately reflect the populations they serve, while also preserving privacy and complying with data protection laws such as GDPR or HIPAA. Techniques like federated learning, differential privacy, and secure multi-party computation are increasingly being used to enable the development of high-performance AI models without compromising individual privacy.

The Role of AI in Regulated Industries and Ensuring Transparency
Despite the regulatory complexities, AI holds significant potential for enhancing efficiency and insights within regulated industries. The key lies in designing AI systems that prioritize transparency and operate within the bounds of established regulations (Yazdanpanah et al., 2021). As Brauner et al. (2022) mention, the challenge is to design simple interfaces to automated processes and decision-support systems that are accessible, transparent, and easy to learn and use. While one intended interface might be as simple as an internet search engine, the underlying AI in regulated industries often needs to provide a deeper level of transparency regarding its reasoning.

In these contexts, the role of AI might initially focus on augmentation rather than full autonomy, with human-in-the-loop (HITL) systems playing a crucial role. AI can analyze complex datasets, identify anomalies, and provide suggestions, but human experts retain the authority to validate, interpret, and act upon these insights. This approach allows regulated industries to utilize the analytical power of AI while maintaining human oversight and ensuring compliance.

Furthermore, the development of explainable AI (XAI) techniques specifically tailored to the needs of regulated sectors is critical (Brauner et al., 2022; Aboy et al., 2024). These techniques can provide auditors and regulators with the necessary insights into how AI systems are functioning and making decisions, facilitating compliance and building trust in their responsible use. The focus is on creating AI tools that are not only accurate but also understandable and accountable within the established legal and ethical frameworks of these industries.

Trust in automation is built on clear evidence of consistent performance, transparent processes, and adherence to established guidelines. For instance, the medical imaging examples demonstrate that when systems reliably deliver high-quality, repeatable results, user confidence naturally grows. In these cases, domain experts work closely with the technology by providing feedback on performance and adjusting protocols to reduce variability, which in turn helps to fine-tune the system for optimal outcomes. Regulations play a dual role here—they not only mandate trusted practices by requiring systems to meet strict safety and performance standards but also set clear guardrails that guide the development of these systems. By adhering to these regulatory requirements, developers are better equipped to build solutions that are both effective and reliable, ultimately reinforcing trust among users and stakeholders.

Forum: Transparency and Trust
In your field, how important is it for users of ML or GenAI tools to understand the “reasoning” behind the outputs? In this forum, you will share your considerations and have the chance to consider perspectives from other fields.​

You will find all forum details in the virtual campus.

Skip to content
Home Menu
Previous
Next 4. Upskilling for Collaboration
The increasing prese of artificial intelligence and automation requires organizations to rethink how their workforce collaborates and adapts. Leaders must proactively develop upskilling initiatives that enable employees to work seamlessly with advanced technologies. This forward-thinking approach is essential for building a resilient team that not only understands the capabilities of automated systems but also knows how to mitigate potential risks.

Dimensions of Human-Automation Interaction
Effective upskilling initiatives begin with a deep understanding of the nuanced relationship between human operators and automated systems. Leaders must recognize that challenges such as disuse—where a lack of trust leads to underutilization—and misuse—where over-reliance results in complacency—directly impact how training programs should be designed. By grasping these dynamics, leaders can tailor upskilling strategies that not only enhance technical proficiency but also cultivate critical decision-making skills and situational awareness. This foundational insight is essential for ensuring that employees are well-prepared to interact safely and effectively with complex automation.

Disuse and Misuse of Automation
The concepts of misuse and disuse of automation are critical aspects of human-automation interaction that can significantly impact the effectiveness and safety of automated systems.

Disuse of automation refers to the intentional neglect of decision aids or automated systems by operators, often stemming from a lack of trust in technology or a perception that it offers no benefits.

Misuse of automation, on the other hand, involves the over-utilization of automated systems due to over-trust, where operators may neglect to check the results or functioning of the automation. This over-reliance can lead to automation complacency and automation biases, where errors or malfunctions in the automated system may go unnoticed, potentially resulting in negative consequences.

(Brauner et al., 2022)

Next
Value Added Human Skills
The focus of upskilling and reskilling should be aligned with the needs created by human and automation collaboration. As more automation is introduced in workflows, the skills needed will evolve. As we understood in the previous section, there are different dimensions of human-automation interaction. Building upon that, let us focus on some of the skills that have become the sine-qua-non in current upskilling initiatives.

Successful human automation collaboration necessitates a blend of technical acumen, domain-specific knowledge, strong interpersonal and communication skills, a deep commitment to safety and ergonomics, and a nuanced understanding of the ethical and practical dimensions of working with intelligent machines. The ongoing evolution of AI and robotics will continue to shape and expand the necessary skills for effective human collaboration.

Understanding the capabilities and limitations of automation
Maintaining situational awareness
Communication and interaction skills
Technical literacy
Domain expertise and conceptual understanding
Responsibility and accountability
Workers need to develop an understanding of what automated systems, including AI, can and cannot do. This includes comprehending the robot’s abilities and limitations, which is crucial for building appropriate trust and avoiding both disuse and misuse of automation. Understanding these limitations also helps in knowing when human intervention is necessary. (Faccio et al., 2022)

Skills for Cross-Disciplinary Collaboration
The digital transformation era calls for a convergence of expertise from various fields. Effective upskilling involves building interdisciplinary knowledge that allows team members from different backgrounds—such as engineering, data science, and business—to communicate fluently and work together toward shared objectives. This means promoting an understanding of AI fundamentals, model-driven thinking, and the practical challenges of integrating automated systems into everyday workflows. A human-centered approach remains crucial to ensure that technology serves as an aid rather than a replacement for human insight.

Interdisciplinary knowledge and understanding
Effective communication abilities
Model-driven thinking and knowledge integration
Understanding AI and automation fundamentals
Human-centered approach
Collaborators need to develop a foundational understanding of the concepts, methodologies, and challenges within each other's disciplines. For instance, computer scientists need to grasp production engineering principles, while engineers should understand the capabilities and limitations of AI and data processing. This does not require becoming an expert in every field, but rather having sufficient working knowledge to facilitate communication and identify common ground. (Brauner et al., 2022)

In essence, the digital age presents both challenges and opportunities. By embracing lifelong learning and proactively developing skills relevant to digital technologies, leaders can help position individuals and teams to thrive in the future workforce, contributing to and collaborating with increasingly intelligent and automated systems across various sectors.

Skip to content
Home Menu
Previous
Next 4. Upskilling for Collaboration
The increasing prese of artificial intelligence and automation requires organizations to rethink how their workforce collaborates and adapts. Leaders must proactively develop upskilling initiatives that enable employees to work seamlessly with advanced technologies. This forward-thinking approach is essential for building a resilient team that not only understands the capabilities of automated systems but also knows how to mitigate potential risks.

Dimensions of Human-Automation Interaction
Effective upskilling initiatives begin with a deep understanding of the nuanced relationship between human operators and automated systems. Leaders must recognize that challenges such as disuse—where a lack of trust leads to underutilization—and misuse—where over-reliance results in complacency—directly impact how training programs should be designed. By grasping these dynamics, leaders can tailor upskilling strategies that not only enhance technical proficiency but also cultivate critical decision-making skills and situational awareness. This foundational insight is essential for ensuring that employees are well-prepared to interact safely and effectively with complex automation.

Disuse and Misuse of Automation
The concepts of misuse and disuse of automation are critical aspects of human-automation interaction that can significantly impact the effectiveness and safety of automated systems.

Disuse of automation refers to the intentional neglect of decision aids or automated systems by operators, often stemming from a lack of trust in technology or a perception that it offers no benefits.

Misuse of automation, on the other hand, involves the over-utilization of automated systems due to over-trust, where operators may neglect to check the results or functioning of the automation. This over-reliance can lead to automation complacency and automation biases, where errors or malfunctions in the automated system may go unnoticed, potentially resulting in negative consequences.

(Brauner et al., 2022)

Next
Value Added Human Skills
The focus of upskilling and reskilling should be aligned with the needs created by human and automation collaboration. As more automation is introduced in workflows, the skills needed will evolve. As we understood in the previous section, there are different dimensions of human-automation interaction. Building upon that, let us focus on some of the skills that have become the sine-qua-non in current upskilling initiatives.

Successful human automation collaboration necessitates a blend of technical acumen, domain-specific knowledge, strong interpersonal and communication skills, a deep commitment to safety and ergonomics, and a nuanced understanding of the ethical and practical dimensions of working with intelligent machines. The ongoing evolution of AI and robotics will continue to shape and expand the necessary skills for effective human collaboration.

Understanding the capabilities and limitations of automation
Maintaining situational awareness
Communication and interaction skills
Technical literacy
Domain expertise and conceptual understanding
Responsibility and accountability
Workers need to develop an understanding of what automated systems, including AI, can and cannot do. This includes comprehending the robot’s abilities and limitations, which is crucial for building appropriate trust and avoiding both disuse and misuse of automation. Understanding these limitations also helps in knowing when human intervention is necessary. (Faccio et al., 2022)

Skills for Cross-Disciplinary Collaboration
The digital transformation era calls for a convergence of expertise from various fields. Effective upskilling involves building interdisciplinary knowledge that allows team members from different backgrounds—such as engineering, data science, and business—to communicate fluently and work together toward shared objectives. This means promoting an understanding of AI fundamentals, model-driven thinking, and the practical challenges of integrating automated systems into everyday workflows. A human-centered approach remains crucial to ensure that technology serves as an aid rather than a replacement for human insight.

Interdisciplinary knowledge and understanding
Effective communication abilities
Model-driven thinking and knowledge integration
Understanding AI and automation fundamentals
Human-centered approach
Collaborators need to develop a foundational understanding of the concepts, methodologies, and challenges within each other's disciplines. For instance, computer scientists need to grasp production engineering principles, while engineers should understand the capabilities and limitations of AI and data processing. This does not require becoming an expert in every field, but rather having sufficient working knowledge to facilitate communication and identify common ground. (Brauner et al., 2022)

In essence, the digital age presents both challenges and opportunities. By embracing lifelong learning and proactively developing skills relevant to digital technologies, leaders can help position individuals and teams to thrive in the future workforce, contributing to and collaborating with increasingly intelligent and automated systems across various sectors.

# Module 4

Skip to content
Home Menu
Previous
Next 4. Upskilling for Collaboration
The increasing prese of artificial intelligence and automation requires organizations to rethink how their workforce collaborates and adapts. Leaders must proactively develop upskilling initiatives that enable employees to work seamlessly with advanced technologies. This forward-thinking approach is essential for building a resilient team that not only understands the capabilities of automated systems but also knows how to mitigate potential risks.

Dimensions of Human-Automation Interaction
Effective upskilling initiatives begin with a deep understanding of the nuanced relationship between human operators and automated systems. Leaders must recognize that challenges such as disuse—where a lack of trust leads to underutilization—and misuse—where over-reliance results in complacency—directly impact how training programs should be designed. By grasping these dynamics, leaders can tailor upskilling strategies that not only enhance technical proficiency but also cultivate critical decision-making skills and situational awareness. This foundational insight is essential for ensuring that employees are well-prepared to interact safely and effectively with complex automation.

Disuse and Misuse of Automation
The concepts of misuse and disuse of automation are critical aspects of human-automation interaction that can significantly impact the effectiveness and safety of automated systems.

Disuse of automation refers to the intentional neglect of decision aids or automated systems by operators, often stemming from a lack of trust in technology or a perception that it offers no benefits.

Misuse of automation, on the other hand, involves the over-utilization of automated systems due to over-trust, where operators may neglect to check the results or functioning of the automation. This over-reliance can lead to automation complacency and automation biases, where errors or malfunctions in the automated system may go unnoticed, potentially resulting in negative consequences.

(Brauner et al., 2022)

Next
Value Added Human Skills
The focus of upskilling and reskilling should be aligned with the needs created by human and automation collaboration. As more automation is introduced in workflows, the skills needed will evolve. As we understood in the previous section, there are different dimensions of human-automation interaction. Building upon that, let us focus on some of the skills that have become the sine-qua-non in current upskilling initiatives.

Successful human automation collaboration necessitates a blend of technical acumen, domain-specific knowledge, strong interpersonal and communication skills, a deep commitment to safety and ergonomics, and a nuanced understanding of the ethical and practical dimensions of working with intelligent machines. The ongoing evolution of AI and robotics will continue to shape and expand the necessary skills for effective human collaboration.

Understanding the capabilities and limitations of automation
Maintaining situational awareness
Communication and interaction skills
Technical literacy
Domain expertise and conceptual understanding
Responsibility and accountability
Workers need to develop an understanding of what automated systems, including AI, can and cannot do. This includes comprehending the robot’s abilities and limitations, which is crucial for building appropriate trust and avoiding both disuse and misuse of automation. Understanding these limitations also helps in knowing when human intervention is necessary. (Faccio et al., 2022)

Skills for Cross-Disciplinary Collaboration
The digital transformation era calls for a convergence of expertise from various fields. Effective upskilling involves building interdisciplinary knowledge that allows team members from different backgrounds—such as engineering, data science, and business—to communicate fluently and work together toward shared objectives. This means promoting an understanding of AI fundamentals, model-driven thinking, and the practical challenges of integrating automated systems into everyday workflows. A human-centered approach remains crucial to ensure that technology serves as an aid rather than a replacement for human insight.

Interdisciplinary knowledge and understanding
Effective communication abilities
Model-driven thinking and knowledge integration
Understanding AI and automation fundamentals
Human-centered approach
Collaborators need to develop a foundational understanding of the concepts, methodologies, and challenges within each other's disciplines. For instance, computer scientists need to grasp production engineering principles, while engineers should understand the capabilities and limitations of AI and data processing. This does not require becoming an expert in every field, but rather having sufficient working knowledge to facilitate communication and identify common ground. (Brauner et al., 2022)

In essence, the digital age presents both challenges and opportunities. By embracing lifelong learning and proactively developing skills relevant to digital technologies, leaders can help position individuals and teams to thrive in the future workforce, contributing to and collaborating with increasingly intelligent and automated systems across various sectors.

Skip to content
Home Menu
Previous
Next 2. Crafting a Powerful Vision of the Future
Digital transformation is an ongoing process. You can begin the process by using force, but it will only be successful if you persuade your employees to be part of the change. That is why having a vision is so important. A good vision is short, simple, sets direction, and is something everyone can believe in. The vision must be grand and aspirational. People must feel that the vision is not just good for the company, but also for themselves.

What Is a Great Vision?
To drive an effort that is organization wide, leadership needs to come up with a clear vision of where the organization is headed. It is not just about crafting a statement that has been agreed upon in the C-suite level meetings. It needs to be something that everyone can believe in, not just the leaders. It must be energizing to inspire people to go beyond the status quo and constantly improve the way they work. Let’s have a look at a few examples of vision articulated by industry leaders:

Nike
Flip
“orward toMoving fgether. Our purpose is to move the world forward through the power of sport. Worldwide, we’re leveling the playing field, doing our part to protect our collective playground and expanding access to sport for everyone.” (Nike, n.d.)

Nike do not want to simply sell you shoes. They want to be part of your life.

Flip
Rio Tinto
Flip
“We’re finding better ways to provide materials the world needs, now and in the future.” (Rio Tinto, n.d.)

Rio Tinto are not solely focused on resource extraction. They are committed to continuously improving how materials are sourced to meet the world’s needs in a responsible and forward-looking manner.

Flip
Schneider Electric
Flip
“Life Is On.” (Schneider Electric, n.d.)

Schneider Electric are not just providing energy solutions. They aim to empower individuals and organizations to use energy more efficiently and sustainably, making progress accessible to all.

Flip
Huntington Ingalls Industries
Flip
“We shall build good ships here; at a profit if we can; at a loss if we must; but always good ships.” (HII, n.d.)

​The company was launched more than a century ago with that vision. The motto “always good ships” is still used today.

Flip
Kaiser Permanente
Schindler

Key Characteristics of a Great Vision
A great vision is short, simple, and sets a clear direction everyone can believe in. It is aspirational, engaging, and has measurable indicators of progress. A compelling vision is essential for driving progress and inspiring belief within an organization. It is key to aim beyond incremental improvements; a “faster caterpillar” will falter when competitors learn to “fly.” A strong vision sets a bold direction, challenging outdated ways of thinking and empowering teams to embrace innovation and adaptability.

Aspirational

Compelling

Actionable

Short

Recall the DBS guiding case. How does their vision fulfill these criteria?

DBS: “Let’s make banking joyful”
Engaging People in the Vision for AI-Powered Transformation
A compelling vision is not just leadership jargon—it is a critical tool for challenging outdated assumptions and guiding process transformation. A strong vision paints a picture of a future that is significantly different and better than the present, pushing the organization beyond incremental improvements. A good vision is short, compelling, and something that everyone—employees, customers, investors, and managers—can believe in. Visions that possess these qualities will facilitate the next leadership capability, engagement.

Activity
Imagine you are leading a company that specializes in developing sustainable technological solutions for businesses in the environmental conservation space.
Which of the two vision statements has the characteristics of a great vision? ﻿

Our vision is to be the best company in the world, with the most advanced products and highest profits, while helping the environment, promoting diversity, and ensuring employees lead happy and productive lives.
Our vision is to lead the global transition to sustainable technology, empowering businesses to thrive while preserving our planet for future generations.
Submit

Skip to content
Home Menu
Previous
Next 3. Engaging Employees and Executives in the Change 
Any organization driving digital transformation will likely need to overcome resistance from within. Change is hard and is often resisted in support of the status quo. By ensuring that all stakeholders are engaged in the transformation process, leaders can address the concerns that create resistance. Beyond that, leaders can show how the vision benefits employees and not just leaders, and they can create excitement around the future goal. This engagement will instill a sense of belonging towards the organizational vision. People become a source of energy and innovation when they are afforded an opportunity to participate in the transformation process (Buvat et al., 2018).

Newport News Shipbuilding did not impose quality and efficiency requirements on its workers. Instead, it focused on making it easier for workers to do good work. This approach reflects the principle that a compelling organizational vision should not only be credible but also beneficial to employees, ensuring their needs are prioritized alongside leadership goals. By focusing on enhancing the daily experiences of employees, Newport News Shipbuilding fosters greater engagement, satisfaction, and productivity, ultimately benefiting both the workforce and the leadership.

Recall DBS’s vision “Let’s make banking joyful.” More than just a slogan, this vision served as a rallying point, engaging employees at all levels in the transformation process. It was not merely about improving customer satisfaction, it was about creating an environment where employees felt empowered to identify and eliminate sources of frustration. Every unnecessary wait time and every cumbersome process became an opportunity for improvement, reinforcing the idea that everyone had a role to play in making banking truly joyful.

By setting a vision that employees could connect with and actively contribute to, DBS not only redefined the customer experience but also transformed its internal culture. This case demonstrates how a well-crafted vision can align an organization’s collective efforts, inspiring innovation and meaningful change from within.

Organizational transformation requires participation from all members of the organization, so leaders must ensure active engagement in transformational initiatives. A clear, compelling vision provides all stakeholders with a beacon—a reference point that enables each individual to engage at their specific level and capacity. This vision not only outlines the strategic direction for change but also makes the transformation relevant to everyone, from executives to front-line employees. From this reference point, each individual can understand how they can contribute to the transformation process, be it through ideas or energy.

Leadership Activities to Encourage Engagement
There are several ways of ensuring that transformation is seen as a collaborative activity rather than as a top-down order.

The DBS case provides some hints as to how leaders can engage their teams in change. Encouraging and acting on bottom-up feedback and allowing employees to pursue their own initiatives allowed the whole organization to participate in transformation. Specifically, DBS implemented opportunities where any employee could propose improvements to processes. Employees were empowered to find ways to cut the pain points that lead to wait times. Leaders highlighted successful implementations and praised the employees who were responsible. As a result, employees felt they were a part of the transformation and contributing to beneficial changes.

Now, recall the other case study from the beginning of this module. Huntington Ingalls’ Newport News Shipbuilding offers a striking example of how effective employee engagement can drive digital transformation, particularly in a unionized environment. Leaders focused on improving the working experience, which naturally set the stage for broader operational improvements and greater efficiency through the adoption of new technologies, such as digital design.

Framing benefits

Engaging unions

Transformational change

In essence, Newport News Shipbuilding’s engagement strategy highlights the importance of aligning digital transformation initiatives with the interests and well-being of employees. Their success demonstrates that when employees are treated as partners in change—where their insights are valued and their concerns addressed—resistance can be overcome, paving the way for a more efficient and forward-thinking organization.

The Three Lenses Framework
It is important for leaders to recognize that change is often met with resistance not because employees are unwilling to change, but because they interpret change differently based on their perspectives. Leaders must recognize that a single approach to driving transformation will not work for everyone—what convinces one person may not resonate with another, and as we have said transformation happens by persuasion, not by force. Change is hard, and leaders must find the right ways to “sell” it by addressing concerns through multiple viewpoints.

A powerful framework for understanding and addressing resistance is the three lenses of change. This is a framework that has been taught at MIT for more than 20 years. The three lenses are rational, political, and cultural. Each lens represents a different way individuals interpret a situation. Some individuals may see things more clearly through a rational lens, while others consider political or cultural aspects to be more essential or convincing.

Successful change lies at the intersection of these three elements. People tend to favor one of these lenses, but it is important to consider all of them.

Adapted from: (Carroll, 2001)

By considering these perspectives, leaders can develop more effective engagement strategies.

Applying the Three Lenses: Asian Paints
Asian Paints’ digital transformation demonstrates the critical need to address the three distinct lenses—rational, political, and cultural—to achieve successful organizational change. Through the rational lens, the initial transformation project was justified by clear business benefits, including a significant potential reduction in working capital, improved data clarity, and enhanced operational efficiency. However, the purely logical appeal of these benefits was not enough to secure universal buy-in.

Looked at through the political lens, some leaders in the 13 regions objected to the standardization inherent in the transformation because it threatened their long-held autonomy. These leaders feared that standardizing processes and centralizing information might strip them of their authority and diminish their ability to tailor strategies to local market conditions. Some feared a loss of power and control over regional operations, undermining their influence and operational independence.​​​

From the cultural lens, the transformation project clashed with entrenched values and practices within the organization. Salespeople, in particular, resisted the change because it redefined their roles. They were concerned that this shift would erode the personalized service that had long been a cultural cornerstone at Asian Paints and damage the relationships they believed customers valued.​​

​​​This case underscores that even when rational benefits are compelling, leaders must also address political power dynamics and cultural resistance to effectively drive digital transformation.​​

Reflect
​​​Before reading further, consider some ways that leaders could address the political and cultural concerns that arose in the Asian Paints case.​​

The Rational Lens: Making the Business Case
​​The rational lens focuses on logic, data, and facts. Employees who view transformation through this lens want to understand the details of the business case—why the change is necessary, the benefits, ​and how it will work. To engage stakeholders from this perspective, leaders must be prepared to clearly articulate their rationale, demonstrate measurable benefits, and provide structured plans.

Clearly articulate the reasons for change using concrete evidence, such as market trends, competitive pressures, or operational inefficiencies.

﻿Demonstrate measurable benefits by sharing projected improvements in productivity, cost savings, or customer satisfaction.

﻿Provide structured implementation plans that outline the steps, timeline, and expected outcomes of the transformation.

For example, if a company is implementing AI-driven automation in customer service, a rational argument might include data on how AI reduces response times, improves accuracy, and allows human employees to focus on the most complex issues. Some managers and employees may appreciate this rational approach, but others may see the situation in a different way.

Strategies for employing a rational lens include:

Goals and objectives

Architecture

Business cases

Process and organization redesign

Metrics

The Political Lens: Navigating Power and Influence
The political lens considers how change affects power dynamics, roles, and influence within an organization. Employees who view transformation through this lens may resist because they feel their authority, status, or decision-making power is being challenged. Others may be persuaded to change through actions that exert or reallocate power. Leaders can acknowledge these concerns by identifying key stakeholders, directly outlining how teams will be impacted, and positioning employees as champions of transformation.

Determine individuals or groups that will be most affected by transformation. Consider their interests, motivations, and concerns.

Form alliances with people who support the transformation initiatives. Ensure that they share the vision and then ask them to help promote the changes.

​Recognize that leaders must sometimes use their authority to drive change. However, this power should be exercised responsibly and ethically, with consideration for the impact on individuals and groups.

For example, if a hospital introduces AI-powered diagnostics, doctors, and medical staff may fear that automation will reduce their expertise or control over decision-making, or experienced doctors may fear being supplanted by newer ones who are more comfortable with AI tools. Engaging key medical professionals in the implementation process—by allowing them to guide AI integration and validate its use—can turn potential resistance into active support.

Strategies for employing a political lens include:

Accountability for results

Transparency on process and performance

Non-public (or public) pressure

Reassignment/firing

Ignoring the political dimension of change can lead to hidden opposition, where employees subtly discourage adoption or delay progress. Leaders must recognize power structures and align transformation with the interests of those who hold sway in the organization.

The Cultural Lens: Aligning With "How We Do Things Around Here"
The cultural lens focuses on the values, practices (formal and informal), and hidden assumptions that shape how we perceive and behave within an organization. Resistance from this perspective arises when transformation feels like it clashes with long-standing norms or disrupts the identity of the workplace. To address cultural resistance, leaders can rely on organizational beliefs and habits, properly frame changes, and employ storytelling.

Understand the organization’s cultural DNA—what values, practices, and hidden assumptions define how work gets done.

​Frame change in a way that aligns with existing values and assumptions, rather than presenting it as a complete departure from the past.

Use storytelling and role models to show how transformation fits naturally into the company’s evolution.

Provide opportunities for employees to voice concerns and present their ideas.​

For instance, if a construction company is shifting from paper-based workflows to digital platforms, resistance may stem from the culture of hands-on, in-person work. Instead of positioning digital tools as a radical departure, leaders can emphasize how they enhance long-standing values of craftsmanship, efficiency, and worker safety.

Strategies for employing a cultural lens include:

Burning platform (if possible)

Clear vision

Engaging employees in the change

Encouraging and recognizing the right behaviors

Celebrating “wins”

Failing to consider cultural resistance can result in employees passively ignoring change, even if they outwardly comply. Leaders must respect cultural norms while guiding their evolution to align with transformation goals.

Applying the Three Lenses for Effective Change Leadership
Affective leaders do not rely on just one lens—they use all three to craft a well-rounded change strategy. When introducing transformation, leaders should ask:

Rational lens: Are we making a strong logical case for change?
Political lens: Are we addressing how change impacts power structures and influence?
Cultural lens: Are we considering cultural norms and values in how we position change?
By integrating these perspectives, leaders can anticipate and address different forms of resistance, increasing the likelihood of successful transformation.

Leaders should also recognize that everyone naturally views the world through their own dominant lens. By being aware of your own lens—and understanding that others have different perspectives—you will better understand the root causes of concerns and resistance and therefore be able to respond more effectively to underlying behaviors. To build a more adaptable team, it is important to include members whose dominant lenses differ from your own, ensuring a well-rounded approach to decision-making and tailored strategies for overcoming challenges.

Understanding that employees interpret change differently is essential for overcoming resistance. The three lenses—rational, political, and cultural—provide a framework for leaders to tailor their approach and engage employees in ways that resonate with their perspectives. Change is not just about logic and strategy; it is about relationships, power dynamics, and deeply held beliefs. By considering these factors, leaders can build trust, reduce opposition, and guide their organizations through transformation with confidence and clarity.

Remember, leaders will encounter people influenced by one of the three lenses discussed above. Each person has one dominant lens through which they understand the world. To actively engage people in the transformation journey, each type of person may need to be persuaded using their dominant lens. Leadership teams must be able to consider rational, political, and cultural lenses all at the same time.

Take a moment to consider which is your dominant lens. Take the following poll and view the results to see where you place in comparison to your peers.

Poll
Results

Forum: Utilizing the Three Lenses
​The three lenses provide a framework for understanding perspectives and communicating with stakeholders. In this forum, share your experiences of examining issues through these different lenses. Look at the poll results and reflect on the questions below and share your thoughts.

Activity
The Three Lenses
Imagine you are leading the initiative to modernize the loan approval process. The new workflows will be using an AI-based platform to evaluate the loan eligibility of the applicants.

Consider the potential motivators or concerns with regard to this new initiative. Drag the statements into rational, political and cultural buckets as per your understanding.

There might be technical issues or system failures. They can compromise data privacy and disrupt the entire loan approval cycle.
Shifting to automated platforms will create resistance from employees who fear job loss or a decrease in their influence.
Personal relationships built by human interactions are more aligned with the cultural values of the organization.
People and their loan needs are not like car parts; everyone is different and needs to be treated differently.
Decision making authority on 30% of loans will move to an offshore group rather than the local units.
We will be able to process applications 40% more efficiently.
This will remove the ability to customize approaches for our specific environment.
This will encourage experimentation and promote a culture where failure can be a learning opportunity.
People accustomed to face-to-face communication may feel alienated from this new impersonal process.
AI models have the superhuman ability to analyze multiple factors beyond credit scores. This improves the accuracy of risk evaluations.
This will create a centralized system, consolidating power within a few decision makers.
The platform will be able to handle larger volumes of applications simultaneously, increasing the number of borrowers.
Undo
Submit

Skip to content
Home Menu
Previous
Next 4. Governing for Progress, Not Just Prevention
Once you have created a vision and set up mechanisms to engage people in transformational initiatives, you must steer the course using governance mechanisms. It is important to establish clear rules and processes that guide the organization in the right direction, while also preventing it from going astray. Although many people think about governance as a way to stop bad things from happening, it should be about encouraging the right levels of sharing and coordination, not just preventing unwanted action. In other words, governance should be more of a steering wheel than a brake pedal. (Westerman, 2024).

The Role of Governance in Transformation
Governance plays a crucial role in ensuring that digital transformation efforts move in the right direction. It should encourage innovation and experimentation, while ensuring those innovations are aligned and scalable. When reviewing opportunities, it should encourage sharing, reuse, and coordination, in addition to ensuring safety and ROI. Without clear governance structures, transformation efforts risk fragmentation, misalignment, cybersecurity weaknesses, regulatory compliance issues, and inconsistent execution across different business units. While governance can sometimes be seen as bureaucratic, effective leaders recognize that it is not about preventing error—it is about guiding the organization in the right direction while maintaining flexibility for innovation.

Governance must serve as a mechanism for continuous course correction. Transformation is not a one-time event but an ongoing process that requires frequent adjustments based on new insights, market conditions, and technological advancements. Effective leaders put in place governance structures that regularly review progress, identify roadblocks, and adjust strategies as needed.

Leaders should understand that governance is a tool that enables organizations to scale transformation efforts while minimizing risks. The most successful leaders view governance not as a bureaucratic burden, but as an essential system of guardrails that keeps innovation moving in the right direction. By setting clear accountabilities, balancing central and local needs, allocating resources wisely, and ensuring ongoing oversight, leaders can create governance structures that empower—not hinder—meaningful transformation.

Key Mechanisms
The key to successful governance is balance—providing enough structure to maintain alignment and efficiency while allowing flexibility for teams to innovate and execute effectively.

Leaders can utilize several important mechanisms in order to build more robust governance structures. Five key mechanisms are: the chief digital officer (or equivalent), digital liaisons, shared digital units, governance committees, and dedicated resources. Each of these mechanisms plays a unique role in aligning digital initiatives with business objectives and fostering a culture of innovation and accountability.

Chief digital officer
Digital liaisons
Shared digital units
Governance committees
Resources
​The chief digital officer (CDO), or an equivalent, is a critical leadership role responsible for unifying the company’s digital vision. The CDO transforms “digital cacophony into a strategic symphony” by aligning digital activities, evaluating and improving products and processes, and equipping teams with essential tools and resources. Whether operating independently or in conjunction with other digital units, a strong CDO—with support from top management—ensures that digital transformation is coordinated across the enterprise.

​(Westerman et al., 2014)

Robust digital governance hinges on a blend of strategic leadership and coordinated action. The chief digital officer provides unified vision and direction, while digital liaisons ensure that local units align with this vision. Shared digital units deliver centralized expertise and infrastructure, governance committees set policies and allocate resources, and dedicated resources empower all these mechanisms to function effectively. Together, these five mechanisms form an integrated framework that not only drives innovation and digital transformation but also ensures accountability, consistency, and sustainable growth in the AI era.

Governance for Innovation
For leaders guiding digital transformation, it is important to establish governance structures that encourage innovation. Effective leaders recognize that governance is not about controlling every aspect of transformation; it is about providing structure while allowing room for experimentation, learning, and adaptation.

A common mistake organizations make—typically exemplified by organizations in the conservative quadrant of the digital mastery framework—is over-governing transformation efforts in an attempt to maintain control. Leaders may create rigid approval processes, centralized committees, and layers of oversight, believing that this will reduce risk. While this approach may ensure compliance and consistency, it often discourages innovation by making it difficult for teams to experiment with new technologies or adapt to changing conditions. For instance, a healthcare organization introducing AI-driven diagnostics may slow adoption if every modification requires multiple layers of executive approval. Instead, leaders must define essential guardrails—such as data privacy, security, and ethical considerations—while empowering teams to explore solutions within these boundaries.

At the same time, too little governance, often exemplified by organizations in the fashionista quadrant of the digital mastery framework, can be equally problematic. When innovation is completely decentralized, different departments or regions may adopt conflicting solutions, making integration difficult and leading to inefficiencies. Leaders must ensure that governance provides enough unifying standards, architecture, and tools to align innovation efforts with enterprise-wide goals.

Consider a global consumer goods company adopting AI-powered demand forecasting. If different regional teams deploy separate AI models without coordination, the company may struggle with inconsistencies, conflicting insights, and inefficiencies in supply chain planning. In this scenario, governance could establish common data standards and value measurement protocols, while allowing regions the flexibility to tailor their methods to local market conditions.

Finding the right level of standardization versus flexibility is a core leadership responsibility. Certain elements—such as cybersecurity policies, regulatory compliance, and enterprise-wide AI ethics—must be centrally governed to protect the organization. However, areas such as product innovation, customer engagement, and localized process improvements may benefit from decentralized execution. Leaders should encourage teams to innovate within a structured framework, ensuring that new ideas align with broader strategic goals without unnecessary constraints.

Sustaining governance over time is also critical. Governance is not a one-time setup—it must evolve alongside technological advancements, market shifts, and organizational learning. Leaders should establish regular reviews of governance structures, ensuring that policies remain relevant and that innovation continues to thrive. This could involve quarterly governance check-ins, adaptive policies that evolve with AI and automation trends, and continuous feedback loops from innovation teams.

Ultimately, leaders must view governance as a mechanism to enable innovation, not restrict it. The best governance models provide clarity, accountability, and alignment without suffocating creativity. By finding the right balance between control and agility, leaders can create an environment where digital transformation is both disciplined and dynamic, structured yet adaptable, and scalable without losing its innovative edge.

Key Questions for Governing Digital Innovation
Effective governance is not a static framework—it must evolve alongside an organization’s transformation efforts. Leaders must continuously assess whether their governance structures are enabling progress or unintentionally creating barriers. Without regular evaluation, governance can become misaligned with strategic goals, slow decision-making, or fail to support innovation effectively.

To ensure governance remains a dynamic and enabling force, leaders should ask key questions that reveal potential gaps, inefficiencies, or risks in their current approach. These questions help clarify who is responsible for transformation, how decisions are made, and whether governance structures are balancing control with flexibility. Leaders who proactively reflect on these areas can adjust their governance models to better support digital and AI-driven transformation.

Oversight
Integration
Centralization
Interaction
Coordination
Learning
Governance
Who oversees the transformation, and how is it being driven?

It is important to have clarity regarding who is responsible for leading the transformation efforts within the organization.

By regularly assessing governance effectiveness, leaders can ensure that structures remain relevant, efficient, and aligned with transformation goals. Governance should not be a rigid set of rules, but a living system that evolves as the organization grows and technology advances. Leaders must be willing to refine decision-making processes, adjust accountability structures, and remove bottlenecks that slow innovation. By continuously revisiting fundamental governance questions, leaders can keep their transformation efforts on track, ensuring that governance remains an enabler of progress rather than an obstacle to change.

Activity
Consider the statements on governance for digital transformation in the first column.
Mark them true or false as per your understanding.

True False
Digital transformation is steered through strong top-down leadership. The Chief Digital Officer (CDO), or a leader with similar responsibilities, should spearhead the digital transformation at the enterprise or business level.
New technologies like AI, generative AI, and IoT are often seen as standalone goals by digital masters. These technologies are adopted on a whim without clear strategic direction, serving as random occurrences within the organization rather than tools to achieve specific business objectives.
Common digital platforms should be established to provide economies of scale and interoperability.
Poor governance can undermine good vision by allowing disconnected initiatives and making it difficult to connect different parts of the organization.
In large organizations, governance usually involves a central entity and individual units working together, encouraging the right level of sharing and coordination between the center and the units.
Governance committees should be used to prioritize competing interests and ratify policies, ensuring that both overall strategic goals and departmental needs are considered.
Establishing a steering committee is sufficient to ensure good digital and AI governance.
The main role of digital/AI governance is to protect the company from risks such as security or IP loss.
AI and IT must be governed separately.
Submit
Assignment: Becoming a Digital Master
Now that you have explored key aspects of leadership capability, you will apply this knowledge to the digital mastery framework. In this assignment, you will consider how organizations in the fashionista and conservative quadrants might strategically move toward digital masters.

You will find all assignment details in the virtual campus.

Skip to content
Home Menu
Previous
Next 5. Case Study: Banking
Imagine a fictional bank in Brazil named SSP Bank. This bank has been strategically considering integrating AI. Let’s begin by getting to know a little bit about the key stakeholders of the SSP Bank.

Ana da Silva, CEO
Ana is leading the charge towards further integrating AI into the bank's operations.

Next
Required Reading
Read the following case study and then answer the question in the Padlet below.

Strategizing the AI-enabled Future of SSP Bank
Should Ana accept Michael and Fernanda’s proposal to aggressively embrace AI? Please justify your answer focusing on the key leadership capabilities of vision, engagement, and governance.

To create a pin, click on the ""+"" button in the bottom-right corner. Type your answer, click ""Publish"" and reposition the pin as needed. You can change the color and edit your pin by clicking on the menu (three dots) on the right side of your pin.

Important note: The following interactive element can be challenging to view or interact with on smaller handheld mobile devices. It is recommended to use a desktop, laptop, or tablet to ensure full accessibility.

Skip to content
Home Menu
Previous
Next 6. Sustaining Momentum
Before we move on to the remaining leadership capabilities, let’s return one last time to the DBS case study to see how they utilized leadership capability to initiate change and, importantly, to sustain this transformation.

Understanding the role of leadership in regard to creating a clear vision, engaging stakeholders, and ensuring proper governance is an essential first step in driving transformational change. However, it is still only a first step. To sustain digital transformation, leaders must go beyond structural changes and top-down impetus to actively shape an organizational culture that is able to engage in continuous change—adaptable, innovative, and prepared for the future. A culture of digital and AI readiness is one where employees are comfortable to share their ideas, experiment with new ways of working, embrace continuous learning, and see change as an opportunity rather than a disruption.

Leadership is central to shaping this culture. Leaders set the tone by creating an environment where curiosity, adaptability, and continuous learning are valued. As values are promoted throughout an organization, the activities and practices of employees reflect these values. It is leadership’s responsibility to identify and embed values of AI-readiness in order to encourage transformative practices. It is through these values and practices that organizational culture is created and reflected.

Additionally, a key feature of digital transformation is the evolution of IT teams and leaders from supporting roles to strategic partners. IT and business leaders must learn to communicate together in ways that are mutually understood. Developing a strong strategic relationship with open communication between these parties will be the final leadership capability we will discuss.

Looking ahead, in Module 6, “Building the Capability to Thrive,” we will examine this AI-ready culture in greater depth. There, we will consider the evolving role of IT teams and the values and practices that both support and emerge from an AI-ready organizational culture. Keep the foundational leadership activities discussed in this module in mind as we widen the scope to consider the larger culture itself. Remember, creating a compelling vision, engaging employees, and developing robust governance are a starting point. By rounding out the other leadership capabilities outlined in the 2×2 digital mastery framework, e.g., partnering with IT leaders and ultimately cultivating an AI-ready culture, transformative change can be maintained.

Course Project Part 4: Defining the Vision, Engagement, and Governance Strategy
In this part of your course project, you will apply the leadership capability covered in this module to your AI transformation initiative. You will craft a vision, plan engagement activities, and evaluate governance policies that will allow you to initiate your project.

You will find all project details in the virtual campus.

# Module 5

Skip to content
Home Menu
Previous
Next

1. Understanding Internet of Things
   The Internet of Things (IoT) is a network of interconnected devices embedded with sensors, software, and communication technologies that enable them to collect and exchange data (Rana et al., 2021). These technologies allow us to collect data from almost anything, at any time, and in any context; this is all made possible by the widespread availability of low-cost communication, improved sensors, and microcomputers. The goal is to gather and transmit data seamlessly. This can happen at the edge, where computing power is located directly with the sensor to make immediate decisions, or in the cloud, where data is sent for processing on remote servers.

Edge
Flip
Computing that takes place close to the data source, allowing for real-time processing and immediate decision-making without relying on a centralized system.

Flip
Cloud
Flip
Remote servers that store, process, and analyze data at scale, providing deeper insights and long-term analytics that may not be possible at the edge.

Flip
At its foundation, the Internet of Things (IoT) is an evolution of instrumentation—one that incorporates advanced capabilities such as networking, local processing, and intelligent decision-making. An IoT system fundamentally involves acquiring data, optionally pre-processing it, communicating it efficiently, extracting useful insights, and ultimately acting upon those insights to influence the environment.

Sensors serve as the fundamental sensory inputs—the “eyes,” “ears,” “smell,” and “touch”—of any IoT system, detecting critical environmental parameters such as temperature, pressure, motion, and chemical composition (Rana et al., 2021). Robust communication networks then enable the seamless transmission of this data from the edge to centralized or distributed processing centers. There, advanced analytics techniques, including machine learning and signal processing, transform raw data into actionable insights (Wang et al., 2023).

These insights drive control mechanisms that allow IoT systems to make real-time or near-real-time adjustments, optimizing operations, enhancing performance, and counteracting disturbances across multiple time scales. In dynamic environments such as industrial production or smart infrastructure, these automated feedback loops play a critical role in ensuring resilience, efficiency, and adaptability.

Important
An IoT solution involves a complex design space—it is a system design challenge rather than the application of a single technology. Effective IoT systems integrate multiple technologies across sensing, communication, data processing, and control. The following case studies will illustrate how these elements come together in practice.

The current IoT landscape is characterized by rapid innovation and expanding adoption across a wide range of industries (Rana et al., 2021). Manufacturing plants, healthcare facilities, smart cities, and logistics networks are increasingly leveraging IoT technologies to enhance operational efficiency, enable predictive maintenance, and improve decision-making (Rana et al., 2021; Bianchini et al., 2024). However, the approaches to implementation—and the associated challenges and successes—are as diverse as the organizations deploying the technology.

In a previous module, we introduced the data-to-decision loop. IoT fuels the data-to-decision process by creating a continuous feedback loop between physical and digital systems. Once data is collected, it progresses through layers of processing, from initial filtering at the edge to advanced analysis in the cloud. This enables adaptive responses—whether adjusting machine settings in a factory, optimizing energy use in a smart grid, or alerting medical staff to a patient’s condition. By ensuring that decisions are informed by real-time and historical data, IoT enhances efficiency, automation, and predictive capabilities across industries.

Definition and Evolution
At its simplest, IoT is about instrumentation and measurement, capturing signals from the physical world and converting it into digital data that can be processed, analyzed, and acted upon. This fundamental definition lays the groundwork for understanding how IoT systems evolve from mere data collection tools into sophisticated, real-time decision-making platforms.

Historically, the journey to today’s IoT began with isolated measurement systems that were limited by manual data capture and rudimentary control mechanisms. Early industrial environments relied on basic sensors and analog instruments to monitor processes (Rana et al., 2021). These systems provided valuable insights but were often constrained by their inability to rapidly process or share data across large networks. Over the decades, rapid advancements in sensor technology, miniaturization, and digital communications dramatically transformed this landscape. Sensors became smaller, more affordable, and more capable, allowing for continuous monitoring of variables like temperature, pressure, and motion with far greater precision (Wang et al., 2023).

This evolution was further accelerated by breakthroughs in wireless communication protocols—such as Wi-Fi, Bluetooth, and later, low-power wide-area networks like LoRa—which enabled devices to connect and transmit data over vast distances. As connectivity improved, so did the ability to aggregate and analyze data in real time (Zhang et al., 2024). The shift from standalone, localized systems to interconnected networks marked the birth of the “data-to-decision” paradigm that now defines modern IoT architectures. These advancements have not only enabled real-time feedback control in manufacturing and healthcare but have also paved the way for innovations that merge physical processes with digital intelligence (Rana et al., 2021).

The historical evolution of IoT is a narrative of technological convergence—where advances in sensor technology, communication networks, and analytics have collectively redefined how data drives decision-making. Today’s IoT systems are a significant evolution from their predecessors, representing a dynamic integration of hardware and software that continuously adapts to and informs the physical world (Wang et al., 2023). Understanding the historical trajectory is helpful for appreciating not only what IoT is, but why it has become a central pillar of modern digital transformation strategies.

Important
One of the most compelling trends shaping IoT today is the rise of edge computing—where computation is integrated close to the sensor and data source (Rana et al., 2021; Wang et al., 2023), complemented by cloud computing for analyzing longer-term trends across multiple edge devices. By bringing data processing closer to the point of collection, edge computing addresses latency challenges, enabling real-time analytics and immediate decision-making while reducing reliance on distant cloud servers. As edge devices grow increasingly powerful, they can support more sophisticated algorithms, paving the way for smarter, more responsive IoT applications. Moreover, advancements in wireless communications continue to expand the reach and reliability of IoT networks, making it feasible to deploy these systems in even the most challenging environments (Eskue, 2023; Wang et al., 2024).

Forum: Computing at the Edge
Analyzing data directly at the source can reduce the need for complicated communications networks and latency. Is edge computing common in your field? Share your insights in this forum and compare the state of edge computing across fields.

Go to the online platform to complete the forum.

Skip to content
Home Menu
Previous
Next 2. Digital Twins and the Digital Thread
The concept of a digital twin has emerged as a critical enabler of data-driven decision-making in modern industries (Cline, 2017; Wang et al., 2023; Zhang et al., 2024). The term digital twin was popularized by General Electric (GE), which initially defined a digital twin as a model, emulation, or digital simulation and predictor of a functioning turbine. In this framework, real-time data from the physical turbine continuously updates the digital model, enabling predictive simulations and allowing the digital twin to operate in parallel with its physical counterpart.

Today, these emulations are being applied in a variety of fields. These models of real-world objects, processes, or systems are not exact replicas but are designed to provide actionable insights that help predict future states and influence the behavior of their physical counterparts. At its core, a digital twin functions as a live computational model (Zhang et al., 2024), capturing detailed information about the behavior, performance, and status of its physical counterpart (Minerva et al., 2020). Real-time data streams feed into these models, enabling predictive capabilities that operate across multiple timescales—from microseconds for control systems to years for long-term planning and lifecycle management. Digital twins can represent a wide range of entities, including individual machines, production processes, people, factories, supply chains, and even entire cities.

Digital twins are defined by several distinguishing characteristics.

First, they rely on a continuous data flow, ensuring that the model remains an accurate and up-to-date reflection of reality (Wang et al., 2023; Zhang et al., 2024).

Next
Important
A digital twin differs from a traditional model in that it is continuously updated with real-world data. Traditional models can predict outcomes based on static inputs and fixed assumptions. However, a digital twin dynamically evolves itself with live data, refining its accuracy and predictive capabilities over time. The goal is to have a digital representation that mirrors the physical system as closely as possible, enabling better predictions about performance, maintenance needs, and operational behavior.

In supply chain management, track and trace refers to the ability to monitor the location and status of materials, products, or personnel throughout their lifecycle. By employing IoT technologies such as GPS and RFID, businesses can enhance visibility, improve efficiency, and ensure reliability in logistics and operations. This real-time monitoring helps optimize inventory management, reduce delays, and maintain quality control across the supply chain.

The digital thread is a related concept. It refers to the flow of data accompanying physical assets throughout their lifecycle—from design and manufacturing to maintenance and operation. If an issue arises in the field, the digital thread allows us to trace it back to its origin, whether it was a fabrication error or a problem with raw materials. Though complex, this vision is becoming increasingly feasible.

Checking the delivery status of a package provides a glimpse of track and trace.

Bridging the Physical and Digital
IoT, i.e., applied instrumentation, is not a new concept. The advancements in low-cost sensors, improved connectivity, and better computing capabilities have made it more accessible. However, technology alone is not enough—domain expertise is essential for successful implementation. The world still operates through physical systems involving people, machines, and materials; IoT technologies provide new ways to collect and analyze data to improve decision-making.

A critical aspect of both IoT and digital twin development is a deep understanding of the physical system and the nature of the available data. Meaningful data collection and the creation of effective models require strong contextual knowledge of how systems operate. The most effective approaches often combine physics-based understanding with data-driven methods, resulting in what are known as gray-box models—integrations where traditional physics-based models and machine learning techniques work together to enhance predictive power.

Knowing what data to collect and what a useful model should predict are key considerations that underpin successful IoT and digital twin strategies.

Collecting the Wrong Data
Developing the Wrong Model
Current Landscape
IoT is generating significant interest because of its potential to improve quality, reduce variability, increase speed, and lower costs. This interest is further supported by the decreasing costs of data acquisition, communication, and processing technologies, as well as the development of standards that simplify implementation and encourage broader adoption. However, realizing the full promise of IoT is not automatic. When considering IoT, digital twins, and models, it is important to recognize that these systems are inherently complex. They involve physical components such as processes, machines, and operations that are domain specific—whether in healthcare, finance, or another area.

A deep understanding of the particular domain, including its constraints and the types of data that can be collected, is essential for success. This contextual knowledge is crucial for making informed decisions about how to collect relevant data and apply algorithms to extract actionable insights. The most effective use of IoT technologies demands a dual approach: blending domain expertise with IoT expertise. These complementary capabilities can be thought of as a "bilingual" skill set—fluency in both domain-specific understanding and data-driven methodologies—which is crucial for designing, deploying, and operating IoT systems.

Outlining Applications
When we examine any system or machine, we must first understand its physical context—its principles of operation. The term "physics" here refers not just to the physical components of the system but to the broader context in which the system operates, including human factors, materials, and organizational decision-making processes. Once we understand this, we can ask: Where is the data coming from, and does the data we have align with our physical intuition about how the system should behave?

Once data is collected and a contextual understanding is established, we can begin to model the current state of a system and move to predict future outcomes. Digital twins are particularly valuable in this regard, as they use real-time data to make predictions that can inform decision-making. By forecasting future events, digital twins enable proactive adjustments. If predictions begin to diverge from actual outcomes—or if there is a need to improve the accuracy of future forecasts—it may be necessary to design additional experiments, collect more targeted data, or deploy additional sensors to refine the twin.

Types of Digital Twins
Digital twins can exist along a spectrum from white-box (models based only on physics-based equations) models to black-box (models only learned from data) models, with gray-box models representing the middle ground.

White box

Black box

The most promising approach, and the one that is often the most practical in real-world applications, is the gray-box model. This approach blends physical knowledge—whether through full understanding of the system’s physics or through intuition—with data-driven insights. This hybrid method is often the most effective approach for industrial applications, as it provides a balance between accuracy, interpretability, and adaptability. The gray-box model, sitting between the white-box and black-box approaches, effectively bridges the physical and digital worlds.

To illustrate these different types of models, we can consider several examples: a finite element model for simulating the behavior of a turbine, a mass-spring-damper system for modeling oscillatory motion, and a neural network for capturing complex, data-driven patterns. All of these are valid modeling approaches, depending on the context and the available data.

Finite Element Model
Mass-Spring-Damper System
Neural Network
Applications and Industry Use Cases
The adoption of digital twins spans multiple industries, each utilizing the technology in unique ways to optimize operations, improve predictive capabilities, and enhance decision-making. Digital twins are particularly valuable for applications requiring real-time data synchronization, predictive maintenance, and operational efficiency. Across sectors like manufacturing, healthcare, smart cities, and aerospace, digital twins are being used to model, analyze, and improve both physical assets and organizational workflows.

Manufacturing and Industrial Operations
One critical application of digital twins is process control through real-time feedback. Digital twins in manufacturing help detect variations in materials, machines, and environmental conditions, adjusting processes dynamically. These systems leverage statistical process control and real-time trend analysis to ensure consistent product quality. By implementing IoT-enabled twins, manufacturers can minimize waste, optimize energy consumption, and reduce unplanned downtime. (Bianchini et al., 2024; Rana et al., 2021)

Healthcare and Medical Devices
In healthcare, digital twins are transforming both patient monitoring and hospital operations. One compelling example is the Vitals Kiosk, a non-contact monitoring system designed for real-time health screening (Anthony, 2025). These kiosks collect multi-modal sensor data, such as heart rate, respiration rate, temperature, and pulse oximetry, using radar, cameras, and other embedded sensors. By integrating digital twins into public health infrastructure, hospitals can monitor population health trends, detect early signs of illness, and optimize medical resource allocation.

Beyond public health monitoring, digital twins are also used for personalized medicine. Patient-specific models enable doctors to simulate treatment scenarios, predict disease progression, and optimize surgical outcomes (Minerva, 2020). In cardiology, for example, digital twins of a patient's heart can model how different medications or procedures may impact heart function, facilitating tailored treatment plans.

Smart Cities and Infrastructure
The deployment of digital twins in urban planning and infrastructure is revolutionizing how cities optimize resources, manage traffic, and enhance sustainability (Minerva, 2020; Wang et al., 2024). Smart city initiatives use real-time models of road networks, energy grids, and public transportation systems to improve efficiency. A digital twin of a city’s transportation network can ingest real-time GPS data, weather conditions, and commuter behaviors to dynamically adjust traffic signals, optimize bus routes, and reduce congestion.

Building management is another key area of adoption (Minerva, 2020). Smart buildings use digital twins to monitor and control heating, ventilation, and air conditioning systems. These models help reduce energy consumption by predicting demand fluctuations and adjusting operational parameters accordingly. Additionally, predictive maintenance for large infrastructure, such as bridges and tunnels, is enhanced by digital twins that monitor structural integrity through embedded IoT sensors, ensuring early detection of potential failures.

Aerospace and Automotive Industries
In aerospace, digital twins are essential for real-time aircraft engine monitoring and predictive maintenance (Anthony, 2025). Companies such as GE and Rolls-Royce use digital twins to track jet engine performance, analyze wear and tear, and predict maintenance needs before failures occur. These models allow airlines to schedule repairs proactively, reducing costly flight delays and improving passenger safety.

Similarly, in the automotive sector, digital twins are being used to develop and test autonomous vehicle algorithms (Minerva, 2020). Simulated driving environments allow companies to train AI-driven systems before deploying vehicles on real roads. These models help refine self-driving behaviors, optimize battery performance, and simulate accident scenarios, ensuring the robustness of autonomous technologies before mass adoption.

Conclusion
Digital twins are impacting industries that rely on real-time monitoring, predictive analytics, and operational optimization. From manufacturing and healthcare to smart cities and aerospace, these models help organizations reduce downtime, enhance decision-making, and improve overall system performance. While digital twins provide valuable predictive insights, their success depends on reliable IoT data, proper integration with enterprise systems, and strategic leadership.

Skip to content
Home Menu
Previous
Next 3. Manufacturing Use Cases
Now, we will examine two examples of IoT and digital twin applications in industrial decision-making. Together, they demonstrate the necessity of combining data science with physical intuition and domain expertise to build reliable predictive models. As digital twins continue to evolve, they will play an increasingly critical role in optimizing manufacturing processes, reducing waste, and enhancing product reliability.

Example 1: Twinning Bottle Packaging Machines
First, we will explore the application of real-time data collection and predictive modeling in industrial manufacturing, focusing on a packaging machine used for wrapping bottles. This machine automates the process of wrapping bottles moving along a conveyor system and producing packaged sets, such as 6-packs or 18-packs of bottles.

As bottles move along the conveyor system, sensors track their speed and position in real time. The machine uses this data to coordinate several operations: adjusting bottle placement, positioning the plastic wrap, wrapping it around the bottles, cutting the wrap, heat-sealing, and ultimately producing the final packaged product.

The central question in this case was whether it is possible to develop a digital twin of this system to predict machine health based on the collected control-system data. One aspect of the target machine health was the condition of the cutting blade. A question was posed: Can we predict when the blade that cuts the plastic wrap will become too dull and require replacement?

Note that by basing predictions on “collected data,” any prediction must be made without adding extra sensors, relying only on the analysis of high-speed data collected over an extended period. The sensor data included information such as torque, velocity, and position over time with one package involving approximately 8 milliseconds of data collection. Additionally, the system generates histograms of these time traces, offering valuable insights into operational trends across thousands of packages.

There was extensive real-time data available—several kilobytes per package across thousands of production cycles—providing a rich dataset for model development. However, one of the critical challenges was that the cutting blade is enclosed within a mechanical housing, making direct visual inspection impossible. Therefore, blade degradation had to be inferred indirectly through changes in machine behavior. Instead of incorporating additional sensors or cameras, it was necessary to rely on maintenance logs, which recorded the dates when the blade was last replaced. These logs enabled a process of approximating the blade’s wear based on its age.

Applying Physical Intuition
As stated above, successful integration of IoT and digital twins for decision-making processes requires a bilingual approach. To assess overall machine health, and the condition of the cutting blade in particular, both data science capabilities and domain expertise were required.

Understanding the system at a physical level was essential. In the case of the cutting blade, domain expertise provided critical intuition: the condition of the blade—specifically, its wear over time—would likely be reflected in the control system data. Consider the analogy of using a sharp versus a dull pair of scissors. A dull pair requires more force or higher speed to cut the same material compared to a sharp pair. Similarly, in the machine data, changes in torque, velocity, or other signals could reveal the blade’s degradation.

This physical intuition gave confidence that meaningful patterns related to blade wear would be embedded in the collected data. It also established the expectation that a predictive model could be developed to approximate the blade’s age and anticipate when maintenance or replacement would be required.

The data engineering required to integrate information from multiple sources—such as production records, control system outputs, and maintenance logs—was a complex task. These data streams varied in format, resolution, and origin, often involving different systems, users, and levels of granularity. However, once the integration was successfully completed, a decision tree model was trained using inputs such as speed, torque, and position to predict the blade’s age. The accuracy of the model was evaluated by comparing its predictions with the recorded blade ages for data that was not used in the training. If the predictions closely aligned with the observed data, the model could be useful.

Decision Trees
Although the model was not highly accurate at predicting blade wear for individual packages, its strength lay in identifying long-term trends. Because each package yielded variable predictions (e.g., 2 months, 3 months, 4 months), decisions could not be based on any single data point. Instead, the model’s output was treated as a noisy sensor—a signal that, while imprecise at the per package level, revealed meaningful patterns when aggregated over many packages.

To extract these patterns, filtering techniques were applied to smooth out per-package variability and generate a more stable estimate of blade wear over time. By averaging predictions across hundreds of packages, the system provided a reliable basis for proactive maintenance decisions. This approach enabled better planning, optimized machine performance, and reduced the likelihood of unexpected failures.

Operational Impacts
The implementation of this IoT-based virtual wear sensor led to several key operational improvements:

Reduction in unplanned downtime

Cost savings through targeted maintenance

Enhanced decision-making for operational leaders
Challenges and Considerations
Despite these benefits, deploying an IoT-based wear sensor is not without its challenges:

Data integration complexity

Sensor calibration and accuracy

Model interpretability and trust

By addressing these challenges, the company was able to establish a robust predictive maintenance system that balanced real-time IoT monitoring with long-term trend analysis.

This case study illustrates how IoT can drive operational improvements. By using sensor data and machine learning, the packaging machine example demonstrates the power of real-time monitoring and predictive maintenance. While individual data points may be noisy, trends extracted over time provide valuable insights, allowing companies to transition from reactive maintenance to proactive, condition-based strategies.

For leaders, this case highlights the importance of asking the right questions when implementing IoT solutions:

What can the data we already collect tell us about our machines or other assets?
What level of accuracy is needed for decision-making?
How can IoT insights be integrated with existing operational workflows?
By understanding these foundational concepts, leaders can make informed decisions about IoT adoption, system reliability, and long-term value generation, ensuring that technology investments align with business objectives.

Example 2: Twinning Variable Compression Rate Engines
An automotive manufacturer was developing a variable compression rate engine, which is mechanically complex and presents significant challenges in assembly. During the pilot production run, the manufacturer encountered a high failure rate among the engines. To prevent defective engines from reaching customers, the company implemented comprehensive testing for each individual unit.

The functional testing process included the following procedures:

Accelerometer

Compressor

Lever arm

While these tests were necessary due to the high failure rate, they were also labor-intensive and costly. The manufacturer then posed a critical question: Could they develop a predictive model—a digital twin—that would enable them to assess engine quality based on assembly data, rather than conducting exhaustive testing on every unit? If successful, this approach could reduce the need for comprehensive functional testing, potentially limiting it to every tenth or twentieth engine—or even eliminating it altogether.

An initial model built on a neural network showed promise. The team created a robust digital twin model capable of predicting engine performance, but they were not yet confident enough to rely solely on the model. Since the model was still undergoing validation, they continued to test every engine while refining the twin. This iterative approach allowed for continuous improvement of both the model and the manufacturing process.

To explain the underlying principles of the neural network used in this process, we can draw a simple analogy to line fitting.

Suppose we have a set of data points (represented as blue dots), and we wish to fit a line to describe the relationship.

Next
Neural networks function on a similar principle but are more complex. Instead of fitting a simple line, we construct a multi-layered structure where inputs are weighted, passed through activation functions, and propagated forward. Learning within a neural network involves optimizing the weights and biases, akin to fitting a line, but on a much larger scale. Given the vast amounts of data typically involved, optimization algorithms are employed rather than direct analytical solutions.

A variable compression rate engine is significantly more intricate than a conventional internal combustion engine, containing numerous moving parts that require precise assembly. The manufacturing process involves several steps in which components are bolted, measured, and transported through the production line. Once assembled, the engine undergoes functional testing.

The challenge in this case was relating assembly data—such as component dimensions and torque measurements from instrumented torque guns—to the results of functional testing. By training a neural network on historical data, the team developed a model capable of predicting the outcomes of functional tests based on the assembly inputs.

The critical element in this process was trust. As the team was still building confidence in the model, they continued to perform functional tests on each engine and compared the predictions made by the model with the actual test results. This feedback loop allowed for ongoing refinement of the model. Over time, they observed that while all engines met the quality threshold, some engines performed exceptionally well. This insight enabled them to identify high-performing engines and gain a better understanding of process variations.

This case demonstrates how a relatively simple modeling tool—a neural network—can be used to create a digital twin that evolves over time. By leveraging IoT data and machine learning, the manufacturer was able to improve quality prediction, reduce reliance on exhaustive testing, and optimize their manufacturing process.

Assignment: Evaluating Real-Time Data for Business Insights
In this assignment, you will analyze how real-time data from connected devices could enhance decision-making or problem-solving within a specific department or business unit in your organization. You will assess current data practices, identify valuable new data sources, and evaluate the technical and operational challenges involved in implementing real-time data integration.

You will find all assignment details in the virtual campus.

Skip to content
Home Menu
Previous
Next 4. Planning Integration
A key question is: how does one begin integrating IoT and digital twins? As previously discussed, this process is complex and requires engaging the entire organization. It remains crucial to assess current practices, collaborate with knowledgeable technology partners, and analyze how data flows from its initial to final stages. Additionally, organizations must consider data security and develop a strategy that emphasizes gradual, incremental progress. A common mistake is failing to take measured steps and neglecting proper planning for both technological implementation and the people involved.

One of the most significant challenges in deploying IoT or digital twin solutions is the lack of awareness among personnel within an organization. As discussed under leadership capabilities, ensuring engagement is essential. Another major hurdle is the limited expertise among leaders responsible for driving these transformations (technology leadership capability will be addressed in a coming module).

Furthermore, organizational structure, strategic alignment, and budget constraints play critical roles in determining success. While some of these points may have already been covered, one of the key barriers to initiation is recognizing that, in many cases, organizations are already implementing aspects of these technologies—albeit perhaps inefficiently or without utilizing the latest advancements.

The optimal approach is to build on existing practices and proceed incrementally. This allows leaders to continually orient themselves along the technological and leadership capabilities necessary for digital transformation.

Rather than creating entirely new data science or digital twin teams, organizations should focus on integrating these capabilities into existing groups already working in related areas—such as simulation, process engineering, and statistical process control. These teams are well positioned to enhance their workflows by incorporating real-time data, enabling continuous model refinement and more responsive decision-making.

It is also important to recognize that designing an IoT system from the ground up requires thoughtful system architecture. This includes selecting and integrating components across the full technology stack—such as computational infrastructure, sensors, connectivity, and location tracking—each of which must be tailored to the specific operational context and goals.

Twinning of Operations
Twinning an operation involves representing the individual components or processes of a system at an appropriate level of abstraction—capturing key characteristics such as uptime and downtime statistics, general personnel, materials, and information flows, and overall system behavior. Variability is inherent in these processes and must be accounted for when developing a digital twin of the operations of a facility.

Consider some of the following examples of possible twins and the questions that can be used to develop a digital twin.

Manufacturing
Flip
In a factory setting, how could the layout be optimized? Where should buffer spaces be allocated?

Flip
Healthcare
Flip
In a hospital setting, what is the required number of staff, beds, or imaging equipment?

Flip
Retail
Flip
In a retail environment, how many registers are necessary to minimize wait times?

Flip
Of course, across all these examples some common questions will arise:

Is investing in additional staff or new machinery justified?
How should data management and storage be structured?
Regardless of industry, organizations can often be conceptually simplified. A straightforward example is a production line composed of multiple sequential tasks (e.g., Task 1, Task 2, Task 3), typically requiring buffer spaces between stages. Similar abstractions can be applied to operations in other fields, even if the workflows are not strictly linear.

Of course, real-world operations introduce added complexities—tasks may need to be repeated, workflows may branch or converge, and machine or personnel availability can be affected by factors such as maintenance schedules, unexpected breakdowns, or health-related absences.

To effectively model this variability, resources such as machines, personnel, or even hospital beds can be categorized into a few fundamental operational states:

Operational vs. non-operational (machines and personnel)

Available or occupied

The probability of machines or personnel being in one state or the other can be derived by collecting data on uptime and downtime—specifically, the duration an asset remains operational before failing and the time required for repair or return to health. In manufacturing, this information is typically obtained from maintenance logs, whereas for personnel, attendance records may serve as a useful data source. While real-world conditions often involve additional complexities (such as partial operational states rather than a binary functioning or non-functioning condition), this foundational model provides a starting point.

Using this data, organizations can employ commercial tools such as Siemens Factory I/O, AnyLogic, or Plant SIM to develop simulations. While these tools offer visual representations, the digital twin itself resides in the underlying model rather than in its graphical depiction. The fundamental objective is to utilize real-world uptime and downtime data to simulate various operational scenarios, thereby enabling data-driven decisions regarding workflow optimization, redundancy planning, and resource allocation.

The core principle is that the operational status of a machine or personnel can be captured through a probabilistic model—essentially simulating a weighted coin flip. For instance, if a machine is operational 90% of the time and fails 10% of the time, this behavior can be modeled using a biased probability distribution rather than assuming an equal likelihood of functioning or failing.

By applying these probabilistic models, organizations can gain a deeper understanding of the effects of process modifications, investments, and workforce management strategies. The overarching goal is to develop a system that accounts for real-world variability, ultimately enabling organizations to optimize operations in a dynamic and effective manner.

Simulation Software for Modeling System Optimization
Simulation software tools are based on these probabilistic concepts which can be understood as a biased coin toss, albeit with additional mathematical refinements. Despite their simplicity, these models enable robust graphical visualizations, making them particularly useful for simulating operations in contexts such as logistics centers, financial institutions, and manufacturing systems. Simulation software visual representations provide an intuitive means of understanding complex system dynamics.

To illustrate this concept, consider the following scenario. While the accompanying graphic pertains to manufacturing, the underlying principles apply broadly. Suppose there are two sequential tasks, referred to here as Task 1 and Task 2. These tasks could represent operations performed by Machine 1 and Machine 2 or actions undertaken by two different individuals. Between these tasks, there exists an intermediate storage buffer.

The necessity of storage arises due to system variability. If both tasks or machines operated continuously without interruption, intermediate storage would be redundant. However, real-world systems are subject to fluctuations in processing time and unexpected downtime, making storage a crucial element in mitigating these disruptions. Work-in-process buffers help absorb variability, ensuring operational continuity even when one component of the system experiences a delay.

The figures presented in this example are derived from a basic Python simulation developed in under 20 minutes—a task that could now easily be accomplished using AI-driven tools such as ChatGPT. The plots represent a simple operational model consisting of Task 1, a buffer, and Task 2. The simulation uses a biased coin-flipping mechanism to approximate the operational status of the machines. Each machine is typically operational, indicated by blue segments on the timeline, but occasionally experiences downtime, shown as white gaps.

When Machine 1 is operational, it performs its task and places material into the intermediate buffer. When Machine 2 is operational, it pulls material from the buffer (if available) and completes its task. Over time, the simulation allows us to estimate key system characteristics, such as the average amount of work-in-progress (WIP) in the buffer and the average production rate, given the variability of the machines and the finite buffer capacity.

By analyzing this simulation, key system characteristics can be examined. For instance, there are periods when Machine 2 is inactive while Machine 1 remains operational. During these intervals, Machine 1 continues processing tasks and deposits output into the buffer. However, once the buffer reaches its maximum capacity—set at 10 units in this case—Machine 1 is forced to cease operations despite being functional.

This simulation provides several important insights. Given independent and random uptimes and downtimes for each machine and a fixed buffer size, we can determine the average number of items stored in the buffer. Furthermore, after observing the system for a sufficient duration, we can estimate the expected production rate. This enables us to answer critical operational questions, including:

What is the optimal buffer size to maintain efficient workflow?
What is the expected production output under given constraints?
How can storage and machine utilization be optimized to balance efficiency and downtime?
Rather than relying solely on complex mathematical derivations, these simulations allow for data-driven decision-making by integrating observed system behaviors. The same principles extend to more intricate models involving multiple machines, workstations, and logistical components.

A more sophisticated simulation tool is AnyLogic. Among various commercial options, AnyLogic provides a robust platform for modeling dynamic systems. One practical application of AnyLogic is modeling hospital emergency departments. The underlying structure of this model mirrors the earlier manufacturing example, consisting of sequential tasks and buffers. Here, patients arrive and undergo a series of medical procedures, with their progression influenced by resource availability, including nurses, hospital beds, and diagnostic equipment.

This simulation framework facilitates scenario analysis, allowing users to explore various operational improvements:

How would adding an additional ultrasound machine affect patient wait times?
What impact would increased staffing levels have on overall throughput or cost?
Given existing hospital layouts and resources, what is the average duration of patient stays?
The software enables both 2D and 3D visualization, providing an interactive means to assess system performance. By adjusting variables such as the number of physicians, nurses, or diagnostic tools, users can evaluate different configurations and their respective impacts on efficiency.

A similar approach can be applied to manufacturing systems, such as a solar panel production line. This model simulates workstation performance under conditions of variable uptime and downtime, offering insights into production fluctuations over time. Such simulations are invaluable not only for system design and optimization, but also for the development of digital twins.

In practice, modern simulation tools typically employ discrete event simulation (DES) rather than simpler discrete-time simulation or coin-flipping models. DES allows systems to be modeled as a sequence of events occurring over time, providing greater flexibility. However, the foundational requirements remain the same: statistical data on machine uptimes, downtimes, and task arrival rates. With these inputs, simulation software can generate actionable insights into resource allocation, system efficiency, and opportunities for improving overall operational performance.

Discrete Event Simulation
The cost depends on the tools and the approach taken. For example, organizations may not want to invest in commercial software like AnyLogic. It is possible to develop basic simulations using simple programming techniques. Even basic coding skills can enable the creation of fundamental models. The key is to start small—experiment with basic tools and models before making significant financial investments. Additionally, it takes leadership within an organization to understand the tools available, how to use them effectively, and when to scale up investments strategically.

The key benefit of digital twins is that they allow us to compare modeled outcomes with real-world data. If the simulation predicts certain trends, we can compare those predictions with actual observations and refine the model over time. This iterative approach improves accuracy and helps organizations make data-driven decisions about staffing and workload management.

That is what makes digital twins so powerful—it isn’t necessary to start with a perfect model. By continuously comparing the simulation to real-world data, you can refine your assumptions and improve accuracy over time. This feedback loop helps organizations make smarter decisions.

The idea is not to create a perfect model from the start, but rather to refine it over time. By running simulations and analyzing errors between predictions and real-world outcomes, we can iteratively improve the digital twin. This allows organizations to optimize operations, make informed decisions, and maximize efficiency.

Recommended Links
You can learn more about simulation software tools at Factory I/O, AnyLogic, or Technomatix Plant Simulation.

Skip to content
Home Menu
Previous
Next 5. Conclusion
This module not only demonstrates how IoT and digital twins transform operational decision-making through real-time data integration and predictive analytics, but also highlights the essential role of digital capabilities within the digital mastery framework. By examining case studies such as the predictive maintenance of packaging machines and the simulation of variable compression rate engines, we explored how digital tools can bridge the gap between physical systems and their digital counterparts, thereby optimizing performance and enhancing innovation.

The digital mastery framework emphasizes the development of robust digital capabilities. This module provides concrete examples of these capabilities in action—illustrating how sensor networks, machine learning, and simulation modeling empower organizations to make data-driven decisions and achieve operational excellence. Leaders who cultivate these digital capabilities are better equipped to navigate the challenges of digital transformation, ensuring that technology investments lead to sustainable competitive advantages.

Ultimately, mastering these digital capabilities is not just about implementing cutting-edge technologies, but also about developing a culture of continuous improvement and adaptive leadership. The insights and practical applications discussed in this module serve as a blueprint for integrating IoT and digital twin solutions, enabling organizations to thrive in an increasingly interconnected and data-driven landscape.

Course Project Part 5: IoT and Digital Twins in Digital Transformation
In this part of your course project, you will explore how IoT and digital twin technologies could be applied to enhance productivity, customer experience, and operational efficiency within your organization or a similar industry. You will evaluate practical use cases, potential limitations, and the leadership strategies needed to support effective implementation and data governance.

You will find all project details in the virtual campus.

# Module 6

Skip to content
Home	Menu
Previous
Next
1. Building a Digital- and AI-Ready Culture
In previous modules, we explored the digital mastery framework—the 2×2 matrix that can be used to evaluate an organization’s digital capability alongside its leadership capability.

We examined how a clear, compelling vision sets a unifying strategic direction; how robust engagement energizes employees to become active participants in change; and how effective governance mechanisms serve as both the steering wheel and the brakes, ensuring that transformation efforts remain aligned with organizational objectives.

As we move into this module, we will shift our focus to the remaining leadership capabilities that create the conditions for sustaining transformation over time. Specifically, we will examine technology leadership and building a digital- and artificial intelligence (AI)-ready culture. These capabilities enable organizations to integrate technological innovations effectively while nurturing an adaptive, forward-thinking organizational environment. Whereas vision, engagement, and governance are essential for initiating and managing change, technology leadership improves the digital platform and smooths relations between IT and business leaders and a strong, adaptive culture—shaped by, and reflective of, those foundational elements—creates the enduring environment in which innovation thrives.

Understanding Organizational Culture
Throughout this course we have seen that digital transformation is not a simple task of adopting a new technology. Successful digital transformation, as with previous technological changes in industry, requires changing the way an organization does business.

Poll
Results


“Culture is what happens when the boss leaves the room.”
Anonymous

Organizational culture is more than just a set of abstract ideals—it is the shared values, goals, attitudes, and practices that define how an organization operates. It shapes the workplace environment, influences decision-making, and guides employee behavior. In many ways, company culture acts as the invisible force that determines how people collaborate, how challenges are approached, and how success is measured.

Management scholar Edgar Schein offered the following definition of organizational culture:

“Organizational culture is the pattern of basic assumptions which a given group has invented, discovered, or developed in learning to cope with its problems of external adaptation and internal integration, which have worked well enough to be considered valid, and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”
Edgar H. Schein, 1983

This definition provides a strong foundation for understanding how the beliefs and actions of a group comprise its general culture.

At its core, organizational culture defines the “personality” of a business. Whether an organization emphasizes innovation, customer service, operational efficiency, or employee well-being, these priorities are reflected in everyday interactions and expectations. Culture is not simply a statement on a website or a slogan in the office; it is embedded in the processes, workflows, and decisions that drive the organization forward.

For instance, in an organization that values transparency, workflows may prioritize open communication and shared decision-making. Employees might regularly provide feedback, leadership may embrace open-door policies, and major business choices may be discussed collectively rather than dictated from the top down. In an organization that prioritizes speed and adaptability, decision-making might be decentralized and emphasize quickly experimenting with new approaches.

The way work gets done is also shaped by cultural expectations around collaboration, autonomy, and accountability. In a hierarchical company culture, processes might be highly structured, with clear chains of command and formal approval mechanisms. Conversely, a more flexible or entrepreneurial culture might encourage employees to take initiative, experiment with new solutions, and iterate quickly based on results.

For our purposes, we will contrast two types of culture.

Traditional cultures often emphasize stability, well-defined processes, and a clear hierarchy, ensuring consistency and minimizing risk. These cultures excel in industries where compliance, precision, and long-term planning are critical.

AI-ready cultures, on the other hand, prioritize adaptability, innovation, and rapid decision-making. They are built to embrace change, using and utilizing data, technology, and agile methods to stay competitive in fast-moving markets.

In today’s rapidly evolving technological landscape, marked by the increasing integration of AI across industries, organizations must cultivate an “AI-ready culture” to thrive. Such a culture is not merely about adopting the latest technologies but also about creating an environment that embraces change, empowers employees, and prioritizes ethical considerations.

Following Schein’s assertion that culture is built upon assumptions, digital- and AI-ready culture encourages curiosity and constant questioning. At its core, the transition away from traditional company culture is characterized by adaptability and innovation. In practice, this means the organization is fast, innovative, and continually ready for change. It prioritizes experimentation and learning over rigid adherence to traditional methods. This involves a willingness to experiment with AI and other digital tools and with new practices. Yet, it still has guardrails that manage risk while enabling innovation. Agility enables the company to quickly respond to new challenges and opportunities, turning potential disruptions into competitive advantages.

In addition, AI-ready culture requires a fundamental shift in perspective regarding the role of AI. Rather than viewing AI as a replacement for human workers, an AI-ready culture sees it as a tool for augmenting human capabilities. This ensures the focus shifts to how AI can assist employees in their tasks, freeing them up to concentrate on activities requiring creativity, critical thinking, and complex problem-solving. By embracing this collaborative human-machine partnership, organizations can leverage the strengths of both humans and AI to drive innovation and achieve unprecedented levels of performance.

Key Components of an AI-Ready Culture
Organizational culture is shaped by the interplay of values, practices, and underlying assumptions. Among these, values are foundational—they guide what is considered appropriate, influence how people assess others’ actions, and shape how they approach their own work. When values are out of sync with actual practices, employees may question their authenticity. Likewise, if the values promoted by leadership do not align with the assumptions employees hold, resistance to change is likely. In such cases, leaders must help shift those assumptions to reflect new realities, or risk undermining the change effort.

In AI-ready organizations, aligned values, practices, and assumptions create a culture capable of embracing transformation. Leaders play a critical role in fostering these elements to build an environment that is not only agile and adaptive, but also equipped to deploy AI technologies in ways that are effective, ethical, and sustainable.

Values
Practices


Assumptions
Values
Dr. Westerman’s research identified four values that are dominant in AI-ready cultures (Westerman et al., 2019). While traditional cultures might also exhibit these values, AI-ready organizations typically promote all four of these values.

Speed
Impact
Autonomy
Openness
AI-ready organizations move fast and iterate quickly, rather than waiting to have all the answers. They prioritize speed over perfection, using rapid prototyping to test ideas and refine them based on feedback. Waiting for lengthy decision processes or detailed plans before acting can hinder progress in a digital environment. Sometimes, the only way to find the answer is to put something out and see what works.

It is important for leaders to both communicate these values and make them real for employees through actions and decisions. Leaders must also reinforce them through their own actions and by rewarding or correcting the actions of others. As we have seen from the examples of the companies above, leaders have made these values real through practices, not only touting them as slogans and philosophy statements.

Practices
The values shared by AI-ready organizations lead to the adoption of certain practices, to a greater or lesser degree. Members of organizations which value speed and autonomy are likely to practice rapid experimentation and prototyping, for example. The adoption of these practices falls along a spectrum, with AI-ready organizations more likely to rapidly experiment and exhibit data-driven decision-making, while traditional organizations are more likely to focus on stability and safety.

Rapid Experimentation

Testing ideas quickly and learning from the results

Self-Organizing Teams

Allowing teams to define their own workflows and make decisions collaboratively

Data-Driven Decision-Making

Using data to guide strategic choices and measure performance

Customer Obsession

Prioritizing customer needs and feedback in every aspect of the business

Results Orientation

Focusing on measurable outcomes rather than process adherence

Acting With Integrity

Maintaining ethical standards while pursuing innovation

Seeking Stability

Providing employees with a sense of security even in fast-changing environments

Strictly Conforming to Rules

Requiring employees to strictly adhere to established organizational rules

Activity
Spectrum of Practices
These practices exist on a spectrum, where some are more common in large traditional companies and others are more common in those born in the digital age. In what order do these practices belong? Which are common to AI-ready organizations? Which are common to traditional organizations? And which are shared by these two?

Drag each practice to the type of organization you think they fit.

Obsessing over customers: Maintaining continual focus on meeting the stated and unstated needs of current and potential customers
Seeking stability: Aiming for reliability and predictability in stakeholder interactions, operations, and employee work life
Rapid experimentation: Constantly and systematically experimenting, learning from the results, and quickly applying new insight
Focusing on results: Continually striving for measurable results instead of just processes and promises
Self-organizing: Collaborating fluidly across functional, geographic, hierarchical, and organizational boundaries to get things done
Driving decisions with data: Collecting and using accurate data to make decisions and solve problems
Acting with integrity: Being honest, behaving ethically, and striving for positive outcomes for all stakeholders
Strictly conforming to rules: Seeking to avoid problems and maintain reliability through rules
Undo
Submit
Except for strictly conforming to rules, which can inhibit innovation and change, the practices at the traditional end of the spectrum are not inherently undesirable. Certainly, some digital-native companies have faced criticism for ethical lapses. While rapid experimentation and self-organization fuel innovation, without the robust governance discussed in previous modules and overall guidance, employees can burn out or face abuse. The key challenge is to build a digital culture that drives innovation while upholding integrity and stability. Research shows that maintaining integrity and stability does not hinder innovation, profitability, or customer satisfaction, but rather helps traditional and maturing digital firms blend the best of both worlds.

Build
Preserve
Reorient
Source: (Westerman et al., 2019)

Activity
Traditional and Digital-Ready Practices
Match the following practices with traditional company cultures or digital-ready company cultures.

Drag each practice to the category you believe they fit.

A worker manually inputs data into a database to ensure accuracy and maintain established quality control standards.
A product team launches a one-week pilot of a new feature, gathering rapid user feedback to make immediate improvements.
An employee attends weekly online training sessions to master new digital tools that enhance their work efficiency.
A cross-functional team makes on-the-spot decisions during a daily stand-up meeting without waiting for upper management’s approval.
A marketing team carefully assesses new advertising strategies to ensure they align with the brand’s long-standing reputation and core values before testing if they will work with customers.
An employee follows a clear, multi-level approval process—from supervisor to executive—to ensure new software purchases meet comprehensive organizational standards.
A manager conducts annual performance reviews using a standardized set of criteria, providing employees with a clear, consistent framework for long-term development.
After a pilot project doesn’t meet expectations, the team holds a short debrief session to extract lessons and iterate quickly.
A marketing team utilizes a live analytics dashboard to monitor campaign performance and adjust strategies in real time.
A development team employs traditional programming frameworks that have reliably supported their software quality and operational stability over time.
HR revises its remote work guidelines monthly to quickly adapt to changing employee needs and external market conditions.
A finance team member focuses on their specialized role, deepening their expertise in budgeting and financial management to support the organization’s long-term goals.
A manager hosts brief daily huddles with the team to review progress and provide immediate feedback, replacing annual reviews.
Staff use detailed procedure manuals to perform tasks with precision, ensuring that every step aligns with established protocols and quality standards.
A digital feedback tool allows customers to vote on new feature ideas, directly influencing the product roadmap.
Any changes to a project plan are carefully reviewed by management through a structured sign-off process, ensuring that decisions are well-aligned with strategic priorities.
​A product team follows a well-defined, long-term roadmap that reflects the company’s vision and stability while incorporating customer insights at regular intervals.
​Customer feedback is gathered through scheduled surveys and formal channels, allowing the organization to analyze responses carefully and address concerns in a systematic way.
​Teams from design, engineering, and sales regularly join creative workshops to brainstorm innovative solutions together.
​The operations team holds regular retrospectives to refine their workflows based on the latest insights and emerging technologies.​


Undo
Submit
Forum: Common Practices in Traditional vs. AI-Ready Cultures
For your organization, or one you are familiar with, consider the spectrum of practices above. In this forum, share which practice is most important for supporting a digital- and AI-ready culture. Which practice does your organization need to drop?

You will find all forum details in the virtual campus.

Assumptions
While values and practices provide a surface-level view of an organization’s AI-readiness, there is still a crucial layer of hidden assumptions that leaders must confront to truly support an AI-ready culture. Leaders may need to challenge legacy or pre-digital assumptions to enable the adoption of AI-ready values and practices.

“Assumptions are not bad or good. They’re an essential part of how we think and act.”
Dr. George Westerman

Assumptions act as guiding principles in our work, but leaders need to be mindful of them across various facets of their organization. It is crucial for leaders in the digital age to recognize prevailing assumptions, understand when to use them, question them, and think differently about them. (Brown, 2022)

In the workplace, assumptions can be valuable as they align people along a common viewpoint and create a shared language and way of decision-making. But they can also reinforce prevailing unconscious biases, which can cause people to resist transformation. (Brown, 2022)

Consider some common organizational assumptions. Are they held in your organization?

Digital Transformation Is a Technological Challenge
The Regulators (or the Unions) Will Never Let Us Do That
Customers Value the Human Touch
Employees Will Work the Way We Tell Them To
Assignment: Rethinking Management Assumptions in AI-Driven Digital Transformation
The hidden assumptions of an organization’s culture may hinder the acceptance of AI-ready values or the adoption of AI-ready practices if they are not aligned. In this assignment, you will identify assumptions that you believe organizations in general or in your field will need to question as they prepare an AI-ready culture.

You will find all assignment details in the virtual campus. ﻿

Reflect
When transformations fail, people often point to culture as the culprit. Famed management scholar Peter Drucker often said “culture eats strategy for lunch.” But culture is not an immutable thing. It is created by the way leaders lead, hence leaders can change it if they lead properly. Doing so means adjusting and aligning three key elements of culture—vision, practices, and assumptions—and then constantly reinforcing them with everything you say and do. This does not have to happen only at the top of the company. Leaders can build the right culture in the units they control, even if the rest of the organization is not yet ready.

How have you seen leaders build or reinforce the right (or wrong) culture? As a leader, what will you do to steer your organization’s culture, at any level, in the right direction?

Skip to content
Home	Menu
Previous
Next
2. Technology Leadership
In the landscape of digital and AI transformation, the relationship between IT and the business units is crucial for success. Too often viewed as a support function, IT must evolve into a strategic enabler that drives innovation and competitive advantage. This transition requires a fundamental shift in mindset, organizational structure, and leadership approach for both technology and business leaders. It has become more complicated in recent years as some organizations have created digital teams separate from IT, others have hired technology people in business units, and many have begun to create AI-focused groups separate from all of them.

From Support to Strategic Enablement
The Importance of the IT-Business Relationship
The shift from order-taker to strategic partner requires a change in mindset, skill sets, and organizational structures. It requires leaders on both sides to build mutual trust and shared understanding (Siamonova et al., 2024). IT leaders must gain greater awareness of business strategies, and business leaders must develop a deeper understanding of technology. They must understand each other's perspectives and believe they can collaborate to achieve their goals. These two must work together to address their legacy IT systems, which can be built in compromised or entangled ways. The following sections will explore the key steps organizations can take to position IT and its leaders for success in the age of AI.

Who Transforms the Digital Platform: IT or Business Leaders?
One of the most essential functions of IT leaders is building and overseeing the digital platform. A robust digital platform is the cornerstone of digital transformation, comprising the technology, applications, and data that drive a company’s business processes (Bonnet & Westerman, 2020). This platform has three key elements: the core platform, the externally facing platform, and the data platform—each essential to creating a seamless digital experience.

Core
Flip
The core platform forms the technology backbone. It supports operational and transactional systems—such as back-office systems and systems of record—that underpin a company’s critical processes. To be effective, the core platform must be well-structured, efficiently managed, and kept as simple as possible to meet its essential functions.

Flip
External Facing
Flip
The externally facing platform, powers websites, mobile apps, and other channels that connect the business with its customers and partners. It not only provides an attractive interface but also integrates with the core system to handle transactions like payments, while enabling agile customer-facing experiments and personalized experiences.

Flip
Data
Flip
The data platform aggregates diverse data sources—ranging from images and voice to other media—to enhance both customer experience and internal operations. By enabling systems and employees to convert raw data into actionable insights, the data platform fuels digital innovation and supports informed decision-making.

Flip
Source: (Bonnet & Westerman, 2020)

For instance, a retail company might rely on its core platform for processing transactions, use its externally facing platform to deliver personalized shopping experiences, and leverage its data platform to analyze consumer trends—all working in concert to drive business growth and operational efficiency.

Although IT and business leaders bring different expertise to the table, they cannot operate in isolation. Key decisions must be made through collaboration, not simply handed off. Successful transformation depends on more than just technical skill—it requires mutual understanding and shared accountability. IT leaders need to speak the language of business, focusing on value rather than just technical merit. In turn, business leaders must recognize how their choices impact the platform’s cost, security, and agility, and involve IT in critical decisions.

To enable this, both sides must foster a culture of shared standards and open collaboration without compromising speed or execution. This partnership aligns technology efforts with strategic business goals, driving innovation and long-term advantage. Building such a partnership starts with elevating IT to strategic roles and strengthening communication between both groups.

The Evolving Role of IT: From Order-Taker to Strategic Partner
The rise of AI and digital technologies is redefining the role of IT, demanding a more proactive and integrated approach. IT’s functions must now extend beyond traditional support to become integral in shaping strategy, driving innovation, and ensuring the secure and effective deployment of AI solutions.

It may be helpful to think of this process as akin to building a new house on top of an old foundation. Leaders are not erasing the department’s history, but they are building something new and modern.

It is essential to involve the IT team right from the start. Evolving from support to strategic enabler means that the IT department is not only there to simply “keep the lights” on anymore. They know details on business processes and how they link with each other. They possess necessary expertise in data management, cybersecurity, and cloud computing, and are therefore essential for making this transformation successful.

They are the architects of this new digital house, ensuring everything is built right and ready for the future.

Developing Mutual Trust and Shared Understanding
Ensuring the IT team successfully evolves requires IT leaders to transition from tactical implementers to strategic decision-makers. To truly thrive in the age of AI, organizations must empower IT and digital leaders to be equal partners in shaping strategy, driving innovation, and creating competitive advantage. This is not a one-way street. Of course, business leaders reshape their organizations and products, but tech leaders must build understanding of the business so that they can see the rationale and suggest alternative approaches. They often have very good ideas about what is possible and what challenges may exist, but may need to learn to communicate in business terms. This means developing a strong understanding of business principles, possessing business savvy, and playing a leading role in driving transformation and business process improvement.

To achieve this evolution, consider these points:

Evolving Expectations
Flip
The role of the IT leader is changing due to AI and digital transformation. IT leaders need to possess a strong understanding of business principles, market dynamics, and competitive landscapes. They are now expected to contribute to strategy rather than just execute tasks.

Flip
Strategic Alignment
Flip
IT strategy must align with overall business goals, positioning IT leaders as key players in achieving these objectives.

Flip
In many ways, IT leaders and business leaders have existed in different worlds with a different understanding of needs and objectives. And it is important to remember, not every IT person needs to do this, just the ones that work with business leaders or build applications for the business. For example, when IT and business leaders plan an AI innovation, they are likely to consider certain aspects from their different points of view. IT leaders may focus more on how maintainable a system will be after it is built, or how it integrates with other systems. Business leaders, on the other hand, may be more focused on achieving their specific goals quickly, in the way they want to do it. Many times, these two groups may be “speaking a different language.” While neither side is incorrect, discussions may be hampered due to lack of perspective and misunderstandings of the other point of view.(Westerman, 2012)

One clear example of what can happen when IT and business leaders do not communicate well is the creation of “legacy spaghetti.”


Technology leaders use the term “spaghetti” to describe how older systems in traditional companies often become tangled and overly interconnected. These legacy systems can slow down decision-making, increase maintenance costs, and reduce the overall agility of the organization. The challenge lies in untangling these systems without disrupting core operations. Transitioning from legacy spaghetti to “ravioli” systems involves breaking down monolithic systems into smaller, self-contained components that can be easily changed without affecting other components, and rearranged into new combinations. This architectural shift enables greater flexibility, faster deployments, and improved system resilience, making the organization more adaptive to technological change.

The creation of “spaghetti” through the misalignment of business and IT goals and capabilities underlines the need for opening lines of communication between IT leaders and business leaders. As IT leaders are brought more closely into strategic decision-making it is essential for successful digital transformations that IT perspectives are not only heard but are also drivers of change. In the end, both sides need to learn how to talk on the other’s terms and how to express their goals in a way the other side can understand.

For IT professionals aspiring to be seen as strategic business partners rather than just support staff, self-reflection is essential. Ask yourself:

Am I positioning myself as a business enabler or just a technical expert?
Am I communicating in a way that business leaders understand, or am I only speaking in technical jargon?
Do I demonstrate value through measurable outcomes?
Building trust and credibility is key. If colleagues see you as competent, reliable, and able to understand their challenges, they will be more willing to collaborate and involve you in decision-making.

Agility in Technology Leadership
Agile is a flexible product development approach that emphasizes speed, collaboration, adaptability, and customer feedback. Emerging in the 1990s as a response to rigid traditional methods, Agile was formalized in 2001 with the Agile Manifesto (Beck et al., 2001), which prioritizes individuals, working solutions, customer collaboration, and responsiveness to change. Unlike sequential processes like Waterfall, Agile operates in short iterative cycles (sprints), enabling teams to continuously refine their work.

Agile methodology, when implemented correctly, provides a structured yet flexible approach to managing projects that achieve results quickly. A crucial element is having a product owner—someone from the business side who has the authority to make decisions and implement changes in real time. This eliminates long delays caused by waiting for executive approvals or steering committee meetings. Instead, decisions can be made immediately or within a day, accelerating progress and clarity.

Agile is about breaking large problems into manageable pieces, and iterating to learn continuously. However, a common challenge is aligning Agile processes with traditional business expectations. Agile teams often struggle to commit to delivering specific features by a set date because the process is inherently about discovery. Instead of rigid deliverables, goals should be framed in terms of outcomes such as increasing revenue or improving customer satisfaction. Then the agile teams, collaborating with the product owner, can iteratively develop features that achieve those goals.

Early adopters of Agile faced resistance from leaders accustomed to structured, long-term planning. Over time, organizations learned that Agile is not about having a fixed roadmap but about refining the solution through ongoing development.

Traditional Waterfall vs. Agile
A key leadership decision is knowing when to move quickly and when a more deliberate approach is needed. In the past, IT systems were built like factories—designed entirely upfront before execution. That model made sense when development cycles were long and resources were scarce. However, today’s fast-moving business environment requires a different mindset.

Leaders should ask:

In what situations does a traditional approach add value?
When does using a traditional approach, instead of an agile one, create unnecessary risk?
For industries driven by customer experience and rapid innovation, sticking to a fixed plan is often a mistake. Instead, the best approach is to experiment, iterate, and refine solutions based on real-world feedback.

Major transformations with generative AI are still evolving, but most companies are taking incremental steps to build capability while managing risks. Many organizations are keeping humans in the loop to refine AI models and maintain oversight. This measured approach allows businesses to develop AI expertise while mitigating uncertainty.

Successfully implementing Agile requires strong leadership and often benefits from an experienced Agile coach. Once a few teams see success with Agile, leadership can address resistance by highlighting those wins.

A common challenge is getting hesitant teams on board. Rather than forcing compliance, leaders should encourage conversation: “Why are some teams able to work effectively in this model while others have challenges?” Most Agile teams ultimately report higher productivity, faster decision-making, a greater sense of accomplishment, and often better work-life-balance. The key is to start pilots with a mix of individuals—not just the most innovative employees—to prove that Agile can work across the organization.

By focusing on gradual adoption and alignment with business goals, organizations can navigate digital transformation more effectively.

Skip to content
Home	Menu
Previous
Next
3. Helping Employees Feel Ready for the Future
Having a workforce that is prepared, willing, and able to embrace change facilitates the development of an AI-ready culture and the process of digital transformation in traditional organizations as well as those seeking the final move to digital mastery. As discussed in the previous sections, establishing a forward-thinking culture and improving mutual trust and shared understanding among IT and business leaders are foundational steps. However, none of this can be successful if employees do not feel ready for the change.

Employees will be more comfortable and confident with change if they have the skills, knowledge, and mindset to thrive in an AI-powered future. Reciprocally, these employees will be better able to engage in the types of change leaders are driving. Cultivating such a workforce involves continual development, aided by understanding the broad reach of digital transformation. We will dive deeper into this important issue in a later module.

Organizations must focus on agile and career-oriented learning, recognizing that digital transformation affects all roles, not just those traditionally considered “technical.” This entails providing accessible, personalized learning experiences and offering clear pathways for career advancement. By creating a culture that values continuous growth, transparent communication, and proactive engagement, leaders can empower their employees to not only adapt to change but also to drive innovation and achieve their full potential.

In previous modules, we saw examples of AI-powered digital transformation’s reach and how workers’ tasks are being augmented by AI and ML systems. However, these examples were all focused on processes, operations, or products, and AI was largely framed as a tool for improving efficiency, reducing costs, or creating new business opportunities. While these are critical aspects of digital transformation, they represent only part of the picture. The full potential of AI-driven transformation lies not just in what it changes externally, but in how it can support internal, human-centered growth.

Ultimately, effective leadership is less about the technology itself and more about the art of leading people through change. Digital transformation transcends the mere implementation of new tools and systems; it is fundamentally about cultivating a people-centric culture where every individual is valued, engaged, and equipped to grow. Leaders must focus on empowering their teams, encouraging an environment of trust, and enabling open communication to help employees navigate and embrace the shift towards a digital future. By centering their approach on the human element of transformation, leaders can build resilient, innovative teams that drive sustainable organizational success.

Conclusion
When we shift our focus to the workforce itself, we see that AI is also a catalyst for individual transformation. Beyond task augmentation, AI can help organizations identify skill gaps, personalize learning pathways, and deliver retraining at scale—making it a key enabler of workforce development. In this way, AI becomes not just a system of productivity, but a system of empowerment. Having an engaged, future-ready workforce is essential to any successful digital transformation initiative. In a future module, we will explore how organizations can support employees in transforming their skills, mindsets, and roles to participate fully in the digital era.

Course Project Part 6: Is Your Organization Ready for Digital Transformation?
For this part of your course project, you will assess the culture of your organization and evaluate how suitable it is for your digital transformation initiative. By examining the current state of your organization's culture, you will be better able to steer change and drive transformation.

You will find all project details in the virtual campus.

# Module 7
Skip to content
Home	Menu
Previous
Next
1. The Speed of Innovation
Recall the Gartner Hype Cycle introduced earlier in the course. This is a framework for understanding the development of expectation and attitudes towards technologies over time. New technologies often rise to a “peak of inflated expectations” before falling into a “trough of disillusionment.” We may likely be experiencing this rapid rise with generative artificial intelligence (GenAI). From the release of ChatGPT in November 2022, countless articles, papers, and other media have been published, inflating the expectations of large language models (LLMs). The 2024 Gartner Hype Cycle now places GenAI on the opposite side of the slope, descending toward the trough of disillusionment (Jaffri, 2024), so we may now expect to see an increasing number of articles deriding or ridiculing this particularly visible hype cycle and GenAI in general.

The Gartner Hype Cycle
Flip
Flip
Adapted from: (Jaffri, 2024)

While not all technologies follow these dynamics, it is important that leaders keep an eye on potential future technologies and think strategically about how these tech advances may impact their businesses and industries in the near, medium, and distant futures. From developments in laboratories, through testing, use case identification, and adoption, technologies can take 10 to 20 years, or more, to mature and reach mass adoption.

Consider the zipper and Velcro. How long do you think it took these technologies to gain mainstream adoption?

Zipper
Flip
The modern zipper was patented in 1913. In 1923, zippers appeared on rubber boots and in 1925 they made their first appearance on clothing. It took 12 years for the zipper to mature to its common use case.

(Anthony & Westerman, 2025)

Flip
Velcro
Flip
Velcro was conceived by George de Mestral in 1948 while on a hike. It was first patented in 1955 and appeared on the first Velcro shoes in 1968. Velcro took 13 years to mature, and many more years to reach mass adoption.

(Anthony & Westerman, 2025)

Flip
The same more or less holds true for other technologies such as the organic light emitting diode (OLED) which took around 25 years from initial patent to inclusion in Samsung Galaxy phones in 2010 with active matrix OLEDs. Of course, this time frame will not hold true for every technology, but it is useful to keep in mind.

The Gartner Hype Cycle is not the only framework available for examining technology measuring and forecasting. Different organizations will naturally offer different perspectives on various technologies. These are useful tools for leaders to keep abreast of developing and maturing technologies.

As we explore some of the emerging technologies in the following pages, keep the Gartner Hype Cycle in mind. Also keep in mind some technologies that have arisen—or failed—during your lifetime.

Forum: Technology Hype Cycles in Your Industry
Different industries experience different hype cycles. What technologies have come and gone, or come and stayed, in your field? Use this forum to reflect on hype cycles you have witnessed and read about perspectives from other fields.

You will find all forum details in the virtual campus.

Skip to content
Home	Menu
Previous
Next
2. Integrated Photonics
In the rapidly evolving landscape of emerging technologies, integrated photonics stands out as a transformative approach to optical system design and miniaturization. Traditionally, optical devices such as spectrometers, LiDAR systems, and fiber-optic communication networks relied on large-scale, free-space optical components (Anthony & Westerman, 2025). However, advancements in semiconductor fabrication have enabled the integration of optical components onto a single chip, revolutionizing multiple industries.

Fundamentals of Integrated Photonics
Integrated photonics can be best understood through its parallel to the evolution of electronic circuits. Just as microelectronics revolutionized computing by integrating transistors onto semiconductor chips, integrated photonics seeks to embed optical components—such as lasers, waveguides, resonators, interferometers, and detectors—into a compact, scalable format, mirroring the miniaturization seen in integrated electronics (Tran et al., 2022; Anthony & Westerman, 2024). By replacing traditional bulk optics like lenses and mirrors with chip-scale photonic architectures, integrated photonics enables more compact, efficient, and scalable optical systems. This advancement supports a wide range of applications, from high-speed communications and sensing to optical signal processing and quantum computing.

Definition
Integrated photonics is the miniaturization of optical systems onto a chip using semiconductor-like fabrication techniques.

Benefits of Using Photonic Circuits
Manufacturing Process
The fabrication of photonic circuits uses processes very similar to the layer-by-layer etching and deposition techniques employed in semiconductor manufacturing, often utilizing silicon wafers as a substrate (Tran et al., 2022; Anthony & Westerman, 2024). This allows integrated photonics to leverage existing semiconductor fabrication plants (commonly referred to as “fabs”) and design tools, facilitating mass production and improving cost efficiency. By leveraging and extending these established processes, integrated photonics aims to create high-performance optical devices at scale, significantly reducing the size and complexity of traditional optical components.

Comparison to Traditional Optics
Conventional optical systems typically involve large optical assemblies with extensive free-space propagation of light. These systems rely on discrete lenses, mirrors, and beam splitters to manipulate light. In contrast, integrated photonics routes and controls light on-chip using components such as waveguides and miniature laser sources, allowing for greater miniaturization and integration with existing electronic systems (Tran et al., 2022; Anthony & Westerman, 2024).

While the initial development cost for specialized integrated photonic circuits can be high, the cost benefits become significant with mass production, much like in the semiconductor industry (Tran et al., 2022; Anthony & Westerman, 2024). The ability to scale production enables widespread adoption across industries, including telecommunications, autonomous vehicles, and biomedical sensing. Additionally, the shift from traditional optics to integrated photonics facilitates greater energy efficiency, a key advantage in data centers and high-speed computing applications.

Current Applications and Limitations
Integrated photonics is actively transforming several sectors, most notably in high-speed data communication and optical radar-like sensing, leveraging the advancements and infrastructure of the established semiconductor industry (Tran et al., 2022; Anthony & Westerman, 2024).


Data Centers and High-Speed Communication

Autonomous Vehicles and LiDAR

Miniaturization of Optical Instruments
Challenges and Limitations
While integrated photonics offers significant advantages, several challenges must be addressed before widespread adoption can be realized.


Manufacturing costs and scalability


Application maturity

Which obstacle do you feel provides more of a challenge to the wide-spread adoption of integrated photonics: reducing costs or identifying applications? Share your thoughts in the Padlet below.

To create a pin, click on the ""+"" button in the bottom-right corner. Type your answer, click ""Publish"" and reposition the pin as needed. You can change the color and edit your pin by clicking on the menu (three dots) on the right side of your pin.

Important note: The following interactive element can be challenging to view or interact with on smaller handheld mobile devices. It is recommended to use a desktop, laptop, or tablet to ensure full accessibility.


Skip to content
Home	Menu
Previous
Next
3. Advanced Laser Sensing
In recent years, integrated photonics has emerged as a transformative technology in the field of advanced sensing, enabling highly sensitive and miniaturized detection systems that span a wide range of industries. Through the development of optical circuits on a chip, photonics has not only enhanced existing sensing techniques but also unlocked entirely new possibilities for precision measurement and environmental monitoring (Zhang et al., 2023).

Sensors are integral to modern society, particularly in optimizing energy systems and process industries in the context of global warming and environmental pollution. Laser-based optical sensors are particularly well-suited for achieving accuracy, sensitivity, selectivity, portability, speed, safety, and intelligence in sensing applications.

Fundamentals of Laser Sensing
The fundamental basis of laser sensing lies in the interaction between photons and matter at a microscopic level, which is governed by the laws of quantum mechanics. Various laser-based sensing techniques exist, each distinguished by their physical principles, implementation strategies, and hardware requirements.

Current Applications
Photonics-Enabled Sensing
Ring Resonators for Ultra-Sensitive Detection
Non-Contact Measurement Techniques: Laser Ultrasound
Photoacoustic Effect: The Science Behind the Laser Ultrasound
Industry Perspective
The newly developed terahertz laser by MIT researchers, which simultaneously achieves high power, a tight beam, and broad frequency tuning, is seen as valuable for a wide range of applications in chemical sensing and imaging. Notable potential applications include chemical detection in outer space (selected for a NASA mission), improved skin and breast cancer imaging, and detecting drugs and explosives.

Integrated Photonics and Advanced Laser Sensing Summary
Integrated photonics and advanced laser sensing are emerging as transformative forces in optical system design, promising to redefine industries from high-speed data communication to autonomous vehicle navigation and precision healthcare diagnostics. By miniaturizing traditional optical components onto semiconductor chips, this technology not only mirrors the revolutionary impact of microelectronics but also unlocks new capabilities in environmental monitoring and material inspection through innovations like ultra-sensitive ring resonators and laser ultrasound.

Despite its vast potential, significant challenges remain. Manufacturing costs, scalability issues, and the integration of photonic systems with existing electronic infrastructures continue to pose hurdles. Moreover, the path to commercialization is marked by distinct stages—from the current expansion in data centers and LiDAR applications to the medium-term emergence of specialized uses in healthcare and quantum technologies, and ultimately the long-term vision of ubiquitous, fault-tolerant systems.

In this rapidly evolving landscape, leadership is crucial. Business and policy leaders must proactively monitor technological advancements and strategically invest in research, development, and talent to bridge the gap between innovation and market-ready solutions. By fostering a culture of continuous learning and collaboration, leaders can navigate the complexities of commercialization, mitigate risks, and harness the transformative power of integrated photonics. This proactive approach will ensure that organizations not only adapt to the changes brought about by these emerging technologies, but also drive future breakthroughs in optical sensing and communication.

Remember also that most companies will adopt technologies like these rather than invent or advance them. Think about the mobile applications you use. Phone manufacturers create the technologies, but businesses create value by identifying new ways to work using those technologies. Similarly, advances in computers or communication or DNA sequencing will be created by a small number of researchers and companies, but used to transform processes in many companies. Learning to work with, and transform with, these technologies still require effort to understand technology trends and innovate with technologies, but it will be of a different type and scale than those aiming to advance the frontiers of the technologies themselves.

Skip to content
Home	Menu
Previous
Next
4. Quantum Technologies
Quantum computing represents a fundamental shift in computational paradigms, offering the potential to solve problems that are intractable for classical computers. Unlike traditional binary systems, which process data as bits that are either 0 or 1, quantum computers leverage quantum bits (qubits) that can exist in multiple states simultaneously (Schneider & Smalley, 2024a). This capability enables unprecedented computational power for specific applications, particularly in optimization, cryptography, and complex simulations (AWS, n.d.). However, quantum computing remains in the early stages of development, with significant technical challenges that must be overcome before widespread adoption. In parallel, quantum communication offers breakthroughs in secure data transmission through principles such as quantum key distribution and quantum entanglement (McKinsey & Company, 2025).

Important note - ﻿Quantum computing is a rapidly advancing field, with new discoveries and innovations emerging regularly. The content in this section reflects a specific moment in the evolution of quantum technology. Our focus is introducing the foundational concepts that underpin quantum computing—principles that remain essential even as the field continues to evolve.

The examples of quantum applications included in this section are not meant to be a comprehensive list. Instead, they are intended to provide a few basic ideas of what quantum computers may be capable of, helping you begin to understand the kinds of problems this technology could eventually address. By reflecting on how quantum is applied, you may be able to identify new areas in which the characteristics of quantum would fit.

Fundamentals of Quantum Technologies
To fully grasp the transformative potential of quantum technologies, it is crucial to understand the quantum mechanical principles that distinguish it from classical computing. Quantum technologies represent a fundamentally different approach, leveraging the strange and powerful behaviors of quantum mechanics to perform calculations that would be impossible or impractical for classical computers.

Recommended Video
Watch this video from the MIT Department of Physics that explains quantum mechanics. It discusses the shift from the first quantum revolution of information processing to the current era of Quantum 2.0. We are now leveraging quantum mechanical properties at a chip level to build technologies like quantum computers.

Quantum Explained
Visualizing Bit and Qubit
Quantum computers derive their power from quantum mechanical principles that differ significantly from classical computing. Superposition is the property of a quantum bit (qubit) that allows it to exist in a simultaneous combination of both the 0 and 1 states, unlike a classical bit which can only be one or the other. Entanglement allows two or more qubits to become linked in such a way that their states are intertwined, regardless of the distance separating them. Quantum interference allows the different probabilistic outcomes in a quantum computation to interact with each other, enabling the amplification of correct answers and the suppression of incorrect ones. If these features seem strange and difficult to understand, do not worry. Some of the best physicists in the world have struggled to explain and truly understand quantum concepts.

Superposition
Entanglement
Quantum gates
Probabilistic nature
Unlike classical bits, which can exist in one of two distinct states (0 or 1), qubits have the unique ability to exist in a superposition of states. This means that a qubit can represent both 0 and 1 simultaneously, as opposed to classical bits, which are constrained to a single state at any given moment. This property allows quantum computers to process a vast number of possibilities at once, dramatically increasing their potential for parallel computation. For example, one logical qubit could represent values from 0 to 7, whereas a classical bit can only represent 0 or 1. This inherent parallelism allows quantum computers to solve certain types of problems exponentially faster than their classical counterparts.



Source: (McKinsey & Company, 2025; Schneider & Smalley, 2024a)

Navigating a Maze: Classical Bits vs. Quantum Qubits
Imagine being stuck in a maze. In a classical computer, bits operate as binary switches (0 or 1) to sequentially explore each path in the maze, marking dead ends and retracing steps—a brute-force approach limited by linear processing. For example, solving a maze with 100 paths would require testing each individually, a time-consuming process.

In contrast, qubits leverage superposition and quantum interference to evaluate paths in parallel. Rather than “testing all paths at once,” qubits encode possible solutions as probability amplitudes—mathematical values that behave like waves. These amplitudes can:

Constructively interfere: Amplify the correct path’s probability (e.g., waves combining to form taller peaks)
Destructively interfere: Cancel out incorrect paths (e.g., waves neutralizing each other)
Imagine standing in the maze and sending out waves that ripple through all paths simultaneously. Paths leading to dead ends produce waves that cancel each other, while the exit path’s waves reinforce into a detectable signal. (Schneider & Smalley, 2024a)

Current Applications and Limitations
Quantum Computing
Quantum computing holds great promise across a variety of industries due to its ability to exploit quantum mechanical principles such as superposition and entanglement. These capabilities enable quantum systems to process and analyze information in ways that classical systems cannot (Schneider & Smalley, 2024b). Although still in its early stages, quantum computing is anticipated to revolutionize several fields, offering potential advancements that were previously unattainable.

Optimization Problems
Material Science and Drug Discovery
Machine Learning and AI
Quantum Communication
Quantum communication focuses on utilizing the principles of quantum mechanics to enhance communication capabilities, particularly in terms of security and, potentially, for new functionalities like a quantum internet. It leverages nonclassical states, such as superposition and entanglement, to achieve advantages over classical communication methods. (Lewis, 2022)

This field promises significant advancements in data protection and privacy, particularly in the realm of cybersecurity and secure networking. Unlike the more distant horizon of practical quantum computing, quantum communication technologies are already transitioning from research to real-world applications, providing more tangible near-term benefits.

Quantum Key Distribution
Post-Quantum Cryptography
Quantum Entanglement for Communication
Current and Near-Term Applications
Recommended Reading
Just as classical computers rely on interconnected components, future large-scale quantum computers will need efficient ways to communicate quantum information between multiple processors. However, current methods for interconnecting superconducting quantum processors primarily use “point-to-point” connections, which require a series of transfers between network nodes and lead to compounding error rates. Researchers at MIT have developed a new interconnected device designed to enable direct communication among multiple quantum processors. This device supports scalable, “all-to-all” communication, meaning that all superconducting quantum processors within a network can communicate directly with each other.

Read more about the project in the article, Device enables direct communication among multiple quantum processors, from MIT News.

Quantum Sensing
Quantum sensing involves utilizing quantum systems to create sensors with unprecedented sensitivity and accuracy for measurements in various areas. Quantum sensing is a tested technology with broad applications in commercial products (e.g., medical devices), in services (e.g., navigation), and as an enabler of internal processes (e.g., quality control). It enables many types of measurements that are currently too difficult, not precise enough, or simply unfeasible otherwise.

Imaging
Extreme Measurements
Navigation
Precise Quality Control
Source: (Soller et al., 2024)

Recommended Readings
For up-to-date news and research in the quantum field, check out the following resources:

The Quantum Insider
The Quantum Index﻿
Skip to content
Home	Menu
Previous
Next
5. Development and Adoption Timelines
It is important to be aware of emerging technologies because it allows individuals and organizations to anticipate their potential future impact and understand the “dynamic journey ahead” as these technologies evolve from the lab to the market. It can take a significant amount of time, on the order of 10–20 years, or more, for an idea invented in the lab to reach the marketplace. However, other technologies can mature and achieve adoption very quickly. Therefore, being aware of these early-stage technologies can help you plan for, and be ready to use, the right technologies at the right times. In this section, we will capture the current landscape and future potential of the technologies discussed in the previous sections. (Anthony & Westerman, 2025)

Integrated Photonics and Advanced Laser Sensing
The commercialization of integrated photonics and advanced laser sensing follows a trajectory influenced by technological advancements, market demand, and manufacturing scalability. While some applications are already in widespread use, others remain in early development.


Current and near-term implementation

Medium-term (3–7 years)

Long-term (7+ years)
Source: (Anthony & Westerman, 2024; Raskovich et al., 2024; Shekhar et al., 2024; Twineamatsiko et al., 2024)

Factors Influencing Photonics Adoption
Several factors will influence the rate at which integrated photonics is adopted. First and foremost, advances in silicon photonics and hybrid electronic-photonic integration techniques will be essential for optimizing performance and manufacturability (Shekhar et al., 2024).

To achieve the scale necessary for widespread adoption, significant investments in photonics semiconductor fabrication facilities (“fabs”) are crucial (Zhang et al., 2023). As manufacturing processes mature and become more efficient, costs will continue to decrease, enabling broader deployment.

The demand for energy-efficient, high-speed optical communication in sectors like data centers and telecommunications will be a major catalyst for adoption (Shekhar et al., 2024). Additionally, the growing importance of advanced sensing—whether for healthcare diagnostics, environmental monitoring, or industrial applications—will further drive the need for photonic-based solutions (Expert Panel, 2024). Finally, developments in fields such as AI, which increasingly requires specialized hardware, and the rise of spatial computing interfaces could create new applications and demand for integrated photonics in unforeseen areas.

Quantum Technologies
The path to the widespread commercialization of quantum computing is expected to unfold in several distinct stages. These stages will be shaped by a combination of technical breakthroughs, strategic government and corporate investment, and the gradual emergence of practical and economically viable use cases. While each stage presents its own set of challenges, they collectively highlight the promising trajectory toward the broader adoption of quantum computing.

Advances in quantum communication, QKD, and quantum sensors make it likely that we will see commercial use of some types of these technologies in the near-to-medium term. As organizations with advanced needs begin to use and improve these technologies in real-world applications, the technologies should reach the reliability and cost levels that other businesses will begin to adopt them.

Quantum computing is not yet as advanced for practical uses as quantum sensing or communication. However, industry experts are projecting practical use growing in the foreseeable future.


Short-term (1–5 years)



Medium-term (5–15 years)





Long-term (15+ years)



Recommended Reading
Listen to this MIT podcast episode, Understanding Quantum Computing. MIT Professors Peter Shor and Will Oliver have a discussion on the current state and future possibilities of quantum computing.

Trends in Private and Government Investments in Quantum Technology
In 2023, $1.71 billion were invested in quantum technology (QT) start-ups, a 27% drop from $2.35 billion in 2022. However, this decrease is smaller than the 38% drop in global start-up investments. Fewer QT start-ups were founded in 2023 than in 2022, with the totals being 13 and 23 respectively. The average deal size also fell to $40 million in 2023, down from $105 million in 2022 and $107 million in 2021. Additionally, the number of deals dropped to 171 in 2023 from 206 in 2022.

Public funding for quantum technologies (QT) rose over 50% in 2023 compared to 2022. While China and the United States have been the main sources of QT public investment, countries like Australia, Canada, Germany, India, Japan, the Netherlands, South Korea, and the United Kingdom have significantly increased their contributions. Notably, South Korea and the United Kingdom made substantial funding boosts, highlighting a growing recognition of QT’s importance by more governments.

Source: (Bogobowicz et al., 2024)

Assignment: Adoption Readiness of a Technology 
This assignment invites you to investigate an emerging technology, either from the module or relevant to your field, and analyze its adoption timeline and potential impact. By examining a real-world use case and the factors influencing its adoption, you will develop critical foresight skills essential for technology leadership in a fast-changing landscape.

You will find all assignment details in the virtual campus.

Skip to content
Home	Menu
Previous
Next
6. Other Emerging Technologies
There are, of course, several more exciting emerging technologies on the horizon today that are reshaping how we work, live, and connect with the world around us. In the following videos, Dr. Westerman and Dr. Anthony provide more detail and insights into agentic AI, health wearables, and spatial computing.

Agentic AI
Agentic AI systems go beyond passive data analysis; they are capable of autonomous decision-making and goal-driven behavior. These systems can plan, adapt, and act on their environment, often collaborating with humans or other agents in dynamic settings.


Recommended Reading
Read more about agentic AI in “Agentic AI: Autonomous intelligence for complex goals – a comprehensive survey.”

Health Wearables
Health wearables are smart devices worn on the body that continuously monitor physiological data such as heart rate, activity levels, sleep, and more. These devices are transforming preventive healthcare, chronic disease management, and personal fitness tracking.


Spatial Computing
Spatial computing blends physical and digital environments using technologies like augmented reality (AR), virtual reality (VR), and advanced sensors. It enables users to interact with digital content in real-world spaces, enhancing experiences in areas such as training, design, navigation, and collaboration.


Recommended Reading
Read about potential use cases of spatial computing in “Spatial commerce: Definition, use cases, strategies.”

Recommended Link
You can find out more about the applications of spatial computing technology in the “﻿IMMERSED” video playlist from MIT.nano.

Conclusion
As we have explored a set of cutting-edge innovations—from the precision of photonics and laser sensing to the disruptive potential of quantum computing, and beyond—it is clear that no single technology holds all the answers. It is important to note that our exploration is not exhaustive. Rather, effective leaders must recognize that each emerging capability follows its own maturation curve and that being mindful of hype cycles will help to avoid overinvesting too early or missing critical inflection points.

Preparing for tomorrow’s industry landscape means more than just tracking today’s capabilities—it requires continuous horizon scanning and strategic patience. Just as “becoming AI-ready” is an ongoing journey of learning and adaptation, so too must organizations stay attuned to where technologies are headed. Different sectors will gravitate toward different innovations, but all will benefit from leaders who balance enthusiasm with pragmatism, understand the lifecycle of emerging tools, and keep their eyes firmly on the horizon.

However, we must keep in mind that it is not the technologies themselves that transform organizations—it is the people who deploy, adapt, and champion them. Ultimately, understanding the technology landscape is really about envisioning how the capabilities of the new tools can enable new ways of doing business. The first law of digital innovation—technology changes quickly but organization change much more slowly—will be just as true for photonics and quantum as it was for internet, mobile, and AI. Tracking technology trends can speed your ability to innovate the way your company works. But in the end, you still need to build the organizational and leadership capabilities to envision and drive change in organizations that are built upon people, not just technology. In the next module, we will shift our focus from tools to talent, exploring strategies for positioning people to thrive in an ever-evolving world of innovation.

Course Project Part 7: Elevator Pitch Forum Post
In this assignment, you will craft a clear, compelling elevator pitch that communicates the core idea, value, and AI integration strategy of your project. This exercise marks your transition from planning to action, helping you refine your vision, gather feedback, and prepare for your final course submission.

You will find all course project details in the virtual campus.

# Module 8

Skip to content
Home	Menu
Previous
Next
1. Project Presentations
One of the most valuable aspects of this course has been the opportunity to learn from the experiences of others. Through the forums and interactive activities, we hope you have considered the differing perspectives your course mates have contributed. In the following videos, previous participants share the projects they developed during the course. These presentations offer a range of perspectives across industries, demonstrating how the principles of digital leadership and AI integration can be applied in diverse organizational contexts.

By exploring these real-world examples, you will gain insight into the challenges others have faced, the strategies they used to address them, and the impact of their solutions. As you watch, consider how their experiences might inform your own approach to digital transformation and leadership in the AI era.

Important note - Please review at least two presentations, as you will be asked to comment on two in the forum below. However, feel free to listen to all of the following presentations, as you may gain insights directly relevant to the project you are developing.

Greg Boone - AI in Marketing
Greg Boone is the CEO of Walk West, a “full service, integrated digital branding” firm based in North Carolina. In the following presentation, Mr. Boone will provide his perspectives on how he plans to use AI in transforming his organization to become an AI-powered human experiences company.


Sven Endres - Automating Logistics
Sven Endres presents an in-depth analysis of digital transformation opportunities for a mid-sized global company, focusing on how AI, IoT, and robotics can improve warehouse design, logistics, and support services. He identifies key challenges such as system integration, manual processes, and workforce transition, and outlines a roadmap that prioritizes targeted AI applications, digital twin streamlining, and organizational change management.


Tarek Daouk - AI for Hospitality
Tarek Daouk, a hospitality executive and entrepreneur, explores how AI and IoT technologies are transforming hotel operations by enhancing personalization, streamlining check-in processes, and improving back-of-house efficiency. He also emphasizes the importance of preserving the human element and navigating region-specific legal and regulatory frameworks during AI implementation.


Forum: Project Presentation Evaluations
In this forum, you will reflect on how innovative you found the projects presented in the videos to be and evaluate the former participants’ application of leadership capabilities. You will be able to share you industry perspective and gain insights from other fields on the presented approaches to AI-driven digital transformation.

You will find all forum details in the virtual campus.

Skip to content
Home	Menu
Previous
Next
2. Managing the Human Element
Transformation is an ongoing process. It does not end with strategies or technologies or project completion dates. It lives and breathes through the people who embrace and drive it. It is a fundamental change in mindset. As we close this course, remember that every framework, tool, and initiative we have discussed only succeeds when individuals choose to engage, learn, and lead. By focusing on the human dimension, cultivating shared purpose, building the right culture, and helping people see themselves in the transformation, you ensure that digital transformation is not just a moment in time, but a sustained, people-powered journey.


Building a People Empowerment Strategy for the AI-Powered World
By now you understand the importance of Westerman’s law, the fact that technologies change quickly but organizations change much more slowly. However, what is not always considered is how the nature of work and the needs of the workforce are changing too.

To ensure that AI-powered digital transformation is truly effective, organizations must recognize and address its broad reach, understanding that AI implementation affects all roles, not just those within IT. Providing training and career development support to help all employees adapt to new AI-driven technologies and processes is essential for ensuring that all members of the organization are able to engage in the change.

Our research shows that organizations—and parts of organizations—are following different strategies with regard to preparing their people for the changes that will come with increasingly AI-augmented business practices.

Broadly speaking, we have found that organizations are following four distinct strategies:

Doing Nothing
Predicting Job Trends
Building Digital Skills
Helping Workers Choose Their Own Futures
Source: (Davenport & Westerman, 2021)

Transforming Employee Learning
As organizations plan retraining and upskilling strategies, it is important to keep in mind that these activities themselves are being affected by AI technologies. Even as people learn new skills, the organization responsible for delivering those skills needs to transform.

No longer limited to delivering training and compliance programs, Chief Learning Officers, and their Learning & Development (L&D) teams, need to become strategic partners who shape enterprise capabilities and culture. While relatively few have stepped up to the challenge yet, research shows that these “Transformer CLOs” are redefining what learning means in their companies. They are leading three major transformations to ensure their companies are delivering the skills needed, in the way they need to be delivered: (1) rethinking learning goals, (2) reinventing learning methods, and (3) redesigning learning departments to support continuous, agile learning aligned with business strategy. Even if you are not responsible for L&D in your organization, it is worth understanding these shifts.

Transforming Learning Goals
Transformer CLOs are shifting focus from merely developing job-specific skills to cultivating broader capabilities such as digital thinking, adaptability, and a growth mindset. Leadership development is restructured to align with organizational strategy. Companies like Cargill and UBS are democratizing learning by extending high-quality development opportunities beyond top-tier leaders to all employees. Standard Chartered is emphasizing experimentation and data-driven decision-making. This new focus helps organizations build resilience by preparing employees for tasks and challenges that may not yet exist, emphasizing mindsets over narrow competencies.

Transforming Learning Methods
These CLOs are moving from a course-focused approach to an employee-focused one. They are embracing digital tools and peer-led models to personalize and scale learning experiences. Traditional classroom training is being replaced or supplemented with digital formats, mobile apps, games, and AI-powered recommendation engines. Learning is becoming more real-time, delivered in smaller pieces using a variety of formats. Organizations like DBS Bank and Accenture promote experiential learning, simulations, and real-time feedback to make training more relevant and engaging. Programs like GANDALF Scholars at DBS and “connected classrooms” at Accenture show how peer teaching and distributed learning environments can boost participation, reinforce learning, and empower employees as both learners and teachers.

Transforming Learning Departments
To support their expanded mandate, CLOs are redesigning L&D departments to be leaner, more strategic, and more collaborative. Rather than simply delivering content, they act as curators and co-creators, combining internal expertise with external resources to offer timely, high-impact learning. Teams increasingly use agile development models to create and refine learning modules, while data analytics helps evaluate and continuously improve content effectiveness. Peer learning forums, such as Deutsche Telekom’s “From Experts, For Experts,” show how bottom-up learning can be identified and scaled by an adaptive learning function.

In essence, these digital and AI tools not only broaden access to learning but also create dynamic, on-demand experiences that adapt to the ever-changing needs of the modern workplace, setting them apart from the one-size-fits-all approach of traditional classrooms.

Forum: Is Your Organization Prepared to Train for the Future?
In this forum, you will assess how well your organization is prepared to train employees for a digitally driven future. Reflect on existing programs, potential gaps, and how training efforts align with broader transformation goals.

You will find all forum details in the virtual campus.

Improving Career Development for Everyone
Companies tend to be very good at developing their high potential employees. A small percentage of people, selected for their potential to become the firm’s future top leaders, receive regular learning and mentoring support to develop the technical and managerial skills they need to advance in the organization.

However, in today’s times of rapid transformation, that is not enough. Employees at all levels may be concerned that their jobs will be destroyed, or their skills invalidated, by AI-powered change. Although companies cannot invest the same amount of time and resources in every employee as they do in their high potentials, they can do more to help every employee develop their careers.

First, organizations must ensure that opportunities for growth are visible to each employee. Second, they can provide opportunities for employees to learn and practice the skills they need. And third, organizations should establish feedback loops and coaching methods to help tune their development.

Providing Visibility Into What Is Possible
Employees cannot pursue opportunities they do not know exist, yet many companies lack visibility into internal roles and career paths. Even human resources (HR) teams often struggle to track openings across regions or business units. As a result, organizations frequently hire externally rather than matching internal talent to available roles.

Employees need guidance on potential new roles they can move into, whether upwards, horizontally, or diagonally in the organization. Most people do not know about, much less understand, other opportunities that are less obvious. Could an accountant move to a cybersecurity role, or a help desk person move to advanced manufacturing, or a receptionist into a lab technician role? Helping people understand alternative next steps from their current position can help them identify where they want to go inside the organization, instead of leaving them to look for opportunities elsewhere.

Tools like GE Digital’s Career Discovery and the University of Pittsburgh Medical Center’s (UPMC) Explore Careers help employees identify potential roles, skill gaps, and training opportunities, making career growth more accessible.

Internal job postings may highlight missing skills without showing how to bridge the gap. Companies like Unilever address this through structured programs that help employees set goals, build skills, and gain certifications. Encouraging managers to see internal transfers as growth opportunities rather than risks further strengthens internal mobility.

Building diverse internal networks also plays a key role in career development. Employees who connect with colleagues in different roles gain valuable insights into career possibilities and skill requirements. Companies like Accenture and DBS Bank foster these connections through global learning programs and peer mentoring. By making career pathways clearer and promoting internal talent, organizations create more engaged, adaptable workforces.﻿

Source: (Westerman & Lundberg, 2023)

Providing Opportunities to Learn and Practice
Organizations can help employees develop essential skills. Companies like Allianz, for example, use AI-driven learning platforms to recommend training based on employees’ existing skills and learning preferences. UPMC has defined structured learning pathways for employees at different career stages, bundling courses into self-paced programs that build both professional and personal skills. These structured approaches help employees gain expertise while aligning their development with organizational needs. ﻿

Beyond formal training, employees need hands-on practice to apply new skills and reflect on their experiences. Companies like UBS, DBS Bank, and Fidelity Investments use simulations, games, and live practice sessions to reinforce learning. Northeastern University partners with employers to create real-world projects tied to students’ job roles, allowing them to build practical experience while contributing to the organizations. Stretch assignments, where employees take on new tasks without switching jobs, further support skill development, yet many companies lack systems to make these opportunities visible.

Organizations benefit when they invest in internal talent. Ignoring internal candidates forces employees to look elsewhere for growth, worsening talent shortages. UPMC now includes career aspirations in performance reviews to encourage career conversations between employees and managers. Schneider Electric’s internal talent marketplace helps employees explore stretch roles through short-term projects and mentorships, giving managers a low-risk way to assess potential hires. By prioritizing skill development and internal mobility, companies strengthen their workforce while retaining top talent.﻿

Source: (Westerman & Lundberg, 2023)

Tuning Through Ongoing Feedback and Coaching
Effective coaching and feedback create an environment of continuous growth and self-improvement. When employees receive clear, constructive insights into their performance, they not only understand their current strengths and areas for development but also feel empowered to pursue new opportunities for learning. This open dialogue encourages a culture of trust and transparency, where individuals are encouraged to reflect, adapt, and strive for excellence beyond traditional performance reviews.

Pernod Ricard’s Let’s Talk Talent program shifts performance management toward ongoing career development, with managers acting as career coaches. Employees create talent profiles outlining their achievements and career goals, which managers and the global talent team use to guide discussions. Regular career conversations ensure employees receive the support they need, even beyond their direct managers. Strong companies make career coaching a core management responsibility, helping employees develop the skills needed for both current and future roles.

Ensuring managers provide quality feedback requires more than policy enforcement—it demands support and accountability. UPMC addresses this by coaching managers on talent development and using Anytime Check-in, a tool that enables real-time feedback from colleagues and supervisors. This system helps employees track their progress while allowing managers to reference feedback for performance reviews. By embedding feedback into daily workflows, companies create a culture where continuous coaching strengthens both individual careers and organizational success.

Source: (Westerman & Lundberg, 2023)

Recommended Readings
To learn more about how learning itself is changing, read The Transformer CLO.

To learn more about improving the career development process, read ﻿Why Companies Should Help Every Employee Chart a Career Path.﻿

Conclusion
Developing these pillars offers a cost-effective and integrated method of career development that replaces traditional, fragmented methods. Companies are no longer relying on separate systems for career discovery, learning, and feedback. Instead, they are uniting these elements into a single framework that automatically adapts to the needs of each employee, reducing the burden on HR and managers. This integrated, technology-driven approach enables employees to access personalized learning pathways, receive timely feedback, and navigate career opportunities with ease, ultimately building a more agile and resilient workforce.

Skip to content
Home	Menu
Previous
Next
3. Co-Creating the Future
Throughout this course, we have explored the foundational ideas of digital mastery in the AI era, examining the leadership capabilities that drive and sustain change and surveying emerging technologies from digital twins to collaborative robots. We have seen how AI can augment operations, products, and processes, and we have discussed the human-centered side of transformation—upskilling, engagement, and culture. But just knowing the concepts is not enough. You need to take concrete action to turn future potential into current reality.

​​​Leaders must choose clear strategic pathways to help their organizations flourish in the AI-powered future. This means setting direction, empowering innovation, and steering the course, and then repeating the process again and again. ​​

It is impossible to know what the future looks like, but you can create the foundations for success in your technology and people. Then, each step you take reveals new opportunities while paring back others.

​​In the end, it is continuous learning and development, in your people, your processes, and even the markets you work in, that will create success in whatever future you choose to pursue.

To wrap up the course, we have listed seven key steps that will help you to turn the concepts from the course into an actionable plan. Ultimately, organizational transformation is not achieved through isolated actions or a single strategic vision. It requires a shift in mindset, habits, and ways of working, grounded in purpose and shaped by context. The following steps serve as guideposts for navigating complex change, offering practical orientations rather than prescriptive formulas. They emphasize learning, adaptability, and the importance of engaging people throughout the organization.

As you start each, realize you will need to keep working on them continually as you drive your first transformation and all of the others that become possible for the AI-powered future.

Begin With Purpose
Effective transformation begins with clarity of purpose. This purpose should go beyond metrics or market position and instead reflect the organization’s broader reason for being. It should give people a reason to want to be part of the organization, and of the change. It should be clear enough for people to recognize what progress looks like, but flexible enough to allow them to contribute to shaping and expanding it.

Begin With Purpose
Flip
What is your vision for the AI-powered future?

Why is it better than your current course—for everyone, not just investors or managers?

How will people know when they are making progress toward the goal?

Flip
Articulating a compelling vision of the future can motivate and engage others in working toward its realization.

Engage Your People
Leaders create change by energizing people to make the change. They allocate resources and set direction, and then people execute on the change efforts. However, while computers tend to do what they are programmed to do, people are different. They do what they want to do. So, your job as a leader is to persuade employees to engage in the transformation and contribute their effort, enthusiasm, and ideas.

Engage Your People
Flip
How is the vision good for employees, not just customers or investors or managers?

What will you do to help people understand the vision, and how it affects them?

How can employees contribute to building out the vision?

What types of influence (soft or hard) do you need to apply to get people on board?

Flip
If you engage your people in the change, it will develop momentum. If not, you will constantly struggle to overcome resistance, both active and passive, and you will not benefit from the ideas of the people who know your business the best.

Move Quickly and Learn
Transformation is a process of constant learning. You cannot plan every step along the way, especially as technologies improve and customer preferences change. Even as you think about your purpose and long term goals, get started now. Where possible, focus on efforts through which you can move quickly, fail cheaply, and learn always. You may also need to make investment that create a foundation for those innovation processes.

Move Quickly and Learn
Flip
What foundational investments—in technology, data, skills, etc.—are needed to help the company be ready for the future?

Where can you start projects that move quickly and cheaply, enabling you to resolve uncertainties and make progress toward your vision?

How will you ensure that each team has what it needs, while also prompting it to push beyond what it is already doing?

Flip
Moving quickly does not have to be exhausting. If you create the right conditions, you can create momentum and keep it going by establishing the right foundation, energizing teams, and constantly celebrating the progress they make.

Steer the Course Through Governance
Organizational transformation is not driven by a single initiative but through the management of a diverse set of efforts. This includes a balance of low-risk, incremental improvements and ambitious, forward-looking projects. By combining short-term wins with long-term investments, organizations can build adaptive capacity, maintain momentum, and create lasting impact.

It is important to establish governance processes that ensure everyone is making progress in the right direction, while not preventing innovation that might identify valuable new directions. This means rules that aim to prevent bad consequences, but also methods to make it easier to move in the right direction. It should also include methods to ensure that each project builds on what others are doing, so that the transformation can scale efficiently without creating a new mess of legacy spaghetti.

Steer the Course Through Governance
Flip
How will you allocate funding across different activities?

How will you manage risks to cybersecurity, business continuity, information accuracy, and other operational goals?

What steps will you take to coordinate across projects?

How will you stop or redirect projects that are not making progress?

Flip
Governance should be more than just the brakes on your vehicle; it should also be the accelerator and the steering wheel. If you have all three, you can move quickly and safely toward making the vision a reality.

Ensure That Technology and Business Work Closely Together
Technology produces value only when it is used to improve a product or process. That means technology people cannot do it alone. It requires shared effort by people who know technology and people who know the business. With the right collaboration, each can contribute toward a solution that works for the company and its customers, while also being technically effective and maintainable. While each group has its own work to do independently of the others, success will happen when the people who need to interact can do it well with trust, shared understanding and sense of joint purpose.

Ensure That Technology and Business Work Closely Together
Flip
How well do your business and IT people collaborate now? How can you improve it?

Are you using agile practices? If not, how can you start?

How are you building shared responsibility, and shared recognition, in each project?

Flip
In any transformation, some tech people will focus only on technical tasks, while some business people will focus on only business tasks. However, the hard and most important part is ensuring that you manage the interface between the two sides so that the solutions can provide value both now and into the future.

Build Culture, Not Just Projects
Successful transformation cannot rely solely on top-down directives; it also requires initiative from across the organization. Leaders play a critical role in creating an environment where individuals at all levels are encouraged to take initiative, experiment, and contribute to change. This involves providing support, granting permission, and ensuring psychological safety—particularly when outcomes are uncertain. The aim is create a new mindset and new ways of working so that everyone feels empowered to move the company in the right direction, without having to be asked.

Build Culture, Not Just Projects
Flip
How can individuals at all levels contribute to the conversation?

How are you recognizing achievement at all levels?

How are you addressing concerns that people may have about the direction?

What are you doing to help people build the skills and experience they need to thrive?

Flip
Culture is what happens when the boss leaves the room. With the right culture, transformation is more than just a set of projects. When done well, it becomes an engine of innovation that creates new energy in its employees, even as it creates a continuous stream of new value for the company.

Never Stop Growing
Great companies never stop growing. Each achievement creates new possibilities to do more. The leader’s job is to push for tomorrow while ensuring people are happy today. This is a tough challenge. Like a great coach, the leader pushes the team to meet each challenge, celebrates each win, and then focuses on the next challenge.

Never Stop Growing
Flip
What are you doing to create a growth mindset in your people?

How do you celebrate wins?

How do you capture innovation ideas from all levels of the company?

Are your leaders, at all levels, pushing hard enough?

Do your people feel appropriately recognized and rewarded?

Flip
The goal is not only to foster employee satisfaction with their roles, but also to cultivate a healthy dissatisfaction with the status quo. While employees should feel fulfilled in their work, they should also be motivated to question existing processes and seek continuous improvement. This productive dissatisfaction is essential for driving innovation and ensuring the company remains competitive in an AI-driven future.

Keep In Mind
To wrap up this final module, you will finalize your AI-driven transformation course project. As you bring all the pieces that you have worked on over the past seven weeks together, be sure to keep the above steps in mind and ensure that you are addressing each of them in a satisfactory manner and consider how you could further refine your project.

Skip to content
Home	Menu
Previous
Next
4. Course Wrap-Up

You’ve done it! You now have the tools you need to help your organization co-create its AI-powered future. Keep in mind, the world of AI and technology never stops moving. As Dr. Westerman says, technology is the endless agitator of the business world (Westerman et al., 2014). Your project will create a plan fit for the current situation. But be sure to also include elements that will empower your organization to meet any future challenges and opportunities that might come along.

As technology continues to advance at an unprecedented pace, uncertainty is inevitable. Embracing this uncertainty as part of the journey encourages experimentation, continuous learning, and resilience. Ultimately, it is through the combined mastery of leadership practices, technological proficiency, and stakeholder readiness that organizations will navigate complexity and co-create ways to thrive in the digital era.


Course Project Part 8: Final Report
In the final part of your course project, you will bring together all of the pieces you have been working on to create a full report of your project. This comprehensive report will demonstrate your understanding and mastery of the materials in this course and your ability to effectively lead in the AI era.



